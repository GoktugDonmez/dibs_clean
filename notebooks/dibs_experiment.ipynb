{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4e0e158",
   "metadata": {},
   "source": [
    "# Setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8d964658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "38285f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/dibs_experiment.ipynb\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import logging\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "import mlflow\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Add project root to the Python path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from data.graph_data import generate_synthetic_data\n",
    "from models.dibs import grad_log_joint, log_joint, hard_gmat_from_z, bernoulli_soft_gmat, update_dibs_hparams\n",
    "from models.utils import acyclic_constr\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75147255",
   "metadata": {},
   "source": [
    "# CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b28f613a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 14:12:13,604 - INFO - Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    seed = 42\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    mlflow_experiment_name = \"DiBS Simple Experiment\"\n",
    "\n",
    "    # --- Data Generation ---\n",
    "    # 'simple_chain' or 'synthetic'\n",
    "    data_source = 'simple_chain'\n",
    "    \n",
    "    # Parameters for 'simple_chain'\n",
    "    num_samples = 50\n",
    "    obs_noise_std = 0.1\n",
    "\n",
    "    # Parameters for 'synthetic'\n",
    "    d_nodes = 3\n",
    "    graph_type = 'erdos-renyi'\n",
    "    graph_params = {'p_edge': 0.40}\n",
    "    synthetic_obs_noise_std = 0.1\n",
    "\n",
    "    # Particle and Model parameters\n",
    "    k_latent = 3\n",
    "    alpha_val = 0.1\n",
    "    beta_val = 1.0\n",
    "    tau_val = 1.0\n",
    "    theta_prior_sigma_val = 0.5\n",
    "    n_grad_mc_samples = 10\n",
    "    n_nongrad_mc_samples = 20\n",
    "\n",
    "    # Training parameters\n",
    "    lr = 0.005\n",
    "    num_iterations = 600\n",
    "    debug_print_iter = 100\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(cfg.seed)\n",
    "np.random.seed(cfg.seed)\n",
    "\n",
    "log.info(f\"Running on device: {cfg.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed17e43",
   "metadata": {},
   "source": [
    "# Syntetic data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5e74203f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:43:38,780 - INFO - Using 'simple_chain' data source.\n",
      "2025-06-17 11:43:38,782 - INFO - Data generated with 3 nodes.\n"
     ]
    }
   ],
   "source": [
    "# notebooks/dibs_experiment.ipynb\n",
    "\n",
    "# ---- [Cell 3: Data Generation] ----\n",
    "# Generate data based on the selected `data_source` from the configuration.\n",
    "\n",
    "def generate_ground_truth_data_x1_x2_x3(num_samples, obs_noise_std, seed=None):\n",
    "    \"\"\"Generates data for the ground truth causal chain X1 -> X2 -> X3.\"\"\"\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    D_nodes = 3\n",
    "    G_true = torch.zeros(D_nodes, D_nodes, dtype=torch.float32)\n",
    "    G_true[0, 1] = 1.0\n",
    "    G_true[1, 2] = 1.0\n",
    "    Theta_true = torch.zeros(D_nodes, D_nodes, dtype=torch.float32)\n",
    "    Theta_true[0, 1] = 2.0\n",
    "    Theta_true[1, 2] = -1.5\n",
    "    X_data = torch.zeros(num_samples, D_nodes)\n",
    "    X_data[:, 0] = torch.randn(num_samples)\n",
    "    noise_x2 = torch.randn(num_samples) * obs_noise_std\n",
    "    X_data[:, 1] = Theta_true[0, 1] * X_data[:, 0] + noise_x2\n",
    "    noise_x3 = torch.randn(num_samples) * obs_noise_std\n",
    "    X_data[:, 2] = Theta_true[1, 2] * X_data[:, 1] + noise_x3\n",
    "    return X_data, G_true, Theta_true\n",
    "\n",
    "if cfg.data_source == 'simple_chain':\n",
    "    log.info(\"Using 'simple_chain' data source.\")\n",
    "    data_x, graph_adj, graph_weights = generate_ground_truth_data_x1_x2_x3(\n",
    "        num_samples=cfg.num_samples,\n",
    "        obs_noise_std=cfg.obs_noise_std,\n",
    "        seed=cfg.seed\n",
    "    )\n",
    "    # Update d_nodes based on the simple chain's size\n",
    "    cfg.d_nodes = 3\n",
    "    \n",
    "elif cfg.data_source == 'synthetic':\n",
    "    log.info(\"Using 'synthetic' data source.\")\n",
    "    graph_adj, graph_weights, data_x = generate_synthetic_data(\n",
    "        n_samples=cfg.num_samples,\n",
    "        n_nodes=cfg.d_nodes,\n",
    "        graph_type=cfg.graph_type,\n",
    "        graph_params=cfg.graph_params,\n",
    "        noise_std=cfg.obs_noise_std\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Unknown data_source: {cfg.data_source}\")\n",
    "\n",
    "data = {'x': data_x.to(cfg.device)}\n",
    "log.info(f\"Data generated with {cfg.d_nodes} nodes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292cf42b",
   "metadata": {},
   "source": [
    "# MLflow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cc4732d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:43:38,824 - INFO - Started MLflow run for experiment: 'DiBS Simple Experiment'\n"
     ]
    }
   ],
   "source": [
    "# End any existing active run before starting a new one\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "mlflow.set_experiment(cfg.mlflow_experiment_name)\n",
    "mlflow.start_run()\n",
    "\n",
    "# Log all hyperparameters from the Config class\n",
    "for param, value in vars(cfg).items():\n",
    "    if not param.startswith('__') and not callable(value):\n",
    "        mlflow.log_param(param, value)\n",
    "\n",
    "log.info(f\"Started MLflow run for experiment: '{cfg.mlflow_experiment_name}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a604f2bc",
   "metadata": {},
   "source": [
    "# Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e13e0d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/dibs_experiment.ipynb\n",
    "\n",
    "# ---- [Cell 4: Model and Particle Initialization] ----\n",
    "# We initialize the learnable parameters (particles) z and theta.\n",
    "\n",
    "def init_particle(d: int, k: int, device: str) -> dict:\n",
    "    return {\n",
    "        'z': torch.randn(d, k, 2, device=device),\n",
    "        'theta': torch.randn(d, d, device=device)\n",
    "    }\n",
    "\n",
    "particle = init_particle(cfg.d_nodes, cfg.k_latent, cfg.device)\n",
    "\n",
    "# Hparams dictionary, as used by the model functions\n",
    "sigma_z = (1.0 / math.sqrt(cfg.k_latent))\n",
    "hparams = {\n",
    "    \"alpha\": cfg.alpha_val,\n",
    "    \"beta\": cfg.beta_val,\n",
    "    \"alpha_base\":cfg.alpha_val,\n",
    "    \"beta_base\": cfg.beta_val,\n",
    "    \"tau\": cfg.tau_val,\n",
    "    \"sigma_z\": sigma_z,\n",
    "    \"sigma_obs_noise\": cfg.synthetic_obs_noise_std,\n",
    "    \"theta_prior_sigma\": cfg.theta_prior_sigma_val,\n",
    "    \"n_grad_mc_samples\": cfg.n_grad_mc_samples,\n",
    "    \"n_nongrad_mc_samples\": cfg.n_nongrad_mc_samples,\n",
    "    \"d\": cfg.d_nodes,\n",
    "    \"debug_print_iter\": cfg.debug_print_iter\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c598ab4",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "Basic training loop using PyTorch optimizers with proper gradient hooking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b25ca0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,  44.4786,  24.2033],\n",
      "        [-47.1898,   0.0000,  65.2866],\n",
      "        [ -9.0020,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  1.4761e-03,  2.6468e+01],\n",
      "        [-5.2047e+01,  0.0000e+00,  6.9777e+01],\n",
      "        [ 2.2929e-25,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  2.6677e+02,  2.9686e-23],\n",
      "        [-5.5073e+01,  0.0000e+00,  3.1730e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  267.3206,    0.0000],\n",
      "        [-281.3912,    0.0000,  319.8256],\n",
      "        [ 409.1879,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000,   0.0000],\n",
      "        [-60.5278,   0.0000, 322.5313],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  2.6849e+02,  3.4185e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  8.5374e+01],\n",
      "        [-5.4408e-02,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  9.9117e-09,  3.6042e+01],\n",
      "        [-2.6135e+02,  0.0000e+00,  8.8920e+01],\n",
      "        [ 3.8009e+02,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  269.6341,    0.0000],\n",
      "        [-299.6117,    0.0000,  330.5020],\n",
      "        [ 435.7574,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  5.8735e-08,  3.9743e+01],\n",
      "        [-6.6367e-08,  0.0000e+00,  9.6315e+01],\n",
      "        [-8.9266e+01,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000,  41.6087],\n",
      "        [  0.0000,   0.0000, 100.0406],\n",
      "        [-85.5298,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 271.2349,  43.4824],\n",
      "        [-10.3117,   0.0000, 103.7783],\n",
      "        [-71.0858,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  8.3125e-13,  4.5363e+01],\n",
      "        [-7.5864e+01,  0.0000e+00,  1.0753e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  272.2716,   47.2523],\n",
      "        [-320.8500,    0.0000,  111.2903],\n",
      "        [ 466.7297,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  2.7283e+02,  4.9151e+01],\n",
      "        [-3.2335e-35,  0.0000e+00,  1.1507e+02],\n",
      "        [-7.4932e+01,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  5.4705e-16,  0.0000e+00],\n",
      "        [-6.5832e-16,  0.0000e+00,  3.4764e+02],\n",
      "        [-7.2269e+01,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  2.7398e+02,  5.3005e+01],\n",
      "        [-1.6336e-25,  0.0000e+00,  1.2275e+02],\n",
      "        [ 1.6963e-25,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  2.7458e+02,  5.4962e+01],\n",
      "        [-8.5296e+01,  0.0000e+00,  1.2665e+02],\n",
      "        [ 8.9292e-36,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 275.2227,   0.0000],\n",
      "        [-86.9641,   0.0000, 355.1331],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 275.8960,  58.9274],\n",
      "        [-88.6785,   0.0000, 134.5553],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 276.5970,   0.0000],\n",
      "        [  0.0000,   0.0000, 360.4058],\n",
      "        [-63.3778,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  2.7732e+02,  6.2966e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.4261e+02],\n",
      "        [-2.8517e-23,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000,   0.0000],\n",
      "        [-93.4978,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  2.7874e+02,  6.6876e+01],\n",
      "        [-9.5045e+01,  0.0000e+00,  1.5042e+02],\n",
      "        [ 7.7865e-39,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000,  68.7861],\n",
      "        [  0.0000,   0.0000, 154.2245],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000,  70.7384],\n",
      "        [-98.1629,   0.0000, 158.1148],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  4.0142e-12,  7.2729e+01],\n",
      "        [-9.9751e+01,  0.0000e+00,  1.6208e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,   74.7563],\n",
      "        [-101.4347,    0.0000,  166.1162],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  281.6813,   76.8174],\n",
      "        [-103.2087,    0.0000,  170.2189],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  282.2202,   78.9115],\n",
      "        [-105.0683,    0.0000,  174.3863],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  8.1037e+01],\n",
      "        [-4.9850e-11,  0.0000e+00,  1.7862e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  8.3194e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.8291e+02],\n",
      "        [-3.1741e-08,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  2.8383e+02,  8.5382e+01],\n",
      "        [-1.1039e+02,  0.0000e+00,  1.8726e+02],\n",
      "        [-3.0828e-07,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  2.8437e+02,  8.7600e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.9167e+02],\n",
      "        [-1.5098e-08,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  2.8496e+02,  0.0000e+00],\n",
      "        [-2.9026e-27,  0.0000e+00,  3.9640e+02],\n",
      "        [ 4.2222e-27,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,   92.1219],\n",
      "        [-115.1471,    0.0000,  200.6764],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,   94.4259],\n",
      "        [-116.7472,    0.0000,  205.2667],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  2.8668e+02,  9.6758e+01],\n",
      "        [-1.1849e+02,  0.0000e+00,  2.0991e+02],\n",
      "        [-2.9689e-04,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,   99.1189],\n",
      "        [-380.2983,    0.0000,  214.6138],\n",
      "        [ 553.1609,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  101.5069],\n",
      "        [-384.2928,    0.0000,  219.3690],\n",
      "        [ 558.9776,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 103.9220],\n",
      "        [  0.0000,   0.0000, 224.1779],\n",
      "        [-47.3985,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  288.6898,  106.3640],\n",
      "        [-128.1175,    0.0000,  229.0398],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  2.8919e+02,  1.0883e+02],\n",
      "        [-1.9483e-04,  0.0000e+00,  2.3395e+02],\n",
      "        [-4.1100e+01,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  1.1133e+02],\n",
      "        [-1.0991e-04,  0.0000e+00,  2.3892e+02],\n",
      "        [-3.8519e+01,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  2.9024e+02,  1.1385e+02],\n",
      "        [-1.9101e-32,  0.0000e+00,  2.4394e+02],\n",
      "        [ 2.7787e-32,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  290.8001,    0.0000],\n",
      "        [-137.0882,    0.0000,  429.2336],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  118.9463],\n",
      "        [-413.4069,    0.0000,  254.0970],\n",
      "        [ 601.3965,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 291.9586, 121.5248],\n",
      "        [  0.0000,   0.0000, 259.2371],\n",
      "        [-29.0053,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000, 439.1913],\n",
      "        [-25.9459,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  293.1064,  126.7294],\n",
      "        [-146.0938,    0.0000,  269.6175],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  2.9370e+02,  1.2936e+02],\n",
      "        [-1.4829e+02,  0.0000e+00,  2.7486e+02],\n",
      "        [-6.9032e-39,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  4.4936e-38,  1.3202e+02],\n",
      "        [-1.5058e+02,  0.0000e+00,  2.8016e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  2.9493e+02,  1.3470e+02],\n",
      "        [-7.0751e-07,  0.0000e+00,  2.8551e+02],\n",
      "        [-1.6559e+01,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 137.4091],\n",
      "        [  0.0000,   0.0000, 290.9168],\n",
      "        [-14.7812,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [-157.0591,    0.0000,  460.1838],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  142.8609],\n",
      "        [-159.1503,    0.0000,  301.7915],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 145.6068],\n",
      "        [  0.0000,   0.0000, 307.2705],\n",
      "        [-10.5097,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  148.3802],\n",
      "        [-453.3830,    0.0000,  312.8029],\n",
      "        [ 659.6057,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  297.9379,  151.1799],\n",
      "        [-165.9508,    0.0000,  318.3864],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 298.3994, 154.0045],\n",
      "        [  0.0000,   0.0000, 324.0187],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  298.9245,    0.0000],\n",
      "        [-170.9887,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  1.6788e-42,  1.5944e+02],\n",
      "        [-1.7348e+02,  0.0000e+00,  3.3485e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -511.8462],\n",
      "        [-176.0627,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 163.9372],\n",
      "        [  0.0000,   0.0000, 343.8488],\n",
      "        [  5.3561,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  1.6592e+02],\n",
      "        [-1.8115e+02,  0.0000e+00,  3.4782e+02],\n",
      "        [ 7.9594e-32,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  3.0134e+02,  0.0000e+00],\n",
      "        [-3.5548e-08,  0.0000e+00,  4.9844e+02],\n",
      "        [ 8.6807e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 170.1550],\n",
      "        [  0.0000,   0.0000, 356.3223],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  172.3974],\n",
      "        [-188.0498,    0.0000,  360.8185],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  174.7267],\n",
      "        [-190.2922,    0.0000,  365.4853],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  177.1347],\n",
      "        [-192.6820,    0.0000,  370.3067],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  179.6144],\n",
      "        [-195.2065,    0.0000,  375.2688],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 182.1593],\n",
      "        [  0.0000,   0.0000, 380.3593],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 184.7639],\n",
      "        [  0.0000,   0.0000, 385.5671],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  304.0633,  187.4232],\n",
      "        [-202.4311,    0.0000,  390.8825],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 304.3958, 190.1328],\n",
      "        [  0.0000,   0.0000, 396.2970],\n",
      "        [ 17.8842,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  304.8135,  192.8889],\n",
      "        [-206.9149,    0.0000,  401.8030],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000, 538.9266],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000, 542.9232],\n",
      "        [ 19.7216,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  3.0616e+02,  4.3874e-21],\n",
      "        [-1.1413e-20,  0.0000e+00,  5.4703e+02],\n",
      "        [ 1.6603e-20,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 306.6388,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000],\n",
      "        [ 20.8211,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  307.1887,  206.4469],\n",
      "        [-216.5347,    0.0000,  428.9354],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 307.7986, 209.0123],\n",
      "        [  0.0000,   0.0000, 434.0720],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 308.4612, 211.6537],\n",
      "        [  0.0000,   0.0000, 439.3577],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  7.0378e-25,  0.0000e+00],\n",
      "        [-5.0432e-25,  0.0000e+00,  5.6670e+02],\n",
      "        [ 2.2744e+01,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  8.7650e-22,  2.1706e+02],\n",
      "        [-2.2291e+02,  0.0000e+00,  4.5018e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  310.3942,  219.8235],\n",
      "        [-224.5937,    0.0000,  455.7063],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  3.1058e+02,  2.2265e+02],\n",
      "        [-2.2622e+02,  0.0000e+00,  4.6135e+02],\n",
      "        [ 1.5983e-13,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [-541.7399,    0.0000,  582.9735],\n",
      "        [ 788.0276,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  228.3641],\n",
      "        [-231.6413,    0.0000,  472.7887],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[0.0000e+00, 0.0000e+00, 2.3126e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 4.7859e+02],\n",
      "        [4.1247e-10, 0.0000e+00, 0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  313.4164,  234.2089],\n",
      "        [-556.1035,    0.0000,  484.4771],\n",
      "        [ 808.9443,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000, 599.8055],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 314.5132, 240.1478],\n",
      "        [  0.0000,   0.0000, 496.3525],\n",
      "        [ 41.7359,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  3.1510e+02,  2.4314e+02],\n",
      "        [-1.9788e-05,  0.0000e+00,  5.0234e+02],\n",
      "        [ 4.5723e+01,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  6.4281e-23,  2.4618e+02],\n",
      "        [-2.4882e+02,  0.0000e+00,  5.0841e+02],\n",
      "        [ 1.1724e-18,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 14:14:07,215 - INFO - [0100] log_joint = -953.472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  316.3229,  249.2581],\n",
      "        [-251.4572,    0.0000,  514.5634],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  316.9619,  252.3716],\n",
      "        [-588.7759,    0.0000,  520.7827],\n",
      "        [ 856.5767,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 255.5179],\n",
      "        [  0.0000,   0.0000, 527.0660],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  318.2762,  258.6946],\n",
      "        [-260.6984,    0.0000,  533.4088],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [-263.8729,    0.0000,  634.3453],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 319.5658,   0.0000],\n",
      "        [  0.0000,   0.0000, 638.7555],\n",
      "        [ 73.7673,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  5.7070e-23,  2.6812e+02],\n",
      "        [-2.7012e+02,  0.0000e+00,  5.5223e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 271.2366],\n",
      "        [  0.0000,   0.0000, 558.4748],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -480.1807],\n",
      "        [-276.0423,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000, 656.1948],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  279.5412],\n",
      "        [-281.7064,    0.0000,  575.1108],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [-284.5800,    0.0000,  664.5206],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[0.0000e+00, 5.1541e-13, 4.5444e-13],\n",
      "        [0.0000e+00, 0.0000e+00, 6.6879e+02],\n",
      "        [9.3182e+01, 0.0000e+00, 0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  3.2342e+02,  2.8751e+02],\n",
      "        [-3.6565e-05,  0.0000e+00,  5.9110e+02],\n",
      "        [ 9.5301e+01,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 290.2499],\n",
      "        [  0.0000,   0.0000, 596.5981],\n",
      "        [ 97.5237,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 293.0744],\n",
      "        [  0.0000,   0.0000, 602.2595],\n",
      "        [ 99.8490,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 324.5639,   0.0000],\n",
      "        [  0.0000,   0.0000, 686.2675],\n",
      "        [102.2751,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  298.8369],\n",
      "        [-666.7494,    0.0000,  613.8060],\n",
      "        [ 970.1649,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  3.0177e+02],\n",
      "        [-7.0913e-29,  0.0000e+00,  6.1969e+02],\n",
      "        [ 1.0973e+02,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 325.7385, 304.7760],\n",
      "        [  0.0000,   0.0000, 625.6984],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  3.2618e+02,  3.0784e+02],\n",
      "        [-1.9310e-05,  0.0000e+00,  6.3183e+02],\n",
      "        [ 1.1884e+02,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 310.9550],\n",
      "        [  0.0000,   0.0000, 638.0577],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 314.1195],\n",
      "        [  0.0000,   0.0000, 644.3834],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  7.0276e-24,  3.1733e+02],\n",
      "        [-1.0022e-26,  0.0000e+00,  6.5079e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[0.0000e+00, 2.0581e-21, 2.0117e-21],\n",
      "        [0.0000e+00, 0.0000e+00, 7.2211e+02],\n",
      "        [1.3358e+02, 0.0000e+00, 0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 323.7471],\n",
      "        [  0.0000,   0.0000, 663.6243],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  7.6136e-25,  3.2697e+02],\n",
      "        [-1.4452e-28,  0.0000e+00,  6.7006e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 328.9175, 330.2242],\n",
      "        [  0.0000,   0.0000, 676.5690],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 333.5204],\n",
      "        [  0.0000,   0.0000, 683.1534],\n",
      "        [144.8156,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  262.0050,  267.7329],\n",
      "        [-318.2153,    0.0000,  701.1176],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,  61.5346,  63.4241],\n",
      "        [  0.0000,   0.0000, 739.6434],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 343.4682],\n",
      "        [  0.0000,   0.0000, 703.0250],\n",
      "        [151.9229,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 330.8091,   0.0000],\n",
      "        [  0.0000,   0.0000, 758.7845],\n",
      "        [154.3223,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  3.3126e+02,  3.5002e+02],\n",
      "        [-2.5910e-27,  0.0000e+00,  7.1612e+02],\n",
      "        [ 1.5697e+02,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 331.7878,   0.0000],\n",
      "        [  0.0000,   0.0000, 768.0999],\n",
      "        [159.8481,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  356.4981],\n",
      "        [-324.3821,    0.0000,  729.0765],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  7.4973e-29,  3.5975e+02],\n",
      "        [-3.2563e+02,  0.0000e+00,  7.3558e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  3.3342e+02,  0.0000e+00],\n",
      "        [-1.2421e-28,  0.0000e+00,  7.8216e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  333.9898,  366.2614],\n",
      "        [-328.7850,    0.0000,  748.6019],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  4.6943e-43,  3.6953e+02],\n",
      "        [-3.3067e+02,  0.0000e+00,  7.5514e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  335.1978,  372.8428],\n",
      "        [-332.8900,    0.0000,  761.7609],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 335.8382, 376.1993],\n",
      "        [  0.0000,   0.0000, 768.4680],\n",
      "        [176.1799,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  3.7959e+02],\n",
      "        [-3.3770e+02,  0.0000e+00,  7.7525e+02],\n",
      "        [ 1.3239e-41,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  325.5223, -449.7458],\n",
      "        [ -11.7552,    0.0000,    0.0000],\n",
      "        [ 173.9295,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 385.9243],\n",
      "        [  0.0000,   0.0000, 787.9027],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[0.0000e+00, 4.2155e-34, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 8.1899e+02],\n",
      "        [1.8446e+02, 0.0000e+00, 0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 294.5977, 391.8558],\n",
      "        [-45.4470,   0.0000, 799.7709],\n",
      "        [162.3986,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 394.8820],\n",
      "        [  0.0000,   0.0000, 805.8254],\n",
      "        [189.6272,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  333.4077,   -8.9144],\n",
      "        [-350.1321,    0.0000,  815.6016],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[0.0000e+00, 8.1959e-11, 4.0102e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 8.1810e+02],\n",
      "        [4.7005e-11, 0.0000e+00, 0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 404.1255],\n",
      "        [  0.0000,   0.0000, 824.3182],\n",
      "        [197.9860,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 341.9096, 407.3039],\n",
      "        [  0.0000,   0.0000, 830.6739],\n",
      "        [200.8932,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  4.1054e+02],\n",
      "        [-5.5104e-12,  0.0000e+00,  8.3715e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  2.1593e-17, -4.4098e+02],\n",
      "        [-3.5851e+02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 416.6429],\n",
      "        [  0.0000,   0.0000, 849.3466],\n",
      "        [209.7993,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  4.1955e+02],\n",
      "        [-1.4847e-37,  0.0000e+00,  8.5516e+02],\n",
      "        [ 2.1290e+02,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  422.5502],\n",
      "        [-363.3872,    0.0000,  861.1619],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  9.2830e-40, -4.3763e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  9.9475e-14],\n",
      "        [ 2.1953e+02,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -436.9595],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [ 223.0938,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000, 879.6443],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  345.5318,    0.0000],\n",
      "        [-369.9548,    0.0000,  883.3558],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000],\n",
      "        [233.7986,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000, 890.6702],\n",
      "        [237.4615,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  2.3195e-23,  4.3911e+02],\n",
      "        [-3.7499e+02,  0.0000e+00,  8.9438e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.3469e+02],\n",
      "        [-3.7695e+02,  0.0000e+00,  1.5400e-13],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  3.4704e+02,  4.4330e+02],\n",
      "        [-2.1984e-39,  0.0000e+00,  9.0281e+02],\n",
      "        [ 2.4855e+02,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 347.3880,   0.0000],\n",
      "        [  0.0000,   0.0000, 905.0541],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.3380e+02],\n",
      "        [-3.7597e-42,  0.0000e+00,  8.9137e-42],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -433.6651],\n",
      "        [-385.0855,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000],\n",
      "        [261.7326,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  7.0288e-26, -4.3371e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.3407e-26,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  4.1452e-12,  4.5324e+02],\n",
      "        [-3.9097e+02,  0.0000e+00,  9.2288e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  1.5554e-10,  4.5460e+02],\n",
      "        [-3.9317e+02,  0.0000e+00,  9.2564e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.3371e+02],\n",
      "        [-2.1940e-22,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[0.0000e+00, 8.2069e-07, 4.5757e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 9.3163e+02],\n",
      "        [2.7574e+02, 0.0000e+00, 0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.3358e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.5437e-38],\n",
      "        [ 2.7870e+02,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.3359e+02],\n",
      "        [-4.0210e+02,  0.0000e+00,  2.6144e-40],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  5.7310e-02,  4.6138e+02],\n",
      "        [-4.0443e+02,  0.0000e+00,  9.3950e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -433.7185],\n",
      "        [-407.1404,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000, 944.2446],\n",
      "        [293.5118,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 351.0152,   0.0000],\n",
      "        [  0.0000,   0.0000, 946.7598],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  467.3718],\n",
      "        [-417.6613,    0.0000,  951.5107],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -434.0756],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [ 302.0468,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.3415e+02],\n",
      "        [-4.2269e+02,  0.0000e+00,  1.3898e-20],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [-931.8948,    0.0000,    0.0000],\n",
      "        [1356.9246,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  472.1642],\n",
      "        [-429.1588,    0.0000,  961.2437],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 303.4483, 473.4056],\n",
      "        [-59.8752,   0.0000, 963.7578],\n",
      "        [276.2455,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -434.4248],\n",
      "        [-436.6824,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -434.4417],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [ 332.0288,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -434.5870],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -434.8467],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  353.1652, -435.2081],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  353.4578,  478.8835],\n",
      "        [-452.5016,    0.0000,  974.9381],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 14:14:09,025 - INFO - [0200] log_joint = -1473.067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  1.1075e-04, -4.3592e+02],\n",
      "        [-3.1122e-04,  0.0000e+00,  3.0608e-04],\n",
      "        [ 4.5321e-04, -1.8291e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  1.1227e-34,  4.8020e+02],\n",
      "        [-1.4518e-34,  0.0000e+00,  9.7766e+02],\n",
      "        [ 3.5969e+02,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  481.1206],\n",
      "        [-460.4272,    0.0000,  979.5341],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  4.9954e-05, -4.3650e+02],\n",
      "        [-4.6320e+02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   355.1232,    -3.0978],\n",
      "        [-1015.5320,     0.0000,     0.0000],\n",
      "        [ 1478.9048,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  8.7210e-17],\n",
      "        [-4.7031e+02,  0.0000e+00,  1.7755e-16],\n",
      "        [ 6.8063e-17,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  355.8544,   -2.9749],\n",
      "        [-474.4848,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   356.3085,  -437.0201],\n",
      "        [-1040.5000,     0.0000,     0.0000],\n",
      "        [ 1515.3129,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -437.2457],\n",
      "        [-483.8328,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 486.6363],\n",
      "        [  0.0000,   0.0000, 990.7903],\n",
      "        [405.0004,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 487.3703],\n",
      "        [  0.0000,   0.0000, 992.2889],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -437.7275],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [ 419.4518,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 358.5682,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000],\n",
      "        [426.6183,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000, 490.0496],\n",
      "        [  0.0000,   0.0000, 997.7314],\n",
      "        [434.0755,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -437.9245],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [ 441.8054,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  492.0167],\n",
      "        [   0.0000,    0.0000, 1001.7172],\n",
      "        [ 449.7918,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  360.1916, -437.9554],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000],\n",
      "        [465.4468,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  4.9503e+02],\n",
      "        [-1.1358e+03,  0.0000e+00,  1.0078e+03],\n",
      "        [ 1.6545e+03, -4.8667e-21,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -438.0075],\n",
      "        [-520.1898,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  497.1651],\n",
      "        [   0.0000,    0.0000, 1012.1412],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -7.3362e-12],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.3813e-12,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  362.3336, -437.8799],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000, 1024.2365],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  501.5855],\n",
      "        [   0.0000,    0.0000, 1021.0804],\n",
      "        [ 520.3044,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  1.9427e-02, -4.3786e+02],\n",
      "        [-5.3595e+02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.8162e-02,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 363.6810,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  505.1608],\n",
      "        [-540.5923,    0.0000, 1028.3131],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  2.7537e-30,  5.0650e+02],\n",
      "        [-4.1041e-30,  0.0000e+00,  1.0310e+03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  3.6478e+02, -4.3757e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.3391e-17,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  365.2219,    0.0000],\n",
      "        [-547.6221,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -437.3854],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [ 554.4160,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -437.4249],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -437.5768],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [ 562.7155,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  367.0952,  512.9802],\n",
      "        [-556.3249,    0.0000, 1044.1321],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.3792e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.2114e-21,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  3.6806e+02,  5.1464e+02],\n",
      "        [-1.5360e-13,  0.0000e+00,  1.0475e+03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  1.2829e-12,  5.1571e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0497e+03],\n",
      "        [ 0.0000e+00, -1.9137e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  369.1108,  517.0918],\n",
      "        [-564.2744,    0.0000, 1052.4733],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  3.6971e+02,  5.1874e+02],\n",
      "        [-4.3699e-18,  0.0000e+00,  1.0558e+03],\n",
      "        [ 7.9787e-24,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  370.3856, -437.5060],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[0.0000e+00, 1.0045e-36, 1.4134e-36],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0670e+03],\n",
      "        [5.9003e+02, 0.0000e+00, 0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  371.8196,  523.9418],\n",
      "        [   0.0000,    0.0000, 1066.2617],\n",
      "        [ 593.4136,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  372.5742,  525.8906],\n",
      "        [   0.0000,    0.0000, 1070.1821],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  528.0506],\n",
      "        [   0.0000,    0.0000, 1074.5214],\n",
      "        [ 601.6581,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  374.1350,  530.3990],\n",
      "        [   0.0000,    0.0000, 1079.2340],\n",
      "        [ 606.4730,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -135.7870],\n",
      "        [-576.7139,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  375.6717, -434.9533],\n",
      "        [-578.3336,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000, 1091.5948],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  377.1889,    0.0000],\n",
      "        [   0.0000,    0.0000, 1095.0424],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  377.9784, -434.0903],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [ 629.5980,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   378.8299,  -433.9681],\n",
      "        [-1314.0739,     0.0000,     0.0000],\n",
      "        [ 1914.8376,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  379.7363,  544.3332],\n",
      "        [   0.0000,    0.0000, 1107.2668],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  546.0710],\n",
      "        [   0.0000,    0.0000, 1110.7727],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  3.8155e+02,  3.4786e-15],\n",
      "        [-3.7652e-15,  0.0000e+00,  1.1117e+03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -433.3382],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [ 660.8560,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  383.2941, -433.2366],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [ 667.2244,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [-1354.3916,     0.0000,     0.0000],\n",
      "        [ 1973.7698,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  384.9742,  554.6263],\n",
      "        [-601.6205,    0.0000, 1128.0416],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -433.1446],\n",
      "        [-604.8143,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000, 1130.0985],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  387.3031,    0.0000],\n",
      "        [-611.4458,    0.0000, 1133.1003],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -433.1335],\n",
      "        [-614.8923,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  3.8877e+02, -4.3324e+02],\n",
      "        [-6.4742e-16,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  563.1377],\n",
      "        [   0.0000,    0.0000, 1145.2830],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  390.2250, -433.4818],\n",
      "        [-624.9790,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  565.7340],\n",
      "        [-628.3220,    0.0000, 1150.5536],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  567.2129],\n",
      "        [   0.0000,    0.0000, 1153.5459],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  -433.4690],\n",
      "        [-1435.5229,     0.0000,     0.0000],\n",
      "        [ 2092.1580,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  392.8607, -433.4425],\n",
      "        [-639.4346,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  -433.5240],\n",
      "        [ -643.8190,     0.0000,     0.0000],\n",
      "        [    0.0000, -1980.7805,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -433.7026],\n",
      "        [-648.3578,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  -433.9680],\n",
      "        [ -653.0344,     0.0000,     0.0000],\n",
      "        [    0.0000, -1992.3612,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  395.0966, -434.3115],\n",
      "        [-657.8344,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [-662.7449,    0.0000, 1167.5853],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  396.1864, -435.0977],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  396.7961, -435.5377],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [ 776.8969,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[  0.0000, 397.4884,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000],\n",
      "        [781.0683,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  398.2542,  576.4207],\n",
      "        [-680.0234,    0.0000, 1172.4236],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -436.7546],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [ 790.7452,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  577.7018],\n",
      "        [   0.0000,    0.0000, 1175.0679],\n",
      "        [ 796.2153,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  400.5103, -437.2676],\n",
      "        [-690.6685,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  401.2614, -437.5242],\n",
      "        [-694.1613,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  402.0794, -437.8588],\n",
      "        [-697.9243,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  580.3166],\n",
      "        [-701.9276,    0.0000, 1180.4579],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   805.9044,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [  821.9311, -2360.0217,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  -438.6921],\n",
      "        [-1569.6627,     0.0000,     0.0000],\n",
      "        [ 2287.6104,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  7.4093e-39,  5.8236e+02],\n",
      "        [-7.1460e+02,  0.0000e+00,  1.1846e+03],\n",
      "        [ 1.5253e-38,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  406.4008,  583.2726],\n",
      "        [   0.0000,    0.0000, 1186.5110],\n",
      "        [ 842.1688,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  1.8338e-35, -4.3907e+02],\n",
      "        [-7.2370e+02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.8271e-35,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -439.1441],\n",
      "        [-728.1782,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  408.7208, -439.3151],\n",
      "        [-732.8104,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  -439.5711],\n",
      "        [ -737.5771,     0.0000,     0.0000],\n",
      "        [    0.0000, -2100.9292,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  410.1775, -439.9037],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [ 874.0429,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  410.9398, -440.3048],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [ 880.0203,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [-750.8454,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  412.5103, -441.1847],\n",
      "        [-755.0327,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  -441.6621],\n",
      "        [ -759.4094,     0.0000,     0.0000],\n",
      "        [    0.0000, -2131.7957,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  414.0514, -442.1936],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [ 903.2411,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  414.8492,  588.0389],\n",
      "        [   0.0000,    0.0000, 1196.4663],\n",
      "        [ 909.0789,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  415.7068, -443.1577],\n",
      "        [-771.7511,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   851.7578,  -443.6049],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -2493.8018,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  -444.1089],\n",
      "        [ -779.2546,     0.0000,     0.0000],\n",
      "        [    0.0000, -2169.0874,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -444.6637],\n",
      "        [-783.0790,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   588.3836],\n",
      "        [    0.0000,     0.0000,  1197.3730],\n",
      "        [    0.0000, -2190.5981,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  420.3535,    0.0000],\n",
      "        [-790.8024,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  -446.0323],\n",
      "        [-1734.0283,     0.0000,     0.0000],\n",
      "        [ 2527.2390,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  421.9747,  589.1149],\n",
      "        [   0.0000,    0.0000, 1198.9537],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  589.6830],\n",
      "        [-803.7611,    0.0000, 1200.1245],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 14:14:10,956 - INFO - [0300] log_joint = -3684.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  423.5523, -446.8035],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [ 962.1981,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   889.1266,  -446.9865],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -2603.1694,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -447.2520],\n",
      "        [-815.8729,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  592.3658],\n",
      "        [-819.7524,    0.0000, 1205.6285],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  427.0778, -447.7628],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  -448.0172],\n",
      "        [ -827.5563,     0.0000,     0.0000],\n",
      "        [    0.0000, -2281.1963,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  428.7266,  594.2703],\n",
      "        [   0.0000,    0.0000, 1209.5465],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   911.8169,  -448.5087],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [  995.3192, -2669.5149,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -448.7546],\n",
      "        [-838.2698,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  -449.0757],\n",
      "        [ -841.7826,     0.0000,     0.0000],\n",
      "        [    0.0000, -2319.2891,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   596.6513],\n",
      "        [    0.0000,     0.0000,  1214.4595],\n",
      "        [    0.0000, -2330.5586,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  433.0966,    0.0000],\n",
      "        [-848.9772,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  -449.8749],\n",
      "        [ -852.6718,     0.0000,     0.0000],\n",
      "        [    0.0000, -2354.5698,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  434.6365,  598.5959],\n",
      "        [-856.6185,    0.0000, 1218.4528],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  -450.2640],\n",
      "        [ -860.7893,     0.0000,     0.0000],\n",
      "        [    0.0000, -2378.6877,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   600.1976],\n",
      "        [    0.0000,     0.0000,  1221.7212],\n",
      "        [    0.0000, -2391.3743,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   601.2652],\n",
      "        [ -869.1002,     0.0000,  1223.8862],\n",
      "        [    0.0000, -2405.1011,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  -450.4277],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [ 1024.8674, -2419.6938,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  437.8883,  603.8077],\n",
      "        [   0.0000,    0.0000, 1229.0266],\n",
      "        [1027.9816,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  438.4957,  605.2737],\n",
      "        [-880.4133,    0.0000, 1231.9844],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  439.1781,  607.0186],\n",
      "        [-884.0927,    0.0000, 1235.4962],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  439.9276,  609.0122],\n",
      "        [-888.0312,    0.0000, 1239.5028],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -449.3221],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [1042.8075,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   988.9969,  -449.0259],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -2895.9094,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  442.4070, -448.8563],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  4.4338e+02, -4.4880e+02],\n",
      "        [-1.9171e+03,  0.0000e+00,  2.7208e-24],\n",
      "        [ 2.7939e+03, -5.4521e-24,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   444.3954,  -448.8464],\n",
      "        [-1925.7944,     0.0000,     0.0000],\n",
      "        [ 2806.5610,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  -448.9842],\n",
      "        [ -911.2180,     0.0000,     0.0000],\n",
      "        [    0.0000, -2529.1606,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  446.3733, -449.2043],\n",
      "        [-916.1373,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [ -921.1581,     0.0000,  1288.4606],\n",
      "        [    0.0000, -2547.2212,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  448.2277,  620.2771],\n",
      "        [   0.0000,    0.0000, 1262.3033],\n",
      "        [1094.0243,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1021.9121,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -2992.1353,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   622.5026],\n",
      "        [ -935.0342,     0.0000,  1266.8245],\n",
      "        [    0.0000, -2576.8877,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  1.0316e+03,  1.6916e-04],\n",
      "        [-9.3938e+02,  0.0000e+00,  3.4425e-04],\n",
      "        [ 7.8837e-04, -3.0205e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  452.4301,  625.1309],\n",
      "        [-943.8924,    0.0000, 1272.1365],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   626.6846],\n",
      "        [    0.0000,     0.0000,  1275.2667],\n",
      "        [    0.0000, -2613.2861,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   454.6744,  -449.4138],\n",
      "        [-2018.7092,     0.0000,     0.0000],\n",
      "        [ 2942.0527,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   630.0651],\n",
      "        [    0.0000,     0.0000,  1282.0713],\n",
      "        [    0.0000, -2637.2231,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1057.7008,  -448.9717],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -3096.8579,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  -448.8155],\n",
      "        [ -966.2350,     0.0000,     0.0000],\n",
      "        [    0.0000, -2662.8374,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  -331.4939],\n",
      "        [ -865.4264,     0.0000,   139.7881],\n",
      "        [    0.0000, -2676.8057,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  459.8634,    0.0000],\n",
      "        [   0.0000,    0.0000, 1320.2990],\n",
      "        [1160.5903,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1080.3859,   637.2211],\n",
      "        [    0.0000,     0.0000,  1296.5192],\n",
      "        [    0.0000, -3163.3254,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   461.9757,   638.8541],\n",
      "        [-2076.7534,     0.0000,  1299.8153],\n",
      "        [ 3026.6841,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000, -448.4796],\n",
      "        [-986.6334,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   464.1659,     0.0000],\n",
      "        [-2096.0862,     0.0000,     0.0000],\n",
      "        [ 3054.8909,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   643.8348],\n",
      "        [ -996.3729,     0.0000,  1309.8582],\n",
      "        [    0.0000, -2752.5334,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   466.1765,  -448.0303],\n",
      "        [-2119.0518,     0.0000,     0.0000],\n",
      "        [ 3088.3994,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  1.1102e+03, -5.4937e-14],\n",
      "        [-1.0075e+03,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -3.2506e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  4.6831e+02, -4.4782e+02],\n",
      "        [-2.1447e+03,  0.0000e+00,  7.3935e-41],\n",
      "        [ 3.1258e+03, -1.5611e-40,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1119.8456,  -447.8207],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [ 1237.4667, -3278.7551,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1125.0243,  -447.9171],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -3293.8821,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1130.6772,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [ 1259.6113, -3310.3943,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1136.7340,  -448.2599],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -3328.0847,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1143.1343,  -448.4998],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [ 1279.9283, -3346.7778,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1149.8259,  -448.8093],\n",
      "        [-1042.9579,     0.0000,     0.0000],\n",
      "        [    0.0000, -3366.3215,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1156.7644,   652.8752],\n",
      "        [-1046.9121,     0.0000,  1328.2333],\n",
      "        [    0.0000, -3386.5857,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,    0.0000,  653.5268],\n",
      "        [   0.0000,    0.0000, 1329.5687],\n",
      "        [1306.8634,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   482.3880,   654.5578],\n",
      "        [-1054.7681,     0.0000,  1331.6591],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1176.2675,  -449.3234],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -3443.5347,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   657.0688],\n",
      "        [-1062.2374,     0.0000,  1336.7334],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[   0.0000,  487.1731, -449.1975],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [1336.3108,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1193.3153,  -449.1722],\n",
      "        [-1069.3989,     0.0000,     0.0000],\n",
      "        [    0.0000, -3493.2891,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  -449.2418],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [ 1349.5343, -2967.6167,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  -449.3966],\n",
      "        [-1076.3154,     0.0000,     0.0000],\n",
      "        [    0.0000, -2980.0706,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   492.8707,  -449.6280],\n",
      "        [-1079.8505,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   662.7589],\n",
      "        [-1083.6146,     0.0000,  1348.3005],\n",
      "        [    0.0000, -3004.6494,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  -450.0622],\n",
      "        [-1087.5828,     0.0000,     0.0000],\n",
      "        [    0.0000, -3016.8611,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   496.2550,  -450.2745],\n",
      "        [-2326.8337,     0.0000,     0.0000],\n",
      "        [ 3391.6643,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1230.8391,  -450.5573],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [ 1385.4282, -3603.0034,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1236.1680,  -450.9035],\n",
      "        [-1101.0094,     0.0000,     0.0000],\n",
      "        [    0.0000, -3618.5913,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   499.7387,   665.6011],\n",
      "        [-1105.5355,     0.0000,  1354.1689],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1247.1113,  -451.5332],\n",
      "        [-2364.7214,     0.0000,     0.0000],\n",
      "        [ 3446.9229, -3650.5830,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   502.3940,  -451.8286],\n",
      "        [-2375.9524,     0.0000,     0.0000],\n",
      "        [ 3463.3062,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   503.7433,  -452.1858],\n",
      "        [-2389.0618,     0.0000,     0.0000],\n",
      "        [ 3482.4365,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  1.2627e+03, -4.5260e+02],\n",
      "        [-1.1276e+03,  0.0000e+00,  2.3789e-40],\n",
      "        [ 6.1374e-40, -3.6960e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   667.6407],\n",
      "        [    0.0000,     0.0000,  1358.4443],\n",
      "        [ 1449.4459, -3123.0708,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   507.7697,  -453.3423],\n",
      "        [-2430.7114,     0.0000,     0.0000],\n",
      "        [ 3543.2239,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1277.9027,  -453.6861],\n",
      "        [-1145.5450,     0.0000,     0.0000],\n",
      "        [    0.0000, -3740.4958,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   668.9602],\n",
      "        [-1151.5592,     0.0000,  1361.2010],\n",
      "        [    0.0000, -3156.6726,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   511.6355,  -454.3118],\n",
      "        [-1157.5010,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   670.2402],\n",
      "        [    0.0000,     0.0000,  1363.8353],\n",
      "        [ 1504.3236, -3179.3250,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1298.1879,  -454.7346],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [ 1513.9027, -3799.7759,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   515.1712,   671.9576],\n",
      "        [-1173.4520,     0.0000,  1367.3396],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1308.4023,  -454.9937],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [ 1532.6149, -3829.6313,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1313.6895,   674.0275],\n",
      "        [-1182.6526,     0.0000,  1371.5449],\n",
      "        [    0.0000, -3845.0771,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1319.3168,  -455.1205],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [ 1550.1415, -3861.5144,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1325.2379,  -455.2013],\n",
      "        [-1191.1526,     0.0000,     0.0000],\n",
      "        [    0.0000, -3878.8083,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   677.2543],\n",
      "        [-1195.3278,     0.0000,  1378.0956],\n",
      "        [    0.0000, -3264.2903,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   678.4862],\n",
      "        [-1199.6334,     0.0000,  1380.5901],\n",
      "        [    0.0000, -3278.0264,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1343.4962,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [ 1580.2078, -3932.1794,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   526.3375,   681.4379],\n",
      "        [-1208.0422,     0.0000,  1386.5448],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1355.4473,  -454.9099],\n",
      "        [-1212.1812,     0.0000,     0.0000],\n",
      "        [    0.0000, -3967.1243,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   529.1281,   684.5859],\n",
      "        [-2602.1670,     0.0000,  1392.8866],\n",
      "        [ 3793.4160,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1366.9128,  -454.5473],\n",
      "        [-2612.5647,     0.0000,     0.0000],\n",
      "        [ 3808.5830, -4000.6233,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1372.6864,   687.8129],\n",
      "        [    0.0000,     0.0000,  1399.3868],\n",
      "        [ 1617.2167, -4017.4856,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1378.7104,   689.5912],\n",
      "        [-1231.8944,     0.0000,  1402.9652],\n",
      "        [    0.0000, -4035.0779,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   691.6335],\n",
      "        [-1236.9031,     0.0000,  1407.0690],\n",
      "        [    0.0000, -3384.1169,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  1.3911e+03, -4.5335e+02],\n",
      "        [-1.2419e+03,  0.0000e+00,  1.6822e-13],\n",
      "        [ 4.6186e-13, -4.0712e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1397.3997,  -453.0322],\n",
      "        [-1247.0114,     0.0000,     0.0000],\n",
      "        [    0.0000, -4089.6831,     0.0000]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 14:14:12,868 - INFO - [0400] log_joint = -12462.211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   697.5587],\n",
      "        [-2678.4146,     0.0000,  1418.9792],\n",
      "        [ 3904.6506,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1409.7513,   699.5167],\n",
      "        [-1257.7477,     0.0000,  1422.9158],\n",
      "        [    0.0000, -4125.7725,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1415.8298,  -452.0960],\n",
      "        [-1263.3483,     0.0000,     0.0000],\n",
      "        [    0.0000, -4143.5303,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1422.1014,   703.6202],\n",
      "        [-1268.9125,     0.0000,  1431.1619],\n",
      "        [    0.0000, -4161.8496,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   545.9648,   705.7726],\n",
      "        [-1274.4445,     0.0000,  1435.4854],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1434.4294,   708.1511],\n",
      "        [    0.0000,     0.0000,  1440.2583],\n",
      "        [ 1694.9492, -4197.8486,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1440.5266,  -450.3495],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [ 1701.4215, -4215.6494,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1446.8040,  -449.9191],\n",
      "        [-1289.3804,     0.0000,     0.0000],\n",
      "        [    0.0000, -4233.9741,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1453.2369,   714.9031],\n",
      "        [    0.0000,     0.0000,  1453.8151],\n",
      "        [ 1714.8763, -4252.7544,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1459.8040,  -449.2114],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -4271.9258,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1466.4862,   718.9686],\n",
      "        [-1301.7499,     0.0000,  1461.9861],\n",
      "        [    0.0000, -4291.4326,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1473.2673,   721.1083],\n",
      "        [    0.0000,     0.0000,  1466.2842],\n",
      "        [ 1733.8680, -4311.2285,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1480.1324,   723.4779],\n",
      "        [    0.0000,     0.0000,  1471.0397],\n",
      "        [    0.0000, -4331.2695,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1487.0690,   726.0530],\n",
      "        [-1312.2623,     0.0000,  1476.2041],\n",
      "        [    0.0000, -4351.5190,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1494.0656,  -446.8423],\n",
      "        [-1315.6411,     0.0000,     0.0000],\n",
      "        [    0.0000, -4371.9438,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   565.3280,   731.2141],\n",
      "        [-2811.6060,     0.0000,  1486.5538],\n",
      "        [ 4098.8618,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1507.5431,   733.8194],\n",
      "        [    0.0000,     0.0000,  1491.7780],\n",
      "        [ 1762.9478, -4411.2808,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   736.6063],\n",
      "        [-1327.4508,     0.0000,  1497.3632],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1519.9833,   739.5557],\n",
      "        [-1331.4960,     0.0000,  1503.2717],\n",
      "        [    0.0000, -4447.5840,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1526.0508,   742.6506],\n",
      "        [-1335.6725,     0.0000,  1509.4694],\n",
      "        [    0.0000, -4465.2915,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1532.2661,  -442.7301],\n",
      "        [-1339.9669,     0.0000,     0.0000],\n",
      "        [    0.0000, -4483.4312,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1538.6094,   748.6994],\n",
      "        [    0.0000,     0.0000,  1521.5840],\n",
      "        [ 1794.1730, -4501.9448,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  5.7736e+02,  7.5168e+02],\n",
      "        [-2.8707e+03,  0.0000e+00,  1.5276e+03],\n",
      "        [ 4.1851e+03, -1.1091e-04,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1550.9587,   754.8109],\n",
      "        [    0.0000,     0.0000,  1533.8230],\n",
      "        [ 1807.9788, -4537.9814,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1557.0131,   758.0667],\n",
      "        [    0.0000,     0.0000,  1540.3401],\n",
      "        [ 1816.4224, -4555.6470,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1563.2058,  -438.7159],\n",
      "        [-2900.5811,     0.0000,     0.0000],\n",
      "        [ 4228.6621, -4573.7178,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1569.5188,  -437.9744],\n",
      "        [-1365.4299,     0.0000,     0.0000],\n",
      "        [    0.0000, -4592.1396,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1575.9360,  -437.3868],\n",
      "        [-2923.3379,     0.0000,     0.0000],\n",
      "        [ 4261.8921, -4610.8662,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1582.4429,   769.2266],\n",
      "        [-1375.1350,     0.0000,  1562.7023],\n",
      "        [    0.0000, -4629.8564,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   771.7004],\n",
      "        [-2948.1223,     0.0000,  1567.6637],\n",
      "        [ 4298.0752,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   591.1266,   774.3752],\n",
      "        [-2961.6951,     0.0000,  1573.0251],\n",
      "        [ 4317.8892,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1600.3846,   777.2298],\n",
      "        [    0.0000,     0.0000,  1578.7438],\n",
      "        [ 1891.1890, -4682.2139,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1606.0059,  -434.2991],\n",
      "        [-1397.5605,     0.0000,     0.0000],\n",
      "        [    0.0000, -4698.6143,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1611.7998,   782.8834],\n",
      "        [    0.0000,     0.0000,  1590.0708],\n",
      "        [ 1915.4563, -4715.5205,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1617.7448,  -432.9946],\n",
      "        [-3016.8462,     0.0000,     0.0000],\n",
      "        [ 4398.4224, -4732.8682,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1623.8209,  -432.4506],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [ 1939.7733, -4750.6001,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   790.3171],\n",
      "        [    0.0000,     0.0000,  1604.9786],\n",
      "        [    0.0000, -3913.7390,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1636.0276,   792.7007],\n",
      "        [-1422.7219,     0.0000,  1609.7600],\n",
      "        [    0.0000, -4786.2388,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1642.1621,  -430.9283],\n",
      "        [-1427.2131,     0.0000,     0.0000],\n",
      "        [    0.0000, -4804.1558,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1648.3992,  -430.4657],\n",
      "        [-1431.7626,     0.0000,     0.0000],\n",
      "        [    0.0000, -4822.3711,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1654.7256,   799.5236],\n",
      "        [-1436.3654,     0.0000,  1623.4520],\n",
      "        [    0.0000, -4840.8477,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1661.1293,   801.7460],\n",
      "        [-1441.0154,     0.0000,  1627.9128],\n",
      "        [    0.0000, -4859.5479,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1667.5992,   804.2006],\n",
      "        [    0.0000,     0.0000,  1632.8353],\n",
      "        [ 2006.0817, -4878.4409,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1674.1260,  -428.5094],\n",
      "        [-1449.9381,     0.0000,     0.0000],\n",
      "        [    0.0000, -4897.4995,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   613.9406,  -428.0198],\n",
      "        [-3126.5205,     0.0000,     0.0000],\n",
      "        [ 4558.5200,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1686.6982,   811.2023],\n",
      "        [    0.0000,     0.0000,  1646.8824],\n",
      "        [ 2028.4972, -4934.2046,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   813.4750],\n",
      "        [-1463.6188,     0.0000,  1651.4429],\n",
      "        [    0.0000, -4050.8862,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1698.7251,   815.9757],\n",
      "        [-1468.1193,     0.0000,  1656.4572],\n",
      "        [    0.0000, -4969.3257,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1704.7609,   818.6801],\n",
      "        [-1472.6761,     0.0000,  1661.8763],\n",
      "        [    0.0000, -4986.9570,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1710.8936,   821.5662],\n",
      "        [-3176.0967,     0.0000,  1667.6573],\n",
      "        [ 4630.8481, -5004.8701,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1717.1107,   824.6151],\n",
      "        [-1482.4567,     0.0000,  1673.7618],\n",
      "        [    0.0000, -5023.0293,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1723.4009,   827.8092],\n",
      "        [    0.0000,     0.0000,  1680.1554],\n",
      "        [ 2074.9194, -5041.3999,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1729.7542,  -422.6998],\n",
      "        [-3207.3816,     0.0000,     0.0000],\n",
      "        [ 4676.4810, -5059.9546,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1736.1615,   834.0556],\n",
      "        [-1497.4553,     0.0000,  1692.6595],\n",
      "        [    0.0000, -5078.6660,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   629.9156,  -421.1470],\n",
      "        [-3230.3071,     0.0000,     0.0000],\n",
      "        [ 4709.9336,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   631.4917,   839.8425],\n",
      "        [-3242.9915,     0.0000,  1704.2494],\n",
      "        [ 4728.4434,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1753.8733,   842.7313],\n",
      "        [    0.0000,     0.0000,  1710.0349],\n",
      "        [ 2123.3298, -5130.3706,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1759.4058,   845.7845],\n",
      "        [    0.0000,     0.0000,  1716.1473],\n",
      "        [ 2134.9575, -5146.5151,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   636.0621,   848.9847],\n",
      "        [-3283.2351,     0.0000,  1722.5525],\n",
      "        [ 4787.2002,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  1.7703e+03,  1.3006e-39],\n",
      "        [-3.2974e+03,  0.0000e+00,  1.6944e+03],\n",
      "        [ 4.8078e+03, -5.1782e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1775.6190,   855.6201],\n",
      "        [-1536.0602,     0.0000,  1735.8362],\n",
      "        [    0.0000, -5193.8203,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   859.0445],\n",
      "        [-3326.8105,     0.0000,  1742.6931],\n",
      "        [ 4850.8359, -4242.6626,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1786.5199,  -414.5315],\n",
      "        [-3342.1052,     0.0000,     0.0000],\n",
      "        [ 4873.1694, -5225.6411,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1792.0568,   865.6901],\n",
      "        [-1554.4360,     0.0000,  1756.0002],\n",
      "        [    0.0000, -5241.8101,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1797.7271,   868.9456],\n",
      "        [-3373.4226,     0.0000,  1762.5186],\n",
      "        [ 4918.8936, -5258.3687,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1803.5142,   872.3279],\n",
      "        [-1567.3435,     0.0000,  1769.2891],\n",
      "        [    0.0000, -5275.2671,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1809.4038,   875.8242],\n",
      "        [-1573.7556,     0.0000,  1776.2860],\n",
      "        [    0.0000, -5292.4648,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1815.3828,   879.4223],\n",
      "        [-1579.9905,     0.0000,  1783.4847],\n",
      "        [    0.0000, -5309.9233,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1821.4397,  -409.0281],\n",
      "        [-3431.2146,     0.0000,     0.0000],\n",
      "        [ 5003.2373, -5327.6089,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1827.5645,  -408.1588],\n",
      "        [-3445.3796,     0.0000,     0.0000],\n",
      "        [ 5023.9062, -5345.4922,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1833.7480,  -407.4437],\n",
      "        [-3460.5725,     0.0000,     0.0000],\n",
      "        [ 5046.0791, -5363.5474,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1839.9823,   891.7488],\n",
      "        [-1606.1323,     0.0000,  1808.1652],\n",
      "        [    0.0000, -5381.7495,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   657.5901,   894.4729],\n",
      "        [-3491.5864,     0.0000,  1813.6232],\n",
      "        [ 5091.3403,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1851.9835,  -405.4611],\n",
      "        [-1619.7943,     0.0000,     0.0000],\n",
      "        [    0.0000, -5416.7837,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1857.8052,   899.9398],\n",
      "        [-1626.5017,     0.0000,  1824.5751],\n",
      "        [    0.0000, -5433.7759,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1863.7129,  -404.1725],\n",
      "        [-3535.8406,     0.0000,     0.0000],\n",
      "        [ 5155.9116, -5451.0200,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1869.6960,   905.1228],\n",
      "        [-1639.7428,     0.0000,  1834.9617],\n",
      "        [    0.0000, -5468.4849,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1875.7449,   907.7647],\n",
      "        [-1646.2693,     0.0000,  1840.2550],\n",
      "        [    0.0000, -5486.1416,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1881.8505,     0.0000],\n",
      "        [-3577.1191,     0.0000,  1782.1162],\n",
      "        [ 5216.1255, -5503.9644,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1888.0059,   913.4634],\n",
      "        [-3591.0654,     0.0000,  1851.6735],\n",
      "        [ 5236.4692, -5521.9326,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[ 0.0000e+00,  1.8942e+03,  9.1650e+02],\n",
      "        [-6.6791e-11,  0.0000e+00,  1.8578e+03],\n",
      "        [ 2.4130e+03, -5.5400e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1900.4374,   919.6854],\n",
      "        [-1672.2123,     0.0000,  1864.1379],\n",
      "        [    0.0000, -5558.2227,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1906.7025,   923.0126],\n",
      "        [-1678.2106,     0.0000,  1870.7992],\n",
      "        [    0.0000, -5576.5117,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1912.9939,  -398.2602],\n",
      "        [-3645.6658,     0.0000,     0.0000],\n",
      "        [ 5316.1367, -5594.8784,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1919.3075,  -397.4875],\n",
      "        [-3659.1592,     0.0000,     0.0000],\n",
      "        [ 5335.8242, -5613.3096,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1925.6393,  -396.8556],\n",
      "        [-3673.6624,     0.0000,     0.0000],\n",
      "        [ 5356.9893, -5631.7949,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1931.9863,  -396.3504],\n",
      "        [-3689.0408,     0.0000,     0.0000],\n",
      "        [ 5379.4341, -5650.3247,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1938.3451,   936.5942],\n",
      "        [-1710.3052,     0.0000,  1898.0171],\n",
      "        [    0.0000, -5668.8887,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,   938.9111],\n",
      "        [-3720.1411,     0.0000,  1902.6648],\n",
      "        [ 5424.8242, -4597.5547,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1950.8364,   941.4623],\n",
      "        [    0.0000,     0.0000,  1907.7781],\n",
      "        [ 2518.8665, -5705.3682,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1956.9929,   944.2225],\n",
      "        [-3750.7788,     0.0000,  1913.3074],\n",
      "        [ 5469.5454, -5723.3540,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   688.5905,   947.1697],\n",
      "        [-3766.4482,     0.0000,  1919.2080],\n",
      "        [ 5492.4219,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1968.8141,  -392.5713],\n",
      "        [-3782.8030,     0.0000,     0.0000],\n",
      "        [ 5516.3003, -5757.8779,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1974.5343,   953.0272],\n",
      "        [    0.0000,     0.0000,  1930.9354],\n",
      "        [ 2574.1130, -5774.5815,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1980.3286,   955.9599],\n",
      "        [    0.0000,     0.0000,  1936.8068],\n",
      "        [ 2588.3933, -5791.5005,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1986.1873,  -390.2712],\n",
      "        [-3830.6997,     0.0000,     0.0000],\n",
      "        [ 5586.2485, -5808.6069,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1992.1028,  -389.5762],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [ 2616.6858, -5825.8799,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  1998.0675,   964.1961],\n",
      "        [-3861.3157,     0.0000,  1953.3007],\n",
      "        [ 5630.9736, -5843.2959,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2004.0747,   966.8245],\n",
      "        [    0.0000,     0.0000,  1958.5656],\n",
      "        [ 2645.2485, -5860.8354,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2010.1189,   969.6554],\n",
      "        [-3891.6387,     0.0000,  1964.2333],\n",
      "        [ 5675.2783, -5878.4834,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2016.1947,   972.6672],\n",
      "        [-1789.3787,     0.0000,  1970.2607],\n",
      "        [    0.0000, -5896.2236,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2022.2976,   975.8405],\n",
      "        [    0.0000,     0.0000,  1976.6096],\n",
      "        [ 2687.2000, -5914.0420,     0.0000]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 14:14:14,688 - INFO - [0500] log_joint = -30250.166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2028.4237,  -384.9796],\n",
      "        [-3935.0645,     0.0000,     0.0000],\n",
      "        [ 5738.7217, -5931.9287,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2034.5691,   982.0875],\n",
      "        [-1804.8124,     0.0000,  1989.1088],\n",
      "        [    0.0000, -5949.8711,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2040.7306,   985.1879],\n",
      "        [-3962.9946,     0.0000,  1995.3124],\n",
      "        [ 5779.5215, -5967.8613,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2046.9056,  -382.4166],\n",
      "        [-3977.3335,     0.0000,     0.0000],\n",
      "        [ 5800.4639, -5985.8901,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2053.0916,   991.3132],\n",
      "        [    0.0000,     0.0000,  2007.5682],\n",
      "        [ 2752.4519, -6003.9507,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2059.2854,   994.3631],\n",
      "        [-1826.5172,     0.0000,  2013.6705],\n",
      "        [    0.0000, -6022.0352,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2065.4861,   997.5717],\n",
      "        [-4019.9688,     0.0000,  2020.0889],\n",
      "        [ 5862.7368, -6040.1396,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2071.6917,  -378.9382],\n",
      "        [-1837.1575,     0.0000,     0.0000],\n",
      "        [    0.0000, -6058.2573,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2077.9001,  1003.8824],\n",
      "        [-4047.2783,     0.0000,  2032.7129],\n",
      "        [ 5902.6162, -6076.3843,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2084.1106,  1007.0118],\n",
      "        [-4061.3262,     0.0000,  2038.9733],\n",
      "        [ 5923.1260, -6094.5161,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2090.3215,  -376.3118],\n",
      "        [-4076.1475,     0.0000,     0.0000],\n",
      "        [ 5944.7676, -6112.6504,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2096.5317,  -375.5232],\n",
      "        [-4091.6428,     0.0000,     0.0000],\n",
      "        [ 5967.3926, -6130.7822,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2102.7410,  -374.8696],\n",
      "        [-1866.9120,     0.0000,     0.0000],\n",
      "        [    0.0000, -6148.9102,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2108.9470,  -374.3375],\n",
      "        [-4122.6152,     0.0000,     0.0000],\n",
      "        [ 6012.6128, -6167.0303,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2115.1506,  1019.9572],\n",
      "        [-4138.1528,     0.0000,  2064.8948],\n",
      "        [ 6035.2969, -6185.1421,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2121.3501,  1022.2008],\n",
      "        [-1886.2075,     0.0000,  2069.3914],\n",
      "        [    0.0000, -6203.2427,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2127.5454,  -372.7521],\n",
      "        [-4169.1577,     0.0000,     0.0000],\n",
      "        [ 6080.5581, -6221.3311,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2133.7356,  1026.8800],\n",
      "        [-1899.1471,     0.0000,  2078.7664],\n",
      "        [    0.0000, -6239.4038,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2139.9204,  -371.6281],\n",
      "        [-4199.0771,     0.0000,     0.0000],\n",
      "        [ 6124.2285, -6257.4619,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2146.0996,  1031.4666],\n",
      "        [-1911.9702,     0.0000,  2087.9565],\n",
      "        [    0.0000, -6275.5029,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   738.3713,  1033.8699],\n",
      "        [-4228.1143,     0.0000,  2092.7705],\n",
      "        [ 6166.6055,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   739.8958,  1036.5039],\n",
      "        [-4242.8037,     0.0000,  2098.0439],\n",
      "        [ 6188.0430,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2163.0137,  1039.3439],\n",
      "        [-4258.1226,     0.0000,  2103.7275],\n",
      "        [ 6210.4009, -6324.8711,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2168.2419,  1042.3679],\n",
      "        [-4273.9902,     0.0000,  2109.7773],\n",
      "        [ 6233.5635, -6340.1265,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2173.5649,  1045.5562],\n",
      "        [-4290.3350,     0.0000,  2116.1538],\n",
      "        [ 6257.4214, -6355.6611,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2178.9722,  1048.8907],\n",
      "        [-4307.0952,     0.0000,  2122.8218],\n",
      "        [ 6281.8877, -6371.4404,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2184.4529,  1052.3566],\n",
      "        [    0.0000,     0.0000,  2129.7507],\n",
      "        [ 3036.9583, -6387.4365,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  1055.9388],\n",
      "        [-4340.2529,     0.0000,  2136.9119],\n",
      "        [ 6330.2983, -5130.5283,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2195.3582,  1059.6259],\n",
      "        [-4356.7256,     0.0000,  2144.2810],\n",
      "        [ 6354.3516, -6419.2773,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2200.7952,  1063.4061],\n",
      "        [-1979.0590,     0.0000,  2151.8359],\n",
      "        [    0.0000, -6435.1572,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2206.2998,  1067.2697],\n",
      "        [-4389.1348,     0.0000,  2159.5564],\n",
      "        [ 6401.6699, -6451.2349,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2211.8645,  1071.2075],\n",
      "        [-4405.1675,     0.0000,  2167.4248],\n",
      "        [ 6425.0771, -6467.4863,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2217.4817,  -358.3589],\n",
      "        [-4421.6128,     0.0000,     0.0000],\n",
      "        [ 6449.0874, -6483.8916,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2223.1455,  -357.2924],\n",
      "        [-4438.4160,     0.0000,     0.0000],\n",
      "        [ 6473.6201, -6500.4312,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2228.8496,  -356.3827],\n",
      "        [-4455.5303,     0.0000,     0.0000],\n",
      "        [ 6498.6079, -6517.0894,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2234.5889,  -355.6143],\n",
      "        [-4472.9121,     0.0000,     0.0000],\n",
      "        [ 6523.9863, -6533.8486,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2240.3589,  -354.9732],\n",
      "        [-4490.5254,     0.0000,     0.0000],\n",
      "        [ 6549.7026, -6550.6982,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  1089.3438],\n",
      "        [-4508.3364,     0.0000,  2203.7004],\n",
      "        [ 6575.7090, -5253.6221,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2251.7336,  -353.8190],\n",
      "        [-4526.3154,     0.0000,     0.0000],\n",
      "        [ 6601.9604, -6583.9248,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2257.3579,  -353.3044],\n",
      "        [-4544.4385,     0.0000,     0.0000],\n",
      "        [ 6628.4224, -6600.3589,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2263.0229,  1095.7797],\n",
      "        [-4562.6807,     0.0000,  2216.5962],\n",
      "        [ 6655.0586, -6616.9097,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2268.7229,  -352.3651],\n",
      "        [-4581.0234,     0.0000,     0.0000],\n",
      "        [ 6681.8418, -6633.5620,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2274.4543,  1099.8433],\n",
      "        [-4599.4497,     0.0000,  2224.7415],\n",
      "        [ 6708.7471, -6650.3037,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2280.2119,  1102.0308],\n",
      "        [-4617.9424,     0.0000,  2229.1238],\n",
      "        [ 6735.7490, -6667.1221,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2285.9924,  1104.4752],\n",
      "        [-4636.4883,     0.0000,  2234.0181],\n",
      "        [ 6762.8291, -6684.0068,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2291.7932,  1107.1490],\n",
      "        [-4655.0757,     0.0000,  2239.3691],\n",
      "        [ 6789.9702, -6700.9492,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2297.6106,  1110.0273],\n",
      "        [-4673.6934,     0.0000,  2245.1272],\n",
      "        [ 6817.1553, -6717.9395,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2303.4421,  -348.3607],\n",
      "        [-4692.3320,     0.0000,     0.0000],\n",
      "        [ 6844.3706, -6734.9707,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2309.2859,  -347.6189],\n",
      "        [-4710.9834,     0.0000,     0.0000],\n",
      "        [ 6871.6045, -6752.0371,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2315.1396,  1118.1896],\n",
      "        [-4729.6406,     0.0000,  2261.4597],\n",
      "        [ 6898.8472, -6769.1318,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2321.0015,  1120.8174],\n",
      "        [-4748.2969,     0.0000,  2266.7190],\n",
      "        [ 6926.0884, -6786.2500,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2326.8699,  -345.4951],\n",
      "        [-4766.9463,     0.0000,     0.0000],\n",
      "        [ 6953.3203, -6803.3872,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2332.7432,  1126.1638],\n",
      "        [-4785.5840,     0.0000,  2277.4175],\n",
      "        [ 6980.5347, -6820.5381,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2338.6204,  1128.8956],\n",
      "        [-4804.2075,     0.0000,  2282.8833],\n",
      "        [ 7007.7275, -6837.7002,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2344.5002,     0.0000],\n",
      "        [-4822.8105,     0.0000,  2110.4397],\n",
      "        [ 7034.8916, -6854.8696,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2350.3818,  1134.7604],\n",
      "        [-4841.3916,     0.0000,  2294.6211],\n",
      "        [ 7062.0234, -6872.0435,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2356.2639,  1137.8716],\n",
      "        [-4859.9473,     0.0000,  2300.8489],\n",
      "        [ 7089.1172, -6889.2192,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2362.1460,  1141.1416],\n",
      "        [-4878.4751,     0.0000,  2307.3918],\n",
      "        [ 7116.1714, -6906.3955,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   794.4024,  1144.5533],\n",
      "        [-4896.9727,     0.0000,  2314.2168],\n",
      "        [ 7143.1807,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2373.3799,  1148.0914],\n",
      "        [    0.0000,     0.0000,  2321.2925],\n",
      "        [ 3554.7290, -6939.1914,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2378.7874,  1151.7426],\n",
      "        [    0.0000,     0.0000,  2328.5928],\n",
      "        [ 3570.1648, -6954.9771,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2384.2437,  1155.4943],\n",
      "        [-4948.6841,     0.0000,  2336.0928],\n",
      "        [ 7218.7017, -6970.9053,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2389.7429,  1159.3362],\n",
      "        [-4964.9697,     0.0000,  2343.7722],\n",
      "        [ 7242.4893, -6986.9575,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   801.7070,  1163.2583],\n",
      "        [-4981.4585,     0.0000,  2351.6106],\n",
      "        [ 7266.5718,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2400.3210,  1167.2523],\n",
      "        [-4998.1240,     0.0000,  2359.5918],\n",
      "        [ 7290.9126, -7017.8325,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,   804.4943,  1171.3101],\n",
      "        [-5014.9404,     0.0000,  2367.7000],\n",
      "        [ 7315.4727,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2410.1208,  1175.4250],\n",
      "        [-5031.8882,     0.0000,  2375.9216],\n",
      "        [ 7340.2236, -7046.4287,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2414.9185,  -329.2102],\n",
      "        [-5048.9473,     0.0000,     0.0000],\n",
      "        [ 7365.1367, -7060.4263,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2419.8269,  1183.3010],\n",
      "        [-5066.1011,     0.0000,  2391.6582],\n",
      "        [ 7390.1875, -7074.7500,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2424.8337,  -326.9133],\n",
      "        [-5083.3340,     0.0000,     0.0000],\n",
      "        [ 7415.3545, -7089.3594,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2429.9272,  1190.4897],\n",
      "        [-5100.6338,     0.0000,  2406.0256],\n",
      "        [ 7440.6172, -7104.2256,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2435.0989,  1194.0040],\n",
      "        [-5117.9878,     0.0000,  2413.0496],\n",
      "        [ 7465.9590, -7119.3184,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2440.3386,  1197.6338],\n",
      "        [-5135.3862,     0.0000,  2420.3032],\n",
      "        [ 7491.3667, -7134.6118,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2445.6389,  -322.5848],\n",
      "        [-5152.8188,     0.0000,     0.0000],\n",
      "        [ 7516.8228, -7150.0820,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2450.9932,  1204.6884],\n",
      "        [-5170.2783,     0.0000,  2434.4021],\n",
      "        [ 7542.3188, -7165.7104,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2456.3945,  1208.1461],\n",
      "        [-5187.7583,     0.0000,  2441.3127],\n",
      "        [ 7567.8423, -7181.4771,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2461.8376,  1211.7260],\n",
      "        [-5205.2510,     0.0000,  2448.4663],\n",
      "        [ 7593.3857, -7197.3657,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2467.3171,  1215.4146],\n",
      "        [-5222.7490,     0.0000,  2455.8364],\n",
      "        [ 7618.9380, -7213.3613,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2472.8289,  1219.2003],\n",
      "        [-2324.8325,     0.0000,  2463.3999],\n",
      "        [    0.0000, -7229.4512,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2478.3684,  1223.0726],\n",
      "        [-5256.3447,     0.0000,  2471.1357],\n",
      "        [ 7667.9902, -7245.6226,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,     0.0000,  1227.0223],\n",
      "        [-5272.5894,     0.0000,  2479.0256],\n",
      "        [ 7691.7080, -5770.7573,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2489.2847,  1231.0411],\n",
      "        [-5288.9673,     0.0000,  2487.0530],\n",
      "        [ 7715.6196, -7277.5020,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2494.6802,  1235.1215],\n",
      "        [-5305.4585,     0.0000,  2495.2024],\n",
      "        [ 7739.6963, -7293.2637,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2500.1143,  1239.2567],\n",
      "        [-5322.0464,     0.0000,  2503.4617],\n",
      "        [ 7763.9155, -7309.1367,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2505.5825,  1243.4408],\n",
      "        [-5338.7178,     0.0000,  2511.8179],\n",
      "        [ 7788.2559, -7325.1084,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2511.0801,  1247.6688],\n",
      "        [-5355.4585,     0.0000,  2520.2617],\n",
      "        [ 7812.6982, -7341.1665,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2516.6042,  1251.9355],\n",
      "        [-5372.2578,     0.0000,  2528.7822],\n",
      "        [ 7837.2261, -7357.2993,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2522.1506,  1256.2371],\n",
      "        [-5389.1045,     0.0000,  2537.3721],\n",
      "        [ 7861.8237, -7373.4985,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2527.7166,  1260.5693],\n",
      "        [-5405.9912,     0.0000,  2546.0232],\n",
      "        [ 7886.4795, -7389.7534,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2533.2998,  1264.9294],\n",
      "        [-5422.9097,     0.0000,  2554.7295],\n",
      "        [ 7911.1812, -7406.0591,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2538.8972,  1269.3137],\n",
      "        [-5439.8506,     0.0000,  2563.4844],\n",
      "        [ 7935.9170, -7422.4053,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2544.5076,  1273.7200],\n",
      "        [-5456.8105,     0.0000,  2572.2825],\n",
      "        [ 7960.6792, -7438.7886,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2550.1279,  1278.1456],\n",
      "        [-5473.7822,     0.0000,  2581.1191],\n",
      "        [ 7985.4600, -7455.2021,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2555.7576,  1282.5885],\n",
      "        [-5490.7617,     0.0000,  2589.9900],\n",
      "        [ 8010.2510, -7471.6406,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2561.3945,  1287.0469],\n",
      "        [-5507.7441,     0.0000,  2598.8916],\n",
      "        [ 8035.0479, -7488.1011,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2567.0374,  1291.5184],\n",
      "        [-5524.7261,     0.0000,  2607.8198],\n",
      "        [ 8059.8413, -7504.5791,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2572.6853,  1296.0022],\n",
      "        [-5541.7036,     0.0000,  2616.7722],\n",
      "        [ 8084.6309, -7521.0713,     0.0000]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 14:14:16,476 - INFO - [0600] log_joint = -56269.801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2578.3372,  1300.4967],\n",
      "        [-5558.6729,     0.0000,  2625.7456],\n",
      "        [ 8109.4087, -7537.5728,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2583.9912,  1305.0002],\n",
      "        [-5575.6323,     0.0000,  2634.7373],\n",
      "        [ 8134.1704, -7554.0830,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2589.6472,  1309.5123],\n",
      "        [-5592.5811,     0.0000,  2643.7454],\n",
      "        [ 8158.9170, -7570.5986,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Grad_theta shape: torch.Size([3, 3]), values: \n",
      " tensor([[    0.0000,  2595.3049,  1314.0317],\n",
      "        [-5609.5156,     0.0000,  2652.7683],\n",
      "        [ 8183.6426, -7587.1187,     0.0000]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "def basic_training_loop():\n",
    "\n",
    "    def init_particle(d: int, k: int, device: str) -> dict:\n",
    "        return {\n",
    "            'z': torch.randn(d, k, 2, device=device),\n",
    "            'theta': torch.randn(d, d, device=device)\n",
    "        }\n",
    "\n",
    "    particle = init_particle(cfg.d_nodes, cfg.k_latent, cfg.device)\n",
    "\n",
    "    # Hparams dictionary, as used by the model functions\n",
    "    sigma_z = (1.0 / math.sqrt(cfg.k_latent))\n",
    "    hparams = {\n",
    "    \"alpha\": cfg.alpha_val,\n",
    "    \"beta\": cfg.beta_val,\n",
    "    \"alpha_base\":cfg.alpha_val,\n",
    "    \"beta_base\": cfg.beta_val,\n",
    "    \"tau\": cfg.tau_val,\n",
    "    \"sigma_z\": sigma_z,\n",
    "    \"sigma_obs_noise\": cfg.synthetic_obs_noise_std,\n",
    "    \"theta_prior_sigma\": cfg.theta_prior_sigma_val,\n",
    "    \"n_grad_mc_samples\": cfg.n_grad_mc_samples,\n",
    "    \"n_nongrad_mc_samples\": cfg.n_nongrad_mc_samples,\n",
    "    \"d\": cfg.d_nodes,\n",
    "    \"debug_print_iter\": cfg.debug_print_iter\n",
    "}\n",
    "\n",
    "    # Initialize PyTorch optimizers for z and theta parameters\n",
    "    optimizer_z = torch.optim.Adam([particle['z']], lr=cfg.lr)\n",
    "    optimizer_theta = torch.optim.Adam([particle['theta']], lr=cfg.lr)\n",
    "\n",
    "    # Training loop using PyTorch optimizers with gradient hooking\n",
    "    for t in range(1, cfg.num_iterations + 1):\n",
    "        hparams = update_dibs_hparams(hparams, t)\n",
    "        \n",
    "        # Clear gradients using optimizers\n",
    "        optimizer_z.zero_grad()\n",
    "        optimizer_theta.zero_grad()\n",
    "        \n",
    "        # Set requires_grad for the particles\n",
    "        particle['z'].requires_grad_(True)\n",
    "        particle['theta'].requires_grad_(True)\n",
    "\n",
    "        # Get gradients of the log-joint\n",
    "        params_for_grad = {\"z\": particle['z'], \"theta\": particle['theta'], \"t\": torch.tensor(float(t))}\n",
    "        grads = grad_log_joint(params_for_grad, data, hparams)\n",
    "\n",
    "        # Hook gradients into PyTorch's gradient system\n",
    "        # This is crucial: assign the computed gradients to .grad attributes\n",
    "        particle['z'].grad = grads['z']\n",
    "        particle['theta'].grad = grads['theta']\n",
    "\n",
    "        # Use PyTorch optimizers to update parameters\n",
    "        optimizer_z.step()\n",
    "        optimizer_theta.step()\n",
    "\n",
    "        # Logging\n",
    "        if t % 100 == 0 or t == cfg.num_iterations:\n",
    "            lj_val = log_joint(params_for_grad, data, hparams).item()\n",
    "\n",
    "\n",
    "            log.info(f\"[{t:04d}] log_joint = {lj_val:.3f}\")        \n",
    "            mlflow.log_metric(\"log_joint\", lj_val, step=t)\n",
    "\n",
    "\n",
    "basic_training_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a95b7b",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b3f7c750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 14:14:32,388 - INFO - MLflow run finished and artifacts logged.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_graph = hard_gmat_from_z(particle['z'], hparams['alpha']).detach().cpu()\n",
    "edge_probs = bernoulli_soft_gmat(particle['z'], hparams).detach().cpu()\n",
    "\n",
    "# --- Create and Log Visualization ---\n",
    "def plot_graphs(g_true, g_learned, probs, filename=\"graph_comparison.png\"):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    g_true_nx = nx.from_numpy_array(g_true.numpy(), create_using=nx.DiGraph)\n",
    "    g_learned_nx = nx.from_numpy_array(g_learned.numpy(), create_using=nx.DiGraph)\n",
    "    pos = nx.spring_layout(g_true_nx, seed=cfg.seed)\n",
    "\n",
    "    # Ground Truth Graph\n",
    "    nx.draw(g_true_nx, pos, with_labels=True, ax=axes[0], node_color='skyblue', node_size=700, edge_color='k')\n",
    "    axes[0].set_title(\"Ground Truth Graph\")\n",
    "\n",
    "    # Learned Graph\n",
    "    nx.draw(g_learned_nx, pos, with_labels=True, ax=axes[1], node_color='lightgreen', node_size=700, edge_color='k')\n",
    "    axes[1].set_title(\"Learned Hard Graph\")\n",
    "\n",
    "    # Edge Probabilities\n",
    "    g_probs_nx = nx.from_numpy_array(probs.numpy(), create_using=nx.DiGraph)\n",
    "    edge_labels = {(i, j): f\"{probs[i,j]:.2f}\" for i,j in g_probs_nx.edges()}\n",
    "    nx.draw(g_probs_nx, pos, with_labels=True, ax=axes[2], node_color='lightcoral', node_size=700, connectionstyle='arc3,rad=0.1')\n",
    "    nx.draw_networkx_edge_labels(g_probs_nx, pos, edge_labels=edge_labels, ax=axes[2])\n",
    "    axes[2].set_title(\"Learned Edge Probabilities\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "    return filename\n",
    "\n",
    "# Generate, show, and get filename of the plot\n",
    "plot_filename = plot_graphs(graph_adj, final_graph.int(), edge_probs)\n",
    "\n",
    "# --- Log Artifacts to MLflow ---\n",
    "mlflow.log_artifact(plot_filename)\n",
    "# Log the notebook itself for full reproducibility\n",
    "mlflow.log_artifact(\"dibs_experiment.ipynb\", artifact_path=\"notebook_code\")\n",
    "\n",
    "# End the MLflow run\n",
    "mlflow.end_run()\n",
    "log.info(\"MLflow run finished and artifacts logged.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa43d6e3",
   "metadata": {},
   "source": [
    "# Enhanced traning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f2b01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:42:44,429 - INFO - \n",
      "================================================================================\n",
      "2025-06-17 11:42:44,430 - INFO - STARTING ENHANCED TRAINING LOOP WITH DETAILED MONITORING\n",
      "2025-06-17 11:42:44,430 - INFO - ================================================================================\n",
      "2025-06-17 11:42:44,431 - INFO - Enhanced Training Configuration:\n",
      "2025-06-17 11:42:44,431 - INFO -   Iterations: 2000\n",
      "2025-06-17 11:42:44,431 - INFO -   Learning rates - Z: 0.005, Theta: 0.005\n",
      "2025-06-17 11:42:44,432 - INFO -   Gradient clipping threshold: 10000\n",
      "2025-06-17 11:42:44,432 - INFO -   Logging interval: 50\n",
      "2025-06-17 11:42:44,433 - INFO -   Initial Z norm: 4.4058\n",
      "2025-06-17 11:42:44,433 - INFO -   Initial Theta norm: 3.3477\n",
      "2025-06-17 11:42:44,480 - INFO - Iter 1: Z_norm=4.4150, Theta_norm=3.3473, log_joint=-1770.1501, grad_Z_norm=3.4762e+01, grad_Theta_norm=5.3832e+02\n",
      "2025-06-17 11:42:44,481 - INFO -     grad_Theta (sample from iter 1):\n",
      "2025-06-17 11:42:44,482 - INFO - tensor([[ 0.0000e+00,  0.0000e+00, -4.3504e-17],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -5.3832e+02,  0.0000e+00]])\n",
      "2025-06-17 11:42:44,482 - INFO -     Annealed: alpha=0.100, beta=1.001, tau=1.000\n",
      "2025-06-17 11:42:44,482 - INFO -     Current Edge Probs (from Z, alpha=0.100):\n",
      "2025-06-17 11:42:44,483 - INFO - tensor([[0.0000, 0.5339, 0.5406],\n",
      "        [0.4752, 0.0000, 0.4528],\n",
      "        [0.4716, 0.4710, 0.0000]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.3504e-17],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -5.3832e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.5060e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.5667e-37],\n",
      "        [ 0.0000e+00, -5.4475e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -451.1671],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000, -551.1616,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.1736e-18],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -5.5760e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -3.5949e-19],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -5.6404e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.5626e-20],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -5.7048e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -9.7989e-21],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -5.7692e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.5356e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.2144e-34],\n",
      "        [ 0.0000e+00, -5.8336e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -8.9438e-22],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -5.8983e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -454.4486],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000, -596.2930,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -5.8431e-23],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -6.0277e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.0134e-23],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -6.0927e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -9.0470e-24],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -6.1579e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000, -622.2899,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000, -628.8425,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -2.0625e-27],\n",
      "        [ 0.0000e+00,  0.0000e+00, -9.4968e+02],\n",
      "        [ 0.0000e+00, -6.2533e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.5340e-25],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -6.4193e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.9574e-25],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -6.4853e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000, -655.1062,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000, -661.7412,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -2.3489e-26],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -6.6837e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000, -675.0278,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.5829e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.8477e-33],\n",
      "        [ 0.0000e+00, -6.8169e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -3.9763e-28],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -6.8838e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000, -695.1122,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.6076e-28],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -7.0184e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.5938e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -6.3959e-34],\n",
      "        [ 0.0000e+00, -7.0861e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -459.7462],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000, -715.3916,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -460.2053],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000, -722.1720,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -7.3438e-30],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -7.2902e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.0073e-31],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -7.3587e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -3.3331e-32],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -7.4273e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -388.2055],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000, -629.6661,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -6.2979e-33],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -7.5647e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.6312e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -6.5896e-31],\n",
      "        [ 0.0000e+00, -7.6335e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -2.2697e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00, -5.5404e-38],\n",
      "        [ 0.0000e+00, -3.7704e-05,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000, -776.5469,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.8176e-35],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -7.8292e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -3.3251e-12],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -5.6450e-12,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.7084e-36],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -7.9535e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.5297e-37],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -8.0146e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -2.4018e-37],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -8.0768e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -6.8339e-38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -8.1405e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000, -820.5663,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.6663e-38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -8.2717e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000, -833.8821,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -8.8366e-29],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -1.5900e-28,  0.0000e+00]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:42:46,992 - INFO - Iter 50: Z_norm=4.9715, Theta_norm=3.3439, log_joint=-2024.9127, grad_Z_norm=3.3862e+01, grad_Theta_norm=8.5967e+02\n",
      "2025-06-17 11:42:46,993 - INFO -     grad_Theta (sample from iter 50):\n",
      "2025-06-17 11:42:46,994 - INFO - tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000, -859.6741,    0.0000]])\n",
      "2025-06-17 11:42:46,994 - INFO -     Annealed: alpha=0.100, beta=1.050, tau=1.000\n",
      "2025-06-17 11:42:46,995 - INFO -     Current Edge Probs (from Z, alpha=0.100):\n",
      "2025-06-17 11:42:46,995 - INFO - tensor([[0.0000, 0.5609, 0.5728],\n",
      "        [0.5097, 0.0000, 0.4567],\n",
      "        [0.4850, 0.4508, 0.0000]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -2.0133e-39],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -8.4684e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -2.4844e-39],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -8.5321e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000, -859.6741,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.3109e-41],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -8.6410e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.2950e-40],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -5.0206e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.6806e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.2383e-26],\n",
      "        [ 0.0000e+00, -3.8715e+01,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -9.5348e-37],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -8.8563e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.7146e-40],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -3.6007e-04,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -5.5686e-33],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -9.0259e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -8.5465e-42],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -5.4512e-08,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.0522e-41],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -3.3060e-09,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.6949e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.4053e-24],\n",
      "        [ 0.0000e+00, -1.3616e-10,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.9758e-42],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.3172e-42],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.3172e-42],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -1.8742e-13,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -1.4063e-15,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.2196e-24],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -9.3688e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -9.4952e-24],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -9.4299e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -1.0026e-19,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -1.8885e-20,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.7170e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -4.4113e-22],\n",
      "        [ 0.0000e+00, -5.5043e-22,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -7.7992e-23,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -1.7608e-23,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -2.4298e-24,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.2691e-18],\n",
      "        [ 0.0000e+00,  0.0000e+00, -4.4002e-41],\n",
      "        [ 0.0000e+00, -9.6354e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -8.7023e-19],\n",
      "        [ 0.0000e+00,  0.0000e+00, -2.0626e-40],\n",
      "        [ 0.0000e+00, -9.6612e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -3.7992e-28,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -6.5692e-16],\n",
      "        [ 0.0000e+00,  0.0000e+00, -2.9094e-37],\n",
      "        [ 0.0000e+00, -9.7526e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -6.3321e-31,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.6245e-13],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -9.8470e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -1.3083e-36,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.7417e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -5.6623e-19],\n",
      "        [ 0.0000e+00, -5.4219e-37,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -2.3032e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -1.0054e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -9.9445e-40,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -1.4726e-40,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -2.5543e-41,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -6.8401e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00, -5.0226e-24],\n",
      "        [ 0.0000e+00, -1.0146e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:42:49,399 - INFO - Iter 100: Z_norm=5.6817, Theta_norm=3.3499, log_joint=-2215.7549, grad_Z_norm=6.1537e+01, grad_Theta_norm=1.0263e+03\n",
      "2025-06-17 11:42:49,400 - INFO -     grad_Theta (sample from iter 100):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.1587e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.2700e-19],\n",
      "        [ 0.0000e+00, -1.0263e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:42:49,401 - INFO - tensor([[ 0.0000e+00,  0.0000e+00, -1.1587e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.2700e-19],\n",
      "        [ 0.0000e+00, -1.0263e+03,  0.0000e+00]])\n",
      "2025-06-17 11:42:49,401 - INFO -     Annealed: alpha=0.100, beta=1.100, tau=1.000\n",
      "2025-06-17 11:42:49,402 - INFO -     Current Edge Probs (from Z, alpha=0.100):\n",
      "2025-06-17 11:42:49,403 - INFO - tensor([[0.0000, 0.5994, 0.6200],\n",
      "        [0.5491, 0.0000, 0.4670],\n",
      "        [0.5037, 0.4338, 0.0000]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.4698e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -1.0284e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.9623e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.1239e-17],\n",
      "        [ 0.0000e+00, -9.9045e+02,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.7655e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.1689e-15],\n",
      "        [ 0.0000e+00, -5.9695e-03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.7757e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -2.0195e-14],\n",
      "        [ 0.0000e+00, -9.6557e-05,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.7794e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -9.0587e-05,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -478.4817],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.7914e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -2.3223e-04,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -480.4899],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,   -6.9002,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.7259e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -6.4985e-04],\n",
      "        [ 0.0000e+00, -2.7689e+01,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,    -9.3153],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -1055.8066,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,   -24.4306],\n",
      "        [    0.0000,     0.0000,    -1.0398],\n",
      "        [    0.0000, -1024.0712,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000,  -36.7284],\n",
      "        [   0.0000,    0.0000,   -1.3305],\n",
      "        [   0.0000, -998.8770,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -479.8343],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,  -20.8385,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -489.9726],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -3.7948e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00, -9.0464e+02],\n",
      "        [ 0.0000e+00, -8.5735e-01,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.9140e+02],\n",
      "        [ 2.9260e-13,  0.0000e+00, -5.0557e-05],\n",
      "        [ 0.0000e+00, -1.1014e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -484.4178],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,  -17.0159,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:42:51,803 - INFO - Iter 150: Z_norm=6.6214, Theta_norm=3.3675, log_joint=-2519.0083, grad_Z_norm=5.4162e+01, grad_Theta_norm=4.9401e+02\n",
      "2025-06-17 11:42:51,803 - INFO -     grad_Theta (sample from iter 150):\n",
      "2025-06-17 11:42:51,804 - INFO - tensor([[   0.0000,    0.0000, -493.9965],\n",
      "        [   0.0000,    0.0000,   -2.9921],\n",
      "        [   0.0000,    0.0000,    0.0000]])\n",
      "2025-06-17 11:42:51,804 - INFO -     Annealed: alpha=0.100, beta=1.150, tau=1.000\n",
      "2025-06-17 11:42:51,805 - INFO -     Current Edge Probs (from Z, alpha=0.100):\n",
      "2025-06-17 11:42:51,806 - INFO - tensor([[0.0000, 0.6572, 0.6864],\n",
      "        [0.5968, 0.0000, 0.4789],\n",
      "        [0.5243, 0.4241, 0.0000]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -494.4647],\n",
      "        [   0.0000,    0.0000,   -0.8602],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -493.9965],\n",
      "        [   0.0000,    0.0000,   -2.9921],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -418.7312],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000, -176.0824,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -497.6518],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -273.1870],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000, -506.9524,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -499.3410],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.3533e-15],\n",
      "        [ 7.3958e+02,  0.0000e+00, -2.7123e-15],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -501.9106],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000, -209.3490],\n",
      "        [   0.0000, -893.2957,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -4.6892e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.0055e+03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -3.1437e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -1.1363e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -3.5894e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -1.1392e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -1143.2947,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -507.2879],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -1160.2949,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -508.7166],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -508.8059],\n",
      "        [   0.0000,    0.0000,   -2.8189],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -510.8288],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -512.7676],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -514.0856],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000,  -81.6311],\n",
      "        [   0.0000,    0.0000, -867.6942],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -423.8156],\n",
      "        [   0.0000,    0.0000, -185.9954],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  1.4463e-14, -1.8081e-37],\n",
      "        [ 7.7487e+02,  0.0000e+00, -3.3485e-38],\n",
      "        [ 0.0000e+00, -4.5733e-37,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -518.9180],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0.0000e+00, 2.2745e-09, 0.0000e+00],\n",
      "        [7.8524e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -520.5583],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -5.2101e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.8081e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -521.9063],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -1203.5806,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -1.6558e-33],\n",
      "        [ 8.0148e+02,  0.0000e+00, -9.6505e-36],\n",
      "        [ 0.0000e+00, -3.8300e-33,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000, -1050.3180],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -5.2463e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -2.5780e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:42:54,336 - INFO - Iter 200: Z_norm=7.7404, Theta_norm=3.4451, log_joint=-2969.1965, grad_Z_norm=1.4726e+02, grad_Theta_norm=5.2723e+02\n",
      "2025-06-17 11:42:54,337 - INFO -     grad_Theta (sample from iter 200):\n",
      "2025-06-17 11:42:54,338 - INFO - tensor([[   0.0000,    0.0000, -527.2266],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]])\n",
      "2025-06-17 11:42:54,338 - INFO -     Annealed: alpha=0.100, beta=1.200, tau=1.000\n",
      "2025-06-17 11:42:54,338 - INFO -     Current Edge Probs (from Z, alpha=0.100):\n",
      "2025-06-17 11:42:54,339 - INFO - tensor([[0.0000, 0.7251, 0.7628],\n",
      "        [0.6623, 0.0000, 0.5153],\n",
      "        [0.5577, 0.4288, 0.0000]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000, -1061.0902],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -527.2266],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -527.8870],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -529.2917],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -1219.1969,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[  0.0000, 481.0553,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -532.4752],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0.0000e+00, 4.8390e+02, 0.0000e+00],\n",
      "        [2.1365e-12, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -534.1900],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0.0000e+00, 4.8638e+02, 0.0000e+00],\n",
      "        [3.8541e-10, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000, -1086.3304],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0.0000e+00, 4.8918e+02, 0.0000e+00],\n",
      "        [1.2225e-06, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  1.2362e-28, -6.4304e+02],\n",
      "        [ 7.2194e-24,  0.0000e+00, -1.2874e+03],\n",
      "        [ 0.0000e+00, -1.0600e-23,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000, -1094.7172],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -537.5357],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00, -5.8227e-32],\n",
      "        [ 0.0000e+00, -1.2343e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  4.1017e-20, -6.5347e+02],\n",
      "        [ 2.1825e-07,  0.0000e+00, -1.3083e+03],\n",
      "        [ 0.0000e+00, -3.2104e-07,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -9.1412e-12],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -1.2386e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -540.2310],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000, -1120.1075],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -5.4169e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -5.9789e-30],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[  0.0000, 499.5472,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -543.1810],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -1254.8274,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[  0.0000,   0.0000,   0.0000],\n",
      "        [842.2675,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  9.4062e-05, -5.4535e+02],\n",
      "        [ 8.4447e+02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.8744e-16, -2.7159e-10],\n",
      "        [ 8.4814e+02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -1.2643e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -546.7931],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -547.5626],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -1275.6682,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -549.1664],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -550.0179],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -550.9420],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -1294.9166,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -553.6252],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -554.5062],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -555.4549],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[  0.0000,   0.0000,   0.0000],\n",
      "        [882.7679,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  7.9692e-27,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.1618e+03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 6.4987e-38,  0.0000e+00, -1.1638e+03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.0849e+02, -5.5893e+02],\n",
      "        [ 1.3941e-11,  0.0000e+00, -4.5594e-38],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -559.7748],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -560.6709],\n",
      "        [ 895.1227,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -561.6134],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:42:56,839 - INFO - Iter 250: Z_norm=9.1670, Theta_norm=3.6370, log_joint=-3876.8149, grad_Z_norm=1.6912e+02, grad_Theta_norm=9.0650e+02\n",
      "2025-06-17 11:42:56,840 - INFO -     grad_Theta (sample from iter 250):\n",
      "2025-06-17 11:42:56,841 - INFO - tensor([[  0.0000,   0.0000,   0.0000],\n",
      "        [906.4952,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000]])\n",
      "2025-06-17 11:42:56,841 - INFO -     Annealed: alpha=0.100, beta=1.250, tau=1.000\n",
      "2025-06-17 11:42:56,841 - INFO -     Current Edge Probs (from Z, alpha=0.100):\n",
      "2025-06-17 11:42:56,842 - INFO - tensor([[0.0000, 0.8082, 0.8395],\n",
      "        [0.7577, 0.0000, 0.5846],\n",
      "        [0.6176, 0.4459, 0.0000]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -562.6304],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -1325.5874,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[  0.0000, 510.9564,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[  0.0000,   0.0000,   0.0000],\n",
      "        [906.4952,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.1308e+02, -5.6631e+02],\n",
      "        [ 6.9410e-07,  0.0000e+00, -1.3505e-39],\n",
      "        [ 0.0000e+00, -1.0156e-06,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.1401e+02, -5.6714e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -7.6136e-40],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[  0.0000, 515.2443,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  1.8367e-31, -4.4214e-13],\n",
      "        [ 9.2354e+02,  0.0000e+00, -4.2083e-31],\n",
      "        [ 0.0000e+00, -1.3436e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -5.7036e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -2.6907e-37],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -5.7113e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.1279e-36],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.2106e+02, -5.7199e+02],\n",
      "        [ 2.6423e-21,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -572.8813],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -1354.2728,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -1358.0531,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.2422e+02, -5.7474e+02],\n",
      "        [ 7.5656e-07,  0.0000e+00, -3.0747e-31],\n",
      "        [ 0.0000e+00, -1.0979e-06,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -5.7568e+02],\n",
      "        [ 9.4122e+02,  0.0000e+00, -6.6558e-32],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -577.5562],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -1375.6196,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -3.6427e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.5832e+03, -8.6937e-04,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.2902e+02, -5.7938e+02],\n",
      "        [ 1.9366e-10,  0.0000e+00, -1.1931e-26],\n",
      "        [ 0.0000e+00, -2.8189e-10,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[  0.0000, 530.0303,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[  0.0000, 531.2408,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.3261e+02, -5.8189e+02],\n",
      "        [ 2.1595e-20,  0.0000e+00, -7.3486e-23],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -277.1468],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [-851.3860, -665.5913,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.3549e+02, -5.8356e+02],\n",
      "        [ 1.0494e-17,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.2842e-01, -5.8372e+02],\n",
      "        [ 9.5997e+02,  0.0000e+00, -1.3966e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -585.3992],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.3954e+02, -5.8640e+02],\n",
      "        [ 1.0411e-05,  0.0000e+00, -8.2894e-17],\n",
      "        [ 0.0000e+00, -1.5217e-05,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -587.4191],\n",
      "        [ 967.9171,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [-1669.9513,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000, -1193.9200],\n",
      "        [    0.0000, -1418.1752,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.4420e+02, -5.9039e+02],\n",
      "        [ 5.5944e-16,  0.0000e+00, -4.5597e-13],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -591.3370],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -1424.8639,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[  0.0000, 546.4151,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.4762e+02, -5.9323e+02],\n",
      "        [ 5.5670e-15,  0.0000e+00, -1.0291e-09],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.4896e+02, -5.9419e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.8986e-12],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.5042e+02, -5.9520e+02],\n",
      "        [ 8.0273e-24,  0.0000e+00, -1.2838e-11],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[  0.0000, 551.9543,   0.0000],\n",
      "        [987.5121,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.4408e+02, -5.8694e+02],\n",
      "        [ 1.7061e+01,  0.0000e+00, -5.2611e-06],\n",
      "        [ 0.0000e+00, -2.4926e+01,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  555.2704, -598.1841],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -600.1780],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -1453.4072,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  560.0333, -600.8754],\n",
      "        [   0.0000,    0.0000,   -0.6172],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  561.5252, -602.2048],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -603.2808],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -604.4114],\n",
      "        [1002.6634,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  565.8107,    0.0000],\n",
      "        [1005.1346,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  1.6733e-08, -1.7895e-08],\n",
      "        [ 1.0087e+03,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -1.4706e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000, -1206.7891],\n",
      "        [    0.0000, -1474.3802,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [ 1016.9694,     0.0000, -1208.4698],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:42:59,361 - INFO - Iter 300: Z_norm=10.7541, Theta_norm=4.0002, log_joint=-5510.7915, grad_Z_norm=3.7497e+02, grad_Theta_norm=8.3698e+02\n",
      "2025-06-17 11:42:59,361 - INFO -     grad_Theta (sample from iter 300):\n",
      "2025-06-17 11:42:59,362 - INFO - tensor([[ 0.0000e+00,  5.7231e+02, -6.1073e+02],\n",
      "        [ 4.3456e-11,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "2025-06-17 11:42:59,363 - INFO -     Annealed: alpha=0.100, beta=1.300, tau=1.000\n",
      "2025-06-17 11:42:59,363 - INFO -     Current Edge Probs (from Z, alpha=0.100):\n",
      "2025-06-17 11:42:59,364 - INFO - tensor([[0.0000, 0.8838, 0.9000],\n",
      "        [0.8579, 0.0000, 0.6960],\n",
      "        [0.7033, 0.4863, 0.0000]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -775.1695],\n",
      "        [    0.0000,     0.0000, -1548.7235],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [1025.8619,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.7231e+02, -6.1073e+02],\n",
      "        [ 4.3456e-11,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -611.5715],\n",
      "        [ 1035.2483,     0.0000,     0.0000],\n",
      "        [    0.0000, -1495.7029,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.7419e+02, -7.8540e+02],\n",
      "        [ 1.0697e-03,  0.0000e+00, -1.5691e+03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -613.4689],\n",
      "        [1044.9623,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -614.5048],\n",
      "        [1050.1897,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -615.5780],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -1512.5626,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -616.6845],\n",
      "        [1061.1248,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[  0.0000, 578.3710,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [1071.9662,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.8004e+02, -6.1984e+02],\n",
      "        [ 1.0777e+03,  0.0000e+00, -7.5248e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [ 1083.6980,     0.0000, -1248.5413],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  581.7109,    0.0000],\n",
      "        [1090.1434,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.8268e+02, -6.2241e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -3.0116e-33],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -623.2607],\n",
      "        [1102.9844,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000, -1258.8115],\n",
      "        [    0.0000, -1543.5807,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.8568e+02, -6.2503e+02],\n",
      "        [ 1.1153e+03,  0.0000e+00, -4.2666e-11],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   586.6669,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [-1776.9697,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.8780e+02, -6.2666e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -2.2967e-42],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  589.0381, -627.5209],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   590.3595,     0.0000],\n",
      "        [    0.0000,     0.0000, -1271.6846],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.9179e+02, -6.2929e+02],\n",
      "        [ 1.1406e+03,  0.0000e+00, -4.3846e-15],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  5.9321e+02, -6.3014e+02],\n",
      "        [ 1.1452e+03,  0.0000e+00, -2.0434e-15],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  594.7284, -631.0686],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  596.2896, -632.0486],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -633.0700],\n",
      "        [ 1159.2571,     0.0000,     0.0000],\n",
      "        [    0.0000, -1568.7623,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -634.1282],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -1572.0277,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  600.6367, -635.2188],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -636.3384],\n",
      "        [ 1172.1556,     0.0000,     0.0000],\n",
      "        [    0.0000, -1581.1525,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  603.2432,    0.0000],\n",
      "        [1176.6064,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.0457e+02, -8.4427e+02],\n",
      "        [ 7.1323e-25,  0.0000e+00, -1.6861e+03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -846.6226],\n",
      "        [    0.0000,     0.0000, -1690.7834],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -640.8181],\n",
      "        [1190.0989,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.0831e+02, -6.4201e+02],\n",
      "        [ 1.1947e+03,  0.0000e+00, -1.0499e-16],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -643.1984],\n",
      "        [1199.6989,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.1058e+02, -8.5775e+02],\n",
      "        [ 1.6003e-22,  0.0000e+00, -1.7129e+03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.1178e+02, -6.4572e+02],\n",
      "        [ 1.2101e+03,  0.0000e+00, -1.8534e-18],\n",
      "        [-1.2460e-39,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  0.0000e+00, -8.6389e+02],\n",
      "        [ 4.0023e-21,  0.0000e+00, -1.7251e+03],\n",
      "        [ 0.0000e+00, -1.6165e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  614.1370, -648.3051],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -649.6321],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000, -1624.3436,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -650.9588],\n",
      "        [1228.5248,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   617.4232,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [-1837.0430,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   618.5043,     0.0000],\n",
      "        [    0.0000,     0.0000, -1332.1945],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   619.6705,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [-1848.8733,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [1243.8887,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -656.4062],\n",
      "        [ 1247.7695,     0.0000,     0.0000],\n",
      "        [    0.0000, -1648.9755,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   623.0372,     0.0000],\n",
      "        [    0.0000,     0.0000, -1344.7389],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  624.1367, -658.1626],\n",
      "        [1256.1620,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   625.3160,  -894.2911],\n",
      "        [    0.0000,     0.0000, -1785.6353],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  626.5652, -660.0234],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:43:01,815 - INFO - Iter 350: Z_norm=12.5504, Theta_norm=4.4951, log_joint=-8367.0186, grad_Z_norm=5.1083e+02, grad_Theta_norm=1.5664e+03\n",
      "2025-06-17 11:43:01,816 - INFO -     grad_Theta (sample from iter 350):\n",
      "2025-06-17 11:43:01,817 - INFO - tensor([[   0.0000,  629.2260, -662.0662],\n",
      "        [1272.5366,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]])\n",
      "2025-06-17 11:43:01,818 - INFO -     Annealed: alpha=0.100, beta=1.350, tau=1.000\n",
      "2025-06-17 11:43:01,818 - INFO -     Current Edge Probs (from Z, alpha=0.100):\n",
      "2025-06-17 11:43:01,819 - INFO - tensor([[0.0000, 0.9408, 0.9436],\n",
      "        [0.9350, 0.0000, 0.8044],\n",
      "        [0.8162, 0.5494, 0.0000]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.2788e+02, -6.6104e+02],\n",
      "        [ 1.2684e+03,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.8206e-29,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  629.2260, -662.0662],\n",
      "        [1272.5366,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  630.6689, -663.1737],\n",
      "        [1277.2834,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.3198e+02, -9.0757e+02],\n",
      "        [ 3.8611e-02,  0.0000e+00, -1.8120e+03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   633.6049,  -910.2214],\n",
      "        [    2.8275,     0.0000, -1814.4388],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -666.6399],\n",
      "        [1291.0714,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   636.4634,  -917.4554],\n",
      "        [    0.0000,     0.0000, -1831.7797],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -921.1284],\n",
      "        [ 1299.8236,     0.0000, -1839.1066],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.3914e+02, -6.7048e+02],\n",
      "        [ 1.3045e+03,  0.0000e+00, -6.0008e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  640.4628, -671.8082],\n",
      "        [   0.0000,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.4183e+02, -6.7313e+02],\n",
      "        [ 1.3141e+03,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.9198e-06,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000,    0.0000],\n",
      "        [1319.0084,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   920.0049,     0.0000],\n",
      "        [    0.0000,     0.0000, -1407.8618],\n",
      "        [    0.0000, -2666.8936,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.4576e+02, -6.7656e+02],\n",
      "        [ 1.3288e+03,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -8.0740e-21,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.4731e+02, -6.7779e+02],\n",
      "        [ 0.0000e+00,  0.0000e+00, -1.5246e-24],\n",
      "        [-1.9353e+03,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -947.7473],\n",
      "        [ 1338.9216,     0.0000, -1892.1647],\n",
      "        [    0.0000, -1699.0424,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  8.7871e+02, -7.3034e+02],\n",
      "        [ 8.5450e-06,  0.0000e+00, -3.5208e+02],\n",
      "        [-1.9467e+03, -2.1976e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000, -1427.5569],\n",
      "        [    0.0000, -1710.4235,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.5274e+02, -6.8236e+02],\n",
      "        [ 3.2009e-03,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.9638e+03,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   654.0521,  -683.4590],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [-1974.9108,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   655.4031,     0.0000],\n",
      "        [    0.0000,     0.0000, -1439.8721],\n",
      "        [-1988.2726,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.5683e+02, -6.8563e+02],\n",
      "        [ 1.3627e+03,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.5478e-09,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [ 1366.1987,     0.0000, -1447.8718],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -687.5549],\n",
      "        [ 1370.2878,     0.0000,     0.0000],\n",
      "        [    0.0000, -1747.0710,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  660.4921, -688.3785],\n",
      "        [1374.5287,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -978.2666],\n",
      "        [    0.0000,     0.0000, -1953.0449],\n",
      "        [    0.0000, -1758.5701,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -690.6066],\n",
      "        [1384.1743,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -984.4747],\n",
      "        [ 1389.0035,     0.0000, -1965.4272],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,    0.0000, -692.8735],\n",
      "        [1394.1776,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   665.5872,     0.0000],\n",
      "        [ 1399.6519,     0.0000, -1476.4291],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.6652e+02, -9.9453e+02],\n",
      "        [ 1.4055e+03,  0.0000e+00, -1.9855e+03],\n",
      "        [-6.4726e-25,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   667.4531,  -998.1692],\n",
      "        [    0.0000,     0.0000, -1992.7642],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.6836e+02, -1.0020e+03],\n",
      "        [ 1.4164e+03,  0.0000e+00, -2.0004e+03],\n",
      "        [-3.0508e-20,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  9.8193e+02, -6.9869e+02],\n",
      "        [ 1.4224e+03,  0.0000e+00, -7.4056e-14],\n",
      "        [-1.0243e-33, -2.8466e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  9.8517e+02, -6.9994e+02],\n",
      "        [ 1.4282e+03,  0.0000e+00, -5.7734e-16],\n",
      "        [-4.5975e-14, -2.8560e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000, -1014.2563],\n",
      "        [ 1434.3169,     0.0000, -2024.9093],\n",
      "        [    0.0000, -1811.1897,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.7347e+02, -1.0184e+03],\n",
      "        [ 1.4407e+03,  0.0000e+00, -2.0331e+03],\n",
      "        [-1.8221e-06,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  674.5457, -703.6902],\n",
      "        [1446.6619,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  675.9875, -705.1729],\n",
      "        [1453.5016,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  677.3193, -706.4957],\n",
      "        [1460.1473,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.7868e+02, -7.0781e+02],\n",
      "        [ 3.4430e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.1228e+03,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  680.0659, -709.1136],\n",
      "        [1472.9681,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1014.5079,     0.0000],\n",
      "        [    0.0000,     0.0000, -1542.6227],\n",
      "        [    0.0000, -2941.3101,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.8282e+02, -7.1143e+02],\n",
      "        [ 5.7857e-17,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.1380e+03,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  1.0221e+03, -7.1275e+02],\n",
      "        [ 1.4899e+03,  0.0000e+00, -8.6726e-16],\n",
      "        [ 0.0000e+00, -2.9634e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  1.0266e+03, -7.1394e+02],\n",
      "        [ 1.3050e-32,  0.0000e+00, -1.2460e-12],\n",
      "        [-2.1532e+03, -2.9763e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  1.0317e+03, -7.1512e+02],\n",
      "        [ 1.5000e+03,  0.0000e+00, -8.0497e-06],\n",
      "        [ 0.0000e+00, -2.9912e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   689.3916,  -716.3113],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [-2171.5295,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:43:04,247 - INFO - Iter 400: Z_norm=14.4396, Theta_norm=5.1650, log_joint=-12771.0303, grad_Z_norm=8.6712e+02, grad_Theta_norm=1.8240e+03\n",
      "2025-06-17 11:43:04,248 - INFO -     grad_Theta (sample from iter 400):\n",
      "2025-06-17 11:43:04,248 - INFO - tensor([[   0.0000,  696.0151, -721.2059],\n",
      "        [1523.9261,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]])\n",
      "2025-06-17 11:43:04,249 - INFO -     Annealed: alpha=0.100, beta=1.400, tau=1.000\n",
      "2025-06-17 11:43:04,249 - INFO -     Current Edge Probs (from Z, alpha=0.100):\n",
      "2025-06-17 11:43:04,250 - INFO - tensor([[0.0000, 0.9727, 0.9706],\n",
      "        [0.9770, 0.0000, 0.9048],\n",
      "        [0.9101, 0.6466, 0.0000]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient:\n",
      " tensor([[   0.0000,  691.0711, -717.5053],\n",
      "        [1509.7722,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   692.7340, -1058.9279],\n",
      "        [    0.0000,     0.0000, -2113.8557],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  694.3816, -719.9559],\n",
      "        [1519.1455,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  696.0151, -721.2059],\n",
      "        [1523.9261,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  6.9764e+02, -1.0668e+03],\n",
      "        [ 2.8691e-07,  0.0000e+00, -2.1294e+03],\n",
      "        [-2.2166e+03,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  699.2446,    0.0000],\n",
      "        [1533.5790,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   700.8423, -1072.3375],\n",
      "        [    0.0000,     0.0000, -2140.4758],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  7.0243e+02, -1.0754e+03],\n",
      "        [ 8.8968e-03,  0.0000e+00, -2.1466e+03],\n",
      "        [-2.2429e+03, -5.3911e-33,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -727.4254],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [-2253.0195,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  705.4160, -728.6819],\n",
      "        [1550.4094,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [ 1554.4542,     0.0000, -1594.0048],\n",
      "        [    0.0000, -1975.2534,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   708.1501,     0.0000],\n",
      "        [ 1558.8447,     0.0000, -1598.0068],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  709.4614,    0.0000],\n",
      "        [1563.5676,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   710.7919,  -733.0543],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [-2302.4529,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000, -1097.0293],\n",
      "        [ 1573.1024,     0.0000, -2189.6892],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  7.1320e+02, -1.0999e+03],\n",
      "        [ 1.5776e+03,  0.0000e+00, -2.1955e+03],\n",
      "        [-1.3751e-32, -1.8772e-32,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  7.1445e+02, -1.1034e+03],\n",
      "        [ 1.5827e+03,  0.0000e+00, -2.2024e+03],\n",
      "        [-1.4968e-14,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   715.8664, -1107.4364],\n",
      "        [ 1588.3931,     0.0000, -2210.4741],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   717.5184, -1110.8246],\n",
      "        [ 1593.6652,     0.0000, -2215.3574],\n",
      "        [    0.0000,    -4.0883,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000, -1115.8073],\n",
      "        [ 1599.7013,     0.0000, -2227.2058],\n",
      "        [    0.0000, -2006.9292,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  1.1043e+03, -7.4118e+02],\n",
      "        [ 1.6056e+03,  0.0000e+00, -5.5749e-19],\n",
      "        [-5.8720e-19, -3.2016e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   720.9379, -1124.4905],\n",
      "        [ 1611.6626,     0.0000, -2244.5593],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  1.1109e+03, -7.4387e+02],\n",
      "        [ 1.6178e+03,  0.0000e+00, -4.9212e-14],\n",
      "        [-8.0760e-02, -3.2209e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000, -1132.9572],\n",
      "        [ 1624.1215,     0.0000, -2261.4705],\n",
      "        [    0.0000, -2030.3704,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   724.8912, -1137.2562],\n",
      "        [    0.0000,     0.0000, -2270.0564],\n",
      "        [-2372.2051,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   726.1529, -1141.7269],\n",
      "        [ 1636.2122,     0.0000, -2278.9873],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   727.4627, -1146.4132],\n",
      "        [ 1642.1449,     0.0000, -2288.3513],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000, -1151.2219],\n",
      "        [ 1648.1771,     0.0000, -2297.9612],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   729.8009, -1155.9113],\n",
      "        [ 1653.9741,     0.0000, -2307.3342],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  1.1362e+03, -7.5386e+02],\n",
      "        [ 1.6606e+03,  0.0000e+00, -1.0970e-17],\n",
      "        [-1.1350e-17, -3.2945e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  1.1400e+03, -7.5534e+02],\n",
      "        [ 1.6669e+03,  0.0000e+00, -5.6435e-16],\n",
      "        [-5.8249e-16, -3.3055e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   733.8674, -1170.1638],\n",
      "        [    0.0000,     0.0000, -2335.8040],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  735.2642, -758.2404],\n",
      "        [1679.1011,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  7.3666e+02, -1.1788e+03],\n",
      "        [ 3.5505e-35,  0.0000e+00, -2.3531e+03],\n",
      "        [-2.4112e+03,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  7.3791e+02, -1.1829e+03],\n",
      "        [ 2.3034e-37,  0.0000e+00, -2.3612e+03],\n",
      "        [-2.4163e+03,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1159.7050,  -762.6151],\n",
      "        [    0.0000,     0.0000,     0.0000],\n",
      "        [-2424.8496, -3362.7817,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   740.7877, -1191.6075],\n",
      "        [ 1699.1241,     0.0000, -2378.6016],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000,  -765.5342],\n",
      "        [ 3072.3167,     0.0000,     0.0000],\n",
      "        [-4479.5396, -2131.1460,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   743.5802, -1200.0229],\n",
      "        [ 1709.1407,     0.0000, -2395.3906],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   744.9124, -1204.2694],\n",
      "        [ 1714.6949,     0.0000, -2403.8625],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  7.4641e+02, -1.2089e+03],\n",
      "        [ 1.0517e-23,  0.0000e+00, -2.4132e+03],\n",
      "        [-2.4777e+03,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   747.5977, -1213.2604],\n",
      "        [ 1725.5312,     0.0000, -2421.8093],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1185.8722,  -772.9489],\n",
      "        [ 1731.2252,     0.0000,     0.0000],\n",
      "        [    0.0000, -3438.8403,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1189.8262,  -774.4302],\n",
      "        [ 1736.7209,     0.0000,     0.0000],\n",
      "        [    0.0000, -3450.3359,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   752.0357,     0.0000],\n",
      "        [ 3160.9021,     0.0000,     0.0000],\n",
      "        [-4608.8359,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1198.2361, -1229.7001],\n",
      "        [ 1747.8715,     0.0000, -2454.6086],\n",
      "        [    0.0000, -3474.8215,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   755.0671, -1234.0884],\n",
      "        [ 1754.9147,     0.0000, -2463.3633],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  7.5658e+02, -7.7988e+02],\n",
      "        [ 3.2016e+03,  0.0000e+00, -4.5139e-18],\n",
      "        [-4.6681e+03, -6.3994e-18,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   758.1044, -1241.9427],\n",
      "        [ 1768.1045,     0.0000, -2479.0322],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   759.4380, -1245.6747],\n",
      "        [ 1774.5460,     0.0000, -2486.4766],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  7.6108e+02, -7.8404e+02],\n",
      "        [ 3.2452e+03,  0.0000e+00, -3.4640e-11],\n",
      "        [-4.7318e+03, -4.9120e-11,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   762.5477, -1254.0034],\n",
      "        [ 1788.9336,     0.0000, -2503.0923],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:43:07,114 - INFO - Iter 450: Z_norm=16.2264, Theta_norm=5.9846, log_joint=-19052.7891, grad_Z_norm=1.8213e+03, grad_Theta_norm=3.9239e+03\n",
      "2025-06-17 11:43:07,115 - INFO -     grad_Theta (sample from iter 450):\n",
      "2025-06-17 11:43:07,116 - INFO - tensor([[    0.0000,   765.4498, -1262.3384],\n",
      "        [    0.0000,     0.0000, -2519.7231],\n",
      "        [-2620.7930,     0.0000,     0.0000]])\n",
      "2025-06-17 11:43:07,116 - INFO -     Annealed: alpha=0.100, beta=1.450, tau=1.000\n",
      "2025-06-17 11:43:07,116 - INFO -     Current Edge Probs (from Z, alpha=0.100):\n",
      "2025-06-17 11:43:07,117 - INFO - tensor([[0.0000, 0.9849, 0.9835],\n",
      "        [0.9932, 0.0000, 0.9611],\n",
      "        [0.9689, 0.7787, 0.0000]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient:\n",
      " tensor([[    0.0000,   763.8420, -1257.8162],\n",
      "        [    0.0000,     0.0000, -2510.6985],\n",
      "        [-2607.6682,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   765.4498, -1262.3384],\n",
      "        [    0.0000,     0.0000, -2519.7231],\n",
      "        [-2620.7930,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1232.7965, -1266.7209],\n",
      "        [   17.5397,     0.0000, -2528.4692],\n",
      "        [-2608.6211, -3575.1680,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   768.3872, -1271.2891],\n",
      "        [    0.0000,     0.0000, -2537.5925],\n",
      "        [-2648.3494,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1239.7141, -1275.6771],\n",
      "        [    0.0000,     0.0000, -2546.3552],\n",
      "        [-2662.5525, -3595.2361,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1244.1256, -1280.6813],\n",
      "        [ 1822.4674,     0.0000, -2556.3499],\n",
      "        [    0.0000, -3608.0566,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1248.9384,     0.0000],\n",
      "        [ 1827.0010,     0.0000, -1866.4501],\n",
      "        [    0.0000, -3622.0662,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   774.6470, -1290.2168],\n",
      "        [ 1831.7147,     0.0000, -2575.4043],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   775.9221, -1294.4247],\n",
      "        [ 1835.8424,     0.0000, -2583.8176],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  7.7766e+02, -1.2995e+03],\n",
      "        [ 1.8413e+03,  0.0000e+00, -2.5940e+03],\n",
      "        [-1.3045e-34,  0.0000e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1267.9701, -1304.7274],\n",
      "        [    0.0000,     0.0000, -2604.4126],\n",
      "        [    0.0000, -3677.4651,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1272.7996, -1309.7024],\n",
      "        [ 1851.6392,     0.0000, -2614.3582],\n",
      "        [    0.0000, -3691.5256,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1277.8671, -1314.4523],\n",
      "        [ 1856.1475,     0.0000, -2623.8540],\n",
      "        [    0.0000, -3706.2976,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   784.1172, -1319.5254],\n",
      "        [ 1861.2166,     0.0000, -2633.9951],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   785.9190, -1324.9187],\n",
      "        [ 1866.8312,     0.0000, -2644.7754],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   787.5182,  -809.0058],\n",
      "        [ 3461.6707,     0.0000,     0.0000],\n",
      "        [-5047.8296,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1298.7472,     0.0000],\n",
      "        [ 1878.1284,     0.0000, -1936.3265],\n",
      "        [    0.0000, -3767.1255,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1303.8457, -1339.3575],\n",
      "        [    0.0000,     0.0000, -2673.6335],\n",
      "        [-2785.2083, -3781.9780,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1309.4009, -1344.0044],\n",
      "        [ 1889.5160,     0.0000, -2682.9233],\n",
      "        [    0.0000, -3798.1743,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   794.0314, -1348.7330],\n",
      "        [ 1895.0154,     0.0000, -2692.3765],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  1.3208e+03, -1.3535e+03],\n",
      "        [ 1.9006e+03,  0.0000e+00, -2.7019e+03],\n",
      "        [-4.0659e-34, -3.8314e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   797.1781, -1358.1050],\n",
      "        [ 1905.8693,     0.0000, -2711.1118],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   798.9788,  -818.9555],\n",
      "        [ 3538.1948,     0.0000,     0.0000],\n",
      "        [-5159.3872,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   800.5714, -1367.8356],\n",
      "        [    0.0000,     0.0000, -2730.5559],\n",
      "        [-2831.6755,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1341.7830, -1372.4529],\n",
      "        [ 1923.9249,     0.0000, -2739.7800],\n",
      "        [    0.0000, -3892.5645,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   803.7296, -1377.1478],\n",
      "        [ 1929.6353,     0.0000, -2749.1597],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   804.6729, -1380.8451],\n",
      "        [ 3583.7288,     0.0000, -2756.5479],\n",
      "        [-5225.8008,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   806.8244,  -826.2794],\n",
      "        [ 3600.1379,     0.0000,     0.0000],\n",
      "        [-5249.7397,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1359.8588, -1390.8783],\n",
      "        [ 1947.9772,     0.0000, -2776.5859],\n",
      "        [    0.0000, -3945.1760,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1364.7648, -1395.6804],\n",
      "        [ 1954.9956,     0.0000, -2786.1748],\n",
      "        [    0.0000, -3959.4551,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  1.3699e+03, -1.4003e+03],\n",
      "        [ 1.9616e+03,  0.0000e+00, -2.7954e+03],\n",
      "        [-4.8852e-41, -3.9744e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  1.3755e+03, -1.4050e+03],\n",
      "        [ 1.9681e+03,  0.0000e+00, -2.8048e+03],\n",
      "        [-5.7179e-41, -3.9907e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1381.3650, -1409.7330],\n",
      "        [ 1974.5869,     0.0000, -2814.2395],\n",
      "        [    0.0000, -4007.8584,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000, -1414.5641],\n",
      "        [ 3680.9207,     0.0000, -2823.8889],\n",
      "        [-5367.5581,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   817.9828, -1419.4122],\n",
      "        [ 1987.8967,     0.0000, -2833.5728],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   819.4757,  -838.3097],\n",
      "        [ 3707.7100,     0.0000,     0.0000],\n",
      "        [-5406.6191,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   820.7651,  -839.6201],\n",
      "        [ 3721.7966,     0.0000,     0.0000],\n",
      "        [-5427.1670,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000, -1432.9551],\n",
      "        [ 2009.1418,     0.0000, -2860.6086],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1412.9818,  -843.5007],\n",
      "        [ 3757.9937,     0.0000,     0.0000],\n",
      "        [-5479.9756, -4100.0288,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1417.5232, -1442.5469],\n",
      "        [ 2025.8280,     0.0000, -2879.7434],\n",
      "        [    0.0000, -4113.2666,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1420.8772, -1444.9443],\n",
      "        [ 2030.7926,     0.0000, -2884.5222],\n",
      "        [    0.0000, -4123.0762,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1426.2970, -1449.1469],\n",
      "        [    0.0000,     0.0000, -2892.9067],\n",
      "        [-3023.2949, -4138.8931,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   829.4755,  -848.4605],\n",
      "        [ 3816.1174,     0.0000,     0.0000],\n",
      "        [-5564.7793,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   830.9691, -1457.7446],\n",
      "        [ 2051.6692,     0.0000, -2910.0574],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   832.4305,  -851.3218],\n",
      "        [ 3846.9922,     0.0000,     0.0000],\n",
      "        [-5609.8398,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   833.8636,  -852.7161],\n",
      "        [ 3863.3347,     0.0000,     0.0000],\n",
      "        [-5633.6938,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1451.3623, -1469.1755],\n",
      "        [    0.0000,     0.0000, -2932.8420],\n",
      "        [-3089.8057, -4211.9712,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1456.0706, -1472.8761],\n",
      "        [ 2079.2866,     0.0000, -2940.2166],\n",
      "        [    0.0000, -4225.6899,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   838.2459,  -856.8537],\n",
      "        [ 3913.4587,     0.0000,     0.0000],\n",
      "        [-5706.8779,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   839.7229, -1480.3104],\n",
      "        [ 2092.5840,     0.0000, -2955.0315],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1470.3579, -1484.0571],\n",
      "        [ 2099.2690,     0.0000, -2962.4983],\n",
      "        [    0.0000, -4267.3218,     0.0000]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:43:09,710 - INFO - Iter 500: Z_norm=17.8362, Theta_norm=6.9843, log_joint=-27976.3027, grad_Z_norm=2.4579e+03, grad_Theta_norm=6.4438e+03\n",
      "2025-06-17 11:43:09,711 - INFO -     grad_Theta (sample from iter 500):\n",
      "2025-06-17 11:43:09,711 - INFO - tensor([[    0.0000,  1475.2217, -1487.9562],\n",
      "        [    0.0000,     0.0000, -2970.2715],\n",
      "        [-3158.8933, -4281.4956,     0.0000]])\n",
      "2025-06-17 11:43:09,712 - INFO -     Annealed: alpha=0.100, beta=1.500, tau=1.000\n",
      "2025-06-17 11:43:09,712 - INFO -     Current Edge Probs (from Z, alpha=0.100):\n",
      "2025-06-17 11:43:09,713 - INFO - tensor([[0.0000, 0.9921, 0.9920],\n",
      "        [0.9975, 0.0000, 0.9842],\n",
      "        [0.9891, 0.8875, 0.0000]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient:\n",
      " tensor([[    0.0000,  1475.2217, -1487.9562],\n",
      "        [    0.0000,     0.0000, -2970.2715],\n",
      "        [-3158.8933, -4281.4956,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1480.4945,  -862.4463],\n",
      "        [ 2111.7546,     0.0000,     0.0000],\n",
      "        [    0.0000, -4296.8721,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   846.1112, -1496.2955],\n",
      "        [ 3990.5286,     0.0000, -2986.8977],\n",
      "        [-5819.3799,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   847.3209, -1499.6005],\n",
      "        [ 2123.9180,     0.0000, -2993.4854],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   848.8172,  -866.6685],\n",
      "        [ 4018.0559,     0.0000,     0.0000],\n",
      "        [-5859.5610,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   850.7000, -1508.0779],\n",
      "        [ 4035.4946,     0.0000, -3010.3870],\n",
      "        [-5885.0142,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   851.7068,  -869.4553],\n",
      "        [ 4050.1028,     0.0000,     0.0000],\n",
      "        [-5906.3438,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  8.5298e+02, -1.5145e+03],\n",
      "        [ 4.0671e+03,  0.0000e+00, -3.0233e+03],\n",
      "        [-5.9312e+03, -9.3457e-07,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[   0.0000,  854.4816, -872.2011],\n",
      "        [2158.0212,    0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000,    0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1515.2721, -1521.9832],\n",
      "        [ 2165.1638,     0.0000, -3038.0913],\n",
      "        [    0.0000, -4398.1050,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  8.5712e+02, -1.5254e+03],\n",
      "        [ 4.1186e+03,  0.0000e+00, -3.0449e+03],\n",
      "        [-6.0064e+03, -1.2829e-05,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1522.4662, -1529.1050],\n",
      "        [ 2178.8481,     0.0000, -3052.2832],\n",
      "        [    0.0000, -4419.0132,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1526.9600, -1533.3698],\n",
      "        [ 2186.3047,     0.0000, -3060.7874],\n",
      "        [    0.0000, -4432.0859,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   861.5573,  -879.1557],\n",
      "        [ 4166.8296,     0.0000,     0.0000],\n",
      "        [-6076.7305,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  8.6297e+02, -1.5411e+03],\n",
      "        [ 4.1826e+03,  0.0000e+00, -3.0762e+03],\n",
      "        [-6.0997e+03, -7.5382e-11,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  8.6507e+02, -1.5462e+03],\n",
      "        [ 4.2028e+03,  0.0000e+00, -3.0864e+03],\n",
      "        [-6.1292e+03, -5.0346e-11,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  8.6545e+02, -1.5484e+03],\n",
      "        [ 4.2156e+03,  0.0000e+00, -3.0908e+03],\n",
      "        [-6.1479e+03, -5.0531e-09,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   867.1827, -1553.2368],\n",
      "        [ 2222.5659,     0.0000, -3100.4028],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1549.9373, -1557.1365],\n",
      "        [ 2229.4592,     0.0000, -3108.1824],\n",
      "        [    0.0000, -4498.8901,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1554.0753, -1561.7828],\n",
      "        [    0.0000,     0.0000, -3117.4546],\n",
      "        [-3418.2017, -4510.9175,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1482.2991, -1491.1924],\n",
      "        [ 2470.5581,     0.0000, -2779.3364],\n",
      "        [ -694.1972, -4021.5874,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1563.1022, -1570.5896],\n",
      "        [    0.0000,     0.0000, -3135.0303],\n",
      "        [-3443.2000, -4537.2021,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1567.8761, -1574.7335],\n",
      "        [ 2255.0669,     0.0000, -3143.3015],\n",
      "        [    0.0000, -4551.1235,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   875.4067, -1578.5961],\n",
      "        [ 4323.0928,     0.0000, -3151.0120],\n",
      "        [-6304.8228,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1578.7004, -1584.1830],\n",
      "        [ 2267.2144,     0.0000, -3162.1650],\n",
      "        [    0.0000, -4582.6812,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1583.7549, -1588.4696],\n",
      "        [ 2272.6523,     0.0000, -3170.7234],\n",
      "        [    0.0000, -4597.4272,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1589.4600, -1593.1289],\n",
      "        [ 2278.4851,     0.0000, -3180.0259],\n",
      "        [    0.0000, -4614.0728,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   882.2545,     0.0000],\n",
      "        [ 4378.1899,     0.0000, -2288.6194],\n",
      "        [-6385.2197,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   884.4779, -1603.8252],\n",
      "        [ 4394.7251,     0.0000, -3201.3892],\n",
      "        [-6409.3428,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   885.3373,  -902.5647],\n",
      "        [ 4405.9263,     0.0000,     0.0000],\n",
      "        [-6425.6924,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   886.8110,  -903.9133],\n",
      "        [ 4421.4302,     0.0000,     0.0000],\n",
      "        [-6448.3213,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1615.3080, -1615.1697],\n",
      "        [ 2310.8020,     0.0000, -3224.0437],\n",
      "        [    0.0000, -4689.4253,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  8.8916e+02, -1.6181e+03],\n",
      "        [ 4.4502e+03,  0.0000e+00, -3.2299e+03],\n",
      "        [-6.4904e+03, -1.6573e-37,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1624.4357, -1623.2018],\n",
      "        [ 2324.4094,     0.0000, -3240.0750],\n",
      "        [    0.0000, -4716.0112,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   892.6510,  -909.2905],\n",
      "        [ 4484.2739,     0.0000,     0.0000],\n",
      "        [-6540.0454,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   894.0948, -1631.2014],\n",
      "        [ 2338.0354,     0.0000, -3256.0386],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1637.4352, -1634.8102],\n",
      "        [ 2344.2473,     0.0000, -3263.2383],\n",
      "        [    0.0000, -4753.8701,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   897.8149, -1640.7844],\n",
      "        [ 4533.2563,     0.0000, -3275.1611],\n",
      "        [-6611.5156,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1646.2032, -1643.0187],\n",
      "        [ 2357.5166,     0.0000, -3279.6194],\n",
      "        [    0.0000, -4779.3999,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1650.8534, -1647.2494],\n",
      "        [ 2364.0703,     0.0000, -3288.0640],\n",
      "        [    0.0000, -4792.9468,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   901.3052, -1651.8336],\n",
      "        [ 4570.5156,     0.0000, -3297.2144],\n",
      "        [-6665.8711,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1660.8816,     0.0000],\n",
      "        [ 2377.5720,     0.0000, -2367.2412],\n",
      "        [    0.0000, -4822.1685,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1665.9067, -1660.4419],\n",
      "        [ 2384.0073,     0.0000, -3314.4048],\n",
      "        [    0.0000, -4836.8188,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1671.2683, -1664.6923],\n",
      "        [ 2390.2759,     0.0000, -3322.8965],\n",
      "        [    0.0000, -4852.4570,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   908.2809, -1670.6062],\n",
      "        [ 4626.3975,     0.0000, -3334.7073],\n",
      "        [-6747.3643,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1682.1227, -1673.3854],\n",
      "        [    0.0000,     0.0000, -3340.2622],\n",
      "        [-3712.1826, -4884.1201,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   911.1599, -1679.0610],\n",
      "        [ 4650.8062,     0.0000, -3351.5981],\n",
      "        [-6782.9678,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:43:12,108 - INFO - Iter 550: Z_norm=19.2686, Theta_norm=8.0185, log_joint=-38595.8867, grad_Z_norm=1.5207e+03, grad_Theta_norm=6.9137e+03\n",
      "2025-06-17 11:43:12,109 - INFO -     grad_Theta (sample from iter 550):\n",
      "2025-06-17 11:43:12,109 - INFO - tensor([[    0.0000,  1708.9723, -1695.9181],\n",
      "        [ 2432.4299,     0.0000, -3385.2715],\n",
      "        [    0.0000, -4962.4390,     0.0000]])\n",
      "2025-06-17 11:43:12,110 - INFO -     Annealed: alpha=0.100, beta=1.550, tau=1.000\n",
      "2025-06-17 11:43:12,110 - INFO -     Current Edge Probs (from Z, alpha=0.100):\n",
      "2025-06-17 11:43:12,111 - INFO - tensor([[0.0000, 0.9962, 0.9960],\n",
      "        [0.9991, 0.0000, 0.9923],\n",
      "        [0.9956, 0.9550, 0.0000]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient:\n",
      " tensor([[    0.0000,  1692.6984, -1682.2850],\n",
      "        [ 2414.5959,     0.0000, -3358.0396],\n",
      "        [    0.0000, -4914.9653,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1698.0876, -1686.7966],\n",
      "        [ 2420.5220,     0.0000, -3367.0518],\n",
      "        [    0.0000, -4930.6855,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   915.1443, -1691.4490],\n",
      "        [ 4686.0049,     0.0000, -3376.3440],\n",
      "        [-6834.3208,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1708.9723, -1695.9181],\n",
      "        [ 2432.4299,     0.0000, -3385.2715],\n",
      "        [    0.0000, -4962.4390,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   919.0263, -1702.1460],\n",
      "        [ 4715.7134,     0.0000, -3397.7087],\n",
      "        [-6877.6572,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1719.1893, -1704.7817],\n",
      "        [ 2444.1052,     0.0000, -3402.9756],\n",
      "        [    0.0000, -4992.2437,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   921.1741, -1709.7865],\n",
      "        [ 4737.2925,     0.0000, -3412.9709],\n",
      "        [-6909.1377,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   923.5366, -1716.0854],\n",
      "        [ 4755.5439,     0.0000, -3425.5498],\n",
      "        [-6935.7642,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   924.7761, -1720.3982],\n",
      "        [ 4769.2144,     0.0000, -3434.1638],\n",
      "        [-6955.7134,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   925.4818,  -940.4109],\n",
      "        [ 4781.1689,     0.0000,     0.0000],\n",
      "        [-6973.1646,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1742.5583, -1728.1104],\n",
      "        [ 2477.2473,     0.0000, -3449.5635],\n",
      "        [    0.0000, -5060.3267,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1746.9021, -1732.4672],\n",
      "        [ 2483.9246,     0.0000, -3458.2605],\n",
      "        [    0.0000, -5072.9771,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   930.5867, -1738.5295],\n",
      "        [ 4831.0928,     0.0000, -3470.3623],\n",
      "        [-7046.0171,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   930.9083, -1740.9387],\n",
      "        [ 4840.3540,     0.0000, -3475.1726],\n",
      "        [-7059.5361,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000, -1745.7821],\n",
      "        [ 4857.0527,     0.0000, -3484.8420],\n",
      "        [-7083.9067,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   933.7087, -1750.2852],\n",
      "        [ 2510.8591,     0.0000, -3493.8323],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   936.5502, -1757.8718],\n",
      "        [ 4897.0659,     0.0000, -3508.9780],\n",
      "        [-7142.2983,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1770.2052, -1759.3657],\n",
      "        [ 2524.4709,     0.0000, -3511.9619],\n",
      "        [    0.0000, -5140.7988,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   939.0097, -1767.0099],\n",
      "        [ 4927.7388,     0.0000, -3527.2231],\n",
      "        [-7187.0601,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   940.2493, -1771.6055],\n",
      "        [ 4943.2612,     0.0000, -3536.3982],\n",
      "        [-7209.7144,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   939.4304, -1772.3732],\n",
      "        [ 4948.7124,     0.0000, -3537.9336],\n",
      "        [-7217.6826,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   941.0841, -1777.8507],\n",
      "        [ 4967.8389,     0.0000, -3548.8701],\n",
      "        [-7245.5996,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1786.1980, -1782.3617],\n",
      "        [ 2559.1013,     0.0000, -3557.8770],\n",
      "        [    0.0000, -5187.2603,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   944.3531, -1788.7017],\n",
      "        [ 5005.4409,     0.0000, -3570.5354],\n",
      "        [-7300.4824,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1792.6521, -1791.6299],\n",
      "        [ 2573.0042,     0.0000, -3576.3828],\n",
      "        [    0.0000, -5206.0078,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  9.4556e+02, -1.7955e+03],\n",
      "        [ 5.0303e+03,  0.0000e+00, -3.5841e+03],\n",
      "        [-7.3368e+03, -5.4752e-38,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1799.1423, -1800.3810],\n",
      "        [ 5046.8667,     0.0000, -3593.8564],\n",
      "        [-7360.9502, -5224.8784,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1803.4740, -1805.5183],\n",
      "        [    0.0000,     0.0000, -3604.1143],\n",
      "        [-4063.0730, -5237.4800,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   951.5361, -1813.2797],\n",
      "        [ 5088.8853,     0.0000, -3619.6101],\n",
      "        [-7422.2808,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   951.2017,     0.0000],\n",
      "        [ 5096.0396,     0.0000, -2584.5798],\n",
      "        [-7432.7422,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   954.1503, -1822.2926],\n",
      "        [ 5121.4756,     0.0000, -3637.6125],\n",
      "        [-7469.8696,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1818.2676, -1823.1488],\n",
      "        [ 2618.9495,     0.0000, -3639.3298],\n",
      "        [    0.0000, -5280.5254,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  9.5674e+02, -1.8312e+03],\n",
      "        [ 5.1542e+03,  0.0000e+00, -3.6553e+03],\n",
      "        [-7.5177e+03, -3.6084e-12,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   955.9527, -1831.6561],\n",
      "        [ 5159.3340,     0.0000, -3656.3259],\n",
      "        [-7525.1636,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   958.5331, -1838.6671],\n",
      "        [ 5183.1860,     0.0000, -3670.3276],\n",
      "        [-7559.9795,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   960.5195, -1844.6085],\n",
      "        [ 5204.3843,     0.0000, -3682.1938],\n",
      "        [-7590.9258,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1837.1877, -1847.6650],\n",
      "        [ 2655.7456,     0.0000, -3688.3008],\n",
      "        [    0.0000, -5335.5000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   961.3293, -1850.4128],\n",
      "        [ 5228.8789,     0.0000, -3693.7908],\n",
      "        [-7626.7026,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1842.0760, -1854.9298],\n",
      "        [    0.0000,     0.0000, -3702.8123],\n",
      "        [-4221.1191, -5349.7031,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   963.4682, -1858.6676],\n",
      "        [ 5258.8125,     0.0000, -3710.2783],\n",
      "        [-7670.4146,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1849.2360, -1863.9822],\n",
      "        [ 2679.0867,     0.0000, -3720.8914],\n",
      "        [    0.0000, -5370.5220,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1853.1661, -1868.5159],\n",
      "        [ 2685.1584,     0.0000, -3729.9456],\n",
      "        [    0.0000, -5381.9609,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   969.5420, -1876.3198],\n",
      "        [ 5315.1191,     0.0000, -3745.5273],\n",
      "        [-7752.6094,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   969.1921, -1877.5883],\n",
      "        [ 5320.3511,     0.0000, -3748.0627],\n",
      "        [-7760.2593,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   972.1815, -1885.3912],\n",
      "        [ 5344.6797,     0.0000, -3763.6426],\n",
      "        [-7795.7646,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1868.7079,  -992.9719],\n",
      "        [ 5350.8940,     0.0000,     0.0000],\n",
      "        [-7804.8501, -5427.1909,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1872.5562, -1890.7653],\n",
      "        [ 2716.1179,     0.0000, -3774.3718],\n",
      "        [    0.0000, -5438.3906,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1876.2797, -1894.3857],\n",
      "        [ 5379.7480,     0.0000, -3781.5981],\n",
      "        [-7846.9766, -5449.2427,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1880.8237, -1898.5417],\n",
      "        [ 5394.6699,     0.0000, -3789.8936],\n",
      "        [-7868.7607, -5462.4873,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  1.8894e+03, -1.0003e+03],\n",
      "        [ 5.4209e+03,  0.0000e+00, -1.8101e-40],\n",
      "        [-7.9070e+03, -5.4876e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1890.6162, -1906.4636],\n",
      "        [ 5425.2949,     0.0000, -3805.7017],\n",
      "        [-7913.4717, -5491.0503,     0.0000]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:43:14,451 - INFO - Iter 600: Z_norm=20.5374, Theta_norm=9.0710, log_joint=-50657.9102, grad_Z_norm=2.4279e+03, grad_Theta_norm=1.0650e+04\n",
      "2025-06-17 11:43:14,452 - INFO -     grad_Theta (sample from iter 600):\n",
      "2025-06-17 11:43:14,453 - INFO - tensor([[    0.0000,   924.4783, -1804.7244],\n",
      "        [ 5148.6685,     0.0000, -3602.5996],\n",
      "        [-7510.0464,     0.0000,     0.0000]])\n",
      "2025-06-17 11:43:14,453 - INFO -     Annealed: alpha=0.100, beta=1.600, tau=1.000\n",
      "2025-06-17 11:43:14,453 - INFO -     Current Edge Probs (from Z, alpha=0.100):\n",
      "2025-06-17 11:43:14,454 - INFO - tensor([[0.0000, 0.9979, 0.9977],\n",
      "        [0.9996, 0.0000, 0.9965],\n",
      "        [0.9983, 0.9845, 0.0000]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient:\n",
      " tensor([[    0.0000,   981.7371, -1914.1653],\n",
      "        [ 5452.0308,     0.0000, -3821.0725],\n",
      "        [-7952.4922,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1901.1427, -1914.6964],\n",
      "        [    0.0000,     0.0000, -3822.1294],\n",
      "        [-4405.7407, -5521.7529,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   984.5409, -1921.9757],\n",
      "        [ 5483.1729,     0.0000, -3836.6575],\n",
      "        [-7997.9678,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   984.1990, -1922.6094],\n",
      "        [ 5489.1323,     0.0000, -3837.9199],\n",
      "        [-8006.6890,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  1.9152e+03, -1.0065e+03],\n",
      "        [ 5.5050e+03,  0.0000e+00, -1.4204e-10],\n",
      "        [-8.0298e+03, -5.5628e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1919.8116,     0.0000],\n",
      "        [ 5520.9883,     0.0000, -2742.3157],\n",
      "        [-8053.2134, -5576.1914,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   989.9736, -1937.1859],\n",
      "        [ 5546.7695,     0.0000, -3867.0105],\n",
      "        [-8090.8481,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   994.2805, -1928.8250],\n",
      "        [ 5545.9829,     0.0000, -3837.3560],\n",
      "        [-8089.7305,   -36.0250,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   990.8636, -1941.0682],\n",
      "        [ 5570.0771,     0.0000, -3874.7605],\n",
      "        [-8124.9053,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   993.0588, -1946.6511],\n",
      "        [ 5592.1748,     0.0000, -3885.9058],\n",
      "        [-8157.1699,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  9.9585e+02, -1.9499e+03],\n",
      "        [ 5.6110e+03,  0.0000e+00, -3.8897e+03],\n",
      "        [-8.1847e+03, -7.3333e+00,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1454.7020, -1501.5547],\n",
      "        [ 5627.7148,     0.0000, -2017.5546],\n",
      "        [-8209.0703, -2730.0171,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   995.2703, -1955.2679],\n",
      "        [ 5635.5010,     0.0000, -3903.1064],\n",
      "        [-8220.4580,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   997.8083, -1961.7305],\n",
      "        [ 5660.5186,     0.0000, -3916.0056],\n",
      "        [-8256.9824,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,   999.7283, -1967.0809],\n",
      "        [ 5682.2661,     0.0000, -3926.6855],\n",
      "        [-8288.7354,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1955.0115, -1966.9149],\n",
      "        [ 5687.9985,     0.0000, -3926.3540],\n",
      "        [-8297.1270, -5678.6255,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1000.2471, -1971.3313],\n",
      "        [ 5706.8442,     0.0000, -3935.1689],\n",
      "        [-8324.6475,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1001.3683, -1975.1947],\n",
      "        [ 5724.0303,     0.0000, -3942.8806],\n",
      "        [-8349.7461,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  1.9642e+03, -1.0240e+03],\n",
      "        [ 5.7412e+03,  0.0000e+00, -2.0739e-29],\n",
      "        [-8.3749e+03, -5.7053e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1967.2948, -1982.6614],\n",
      "        [ 2870.2043,     0.0000, -3957.7815],\n",
      "        [    0.0000, -5714.3018,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  1.9709e+03, -1.0265e+03],\n",
      "        [ 5.7742e+03,  0.0000e+00, -9.7231e-33],\n",
      "        [-8.4230e+03, -5.7248e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1974.8578, -1989.7167],\n",
      "        [ 2882.9741,     0.0000, -3971.8550],\n",
      "        [    0.0000, -5736.3252,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1979.2206,     0.0000],\n",
      "        [ 5804.7305,     0.0000, -2826.8982],\n",
      "        [-8467.5859, -5749.0435,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[ 0.0000e+00,  1.9838e+03, -1.0300e+03],\n",
      "        [ 5.8195e+03,  0.0000e+00, -1.2332e-18],\n",
      "        [-8.4892e+03, -5.7624e+03,  0.0000e+00]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1011.8139, -2003.1107],\n",
      "        [ 5844.6675,     0.0000, -3998.5818],\n",
      "        [-8525.8779,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1993.0283, -2002.8030],\n",
      "        [ 2907.6338,     0.0000, -3997.9644],\n",
      "        [    0.0000, -5789.3164,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1013.6695, -2008.0435],\n",
      "        [ 5869.3555,     0.0000, -4008.4224],\n",
      "        [-8561.9238,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2001.5874, -2008.9224],\n",
      "        [ 5876.3652,     0.0000, -4010.1743],\n",
      "        [-8572.1641, -5814.2871,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1016.2833, -2014.8672],\n",
      "        [ 5898.2100,     0.0000, -4022.0383],\n",
      "        [-8604.0459,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2010.3650, -2015.8232],\n",
      "        [ 5905.5225,     0.0000, -4023.9448],\n",
      "        [-8614.7295, -5839.8809,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2015.3781, -1037.9840],\n",
      "        [ 5922.0312,     0.0000,     0.0000],\n",
      "        [-8638.8301, -5854.4937,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1020.9385, -2026.6577],\n",
      "        [ 5947.2358,     0.0000, -4045.5662],\n",
      "        [-8675.6172,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1022.1976, -2029.9595],\n",
      "        [ 5962.3159,     0.0000, -4052.1528],\n",
      "        [-8697.6348,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2027.5806, -2029.1926],\n",
      "        [ 5965.3848,     0.0000, -4050.6167],\n",
      "        [-8702.1318, -5890.0811,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2032.3363, -2033.1873],\n",
      "        [    0.0000,     0.0000, -4058.5886],\n",
      "        [-4868.8579, -5903.9395,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1024.1624, -2036.6979],\n",
      "        [ 5996.6792,     0.0000, -4065.5938],\n",
      "        [-8747.8281,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1025.4092, -2040.2563],\n",
      "        [ 6011.2432,     0.0000, -4072.6941],\n",
      "        [-8769.0986,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1026.6132, -2043.8569],\n",
      "        [ 6026.0039,     0.0000, -4079.8794],\n",
      "        [-8790.6553,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2047.8057, -2046.8823],\n",
      "        [ 6039.1299,     0.0000, -4085.9172],\n",
      "        [-8809.8311, -5949.0303,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1030.7614, -2054.6919],\n",
      "        [ 6066.3823,     0.0000, -4101.5044],\n",
      "        [-8849.6084,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1030.1206, -2054.7742],\n",
      "        [ 6070.8696,     0.0000, -4101.6675],\n",
      "        [-8856.1787,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1032.2251, -2060.4275],\n",
      "        [ 6091.8521,     0.0000, -4112.9512],\n",
      "        [-8886.8125,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1033.3138, -2064.1392],\n",
      "        [ 6107.1318,     0.0000, -4120.3594],\n",
      "        [-8909.1270,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2064.1328, -2065.2783],\n",
      "        [ 6114.8198,     0.0000, -4122.6323],\n",
      "        [-8920.3662, -5996.5391,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1034.4805, -2069.5972],\n",
      "        [ 6131.8916,     0.0000, -4131.2534],\n",
      "        [-8945.2959,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2070.1509, -2072.7000],\n",
      "        [ 6145.3789,     0.0000, -4137.4453],\n",
      "        [-8964.9941, -6014.0376,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1037.6362, -2078.9998],\n",
      "        [ 6168.3193,     0.0000, -4150.0210],\n",
      "        [-8998.4854,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2076.3547, -2080.1045],\n",
      "        [ 6175.8623,     0.0000, -4152.2256],\n",
      "        [-9009.5137, -6032.0840,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1038.8149, -2084.4104],\n",
      "        [ 6192.8711,     0.0000, -4160.8213],\n",
      "        [-9034.3486,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2083.3245, -2088.1128],\n",
      "        [ 3050.3215,     0.0000, -4168.2114],\n",
      "        [    0.0000, -6052.3623,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2086.2651, -2091.2776],\n",
      "        [ 6220.3354,     0.0000, -4174.5293],\n",
      "        [-9074.4531, -6060.9316,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1042.2070, -2095.6528],\n",
      "        [ 6236.2803,     0.0000, -4183.2627],\n",
      "        [-9097.7334,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:43:16,812 - INFO - Iter 650: Z_norm=21.6231, Theta_norm=10.0496, log_joint=-63484.8828, grad_Z_norm=1.0110e+03, grad_Theta_norm=1.3619e+04\n",
      "2025-06-17 11:43:16,812 - INFO -     grad_Theta (sample from iter 650):\n",
      "2025-06-17 11:43:16,813 - INFO - tensor([[    0.0000,  1537.2515, -1541.0668],\n",
      "        [ 4588.1870,     0.0000, -3076.2192],\n",
      "        [-6693.4443, -4466.0039,     0.0000]])\n",
      "2025-06-17 11:43:16,814 - INFO -     Annealed: alpha=0.100, beta=1.650, tau=1.000\n",
      "2025-06-17 11:43:16,814 - INFO -     Current Edge Probs (from Z, alpha=0.100):\n",
      "2025-06-17 11:43:16,814 - INFO - tensor([[0.0000, 0.9988, 0.9986],\n",
      "        [0.9998, 0.0000, 0.9984],\n",
      "        [0.9992, 0.9936, 0.0000]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient:\n",
      " tensor([[    0.0000,  2093.5889, -2098.7849],\n",
      "        [ 6248.6699,     0.0000, -4189.5151],\n",
      "        [-9115.8281, -6082.2686,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2097.9795, -2103.1340],\n",
      "        [ 3073.3127,     0.0000, -4198.1968],\n",
      "        [    0.0000, -6095.0576,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2102.1758, -1067.2626],\n",
      "        [ 6277.9536,     0.0000,     0.0000],\n",
      "        [-9158.5762, -6107.2944,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2106.5818, -1068.4589],\n",
      "        [ 6291.3018,     0.0000,     0.0000],\n",
      "        [-9178.0635, -6120.1484,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2110.5437, -2113.0037],\n",
      "        [ 6302.9072,     0.0000, -4217.8892],\n",
      "        [-9195.0078, -6131.7178,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2115.8953,     0.0000],\n",
      "        [ 6318.3174,     0.0000, -2992.4817],\n",
      "        [-9217.5049, -6147.3296,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1050.8010, -2119.9265],\n",
      "        [ 6331.9268,     0.0000, -4231.7017],\n",
      "        [-9237.3730,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1052.0367, -2123.0691],\n",
      "        [ 6345.7246,     0.0000, -4237.9751],\n",
      "        [-9257.5195,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2129.2903, -2126.2773],\n",
      "        [ 3112.5215,     0.0000, -4244.3784],\n",
      "        [    0.0000, -6186.4165,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1054.4803, -2129.6248],\n",
      "        [ 6372.6357,     0.0000, -4251.0605],\n",
      "        [-9296.8057,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1057.5249, -2136.7307],\n",
      "        [ 6396.9575,     0.0000, -4265.2451],\n",
      "        [-9332.3008,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1056.8467, -2136.4402],\n",
      "        [ 6399.2432,     0.0000, -4264.6655],\n",
      "        [-9335.6484,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1057.9683, -2139.8992],\n",
      "        [ 6412.8447,     0.0000, -4271.5693],\n",
      "        [-9355.5059,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2148.3474, -1079.5510],\n",
      "        [ 6426.6113,     0.0000,     0.0000],\n",
      "        [-9375.6045, -6241.9565,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1060.1730, -2146.5862],\n",
      "        [ 6440.4326,     0.0000, -4284.9150],\n",
      "        [-9395.7832,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2154.4526, -2149.1985],\n",
      "        [ 6452.4600,     0.0000, -4290.1255],\n",
      "        [-9413.3438, -6259.7393,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1062.3650, -2153.1001],\n",
      "        [ 6468.2891,     0.0000, -4297.9121],\n",
      "        [-9436.4551,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2169.6362, -2164.1997],\n",
      "        [ 6505.7363,     0.0000, -4320.0664],\n",
      "        [-9491.1016, -6303.8994,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1064.5382, -2159.7119],\n",
      "        [ 6496.2642,     0.0000, -4311.1064],\n",
      "        [-9477.3008,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2168.5283, -2163.0581],\n",
      "        [ 3174.5261,     0.0000, -4317.7837],\n",
      "        [    0.0000, -6300.7256,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1066.7476, -2166.5283],\n",
      "        [ 6523.3486,     0.0000, -4324.7100],\n",
      "        [-9516.8438,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1067.8522, -2170.0203],\n",
      "        [ 6536.5708,     0.0000, -4331.6782],\n",
      "        [-9536.1465,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2186.6729, -2181.3853],\n",
      "        [ 6573.6338,     0.0000, -4354.3643],\n",
      "        [-9590.2334, -6353.5151,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2190.0981, -2184.8835],\n",
      "        [ 6587.0605,     0.0000, -4361.3462],\n",
      "        [-9609.8311, -6363.4907,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1071.1327, -2180.4783],\n",
      "        [ 6576.7002,     0.0000, -4352.5513],\n",
      "        [-9594.7324,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1074.0803, -2187.7656],\n",
      "        [ 6601.6885,     0.0000, -4367.0972],\n",
      "        [-9631.2021,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2200.2393, -2195.3645],\n",
      "        [ 6627.7021,     0.0000, -4382.2656],\n",
      "        [-9669.1689, -6393.0293,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2203.6162, -2198.8501],\n",
      "        [ 6641.3276,     0.0000, -4389.2217],\n",
      "        [-9689.0635, -6402.8633,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2207.2297, -2202.3120],\n",
      "        [ 6654.9053,     0.0000, -4396.1323],\n",
      "        [-9708.8867, -6413.3965,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2211.0544, -2205.7524],\n",
      "        [ 6668.4326,     0.0000, -4402.9990],\n",
      "        [-9728.6387, -6424.5483,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2215.0664, -2209.1724],\n",
      "        [ 6681.9160,     0.0000, -4409.8262],\n",
      "        [-9748.3271, -6436.2505,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2219.2441, -2212.5737],\n",
      "        [ 6695.3560,     0.0000, -4416.6157],\n",
      "        [-9767.9521, -6448.4429,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2223.5708, -2215.9587],\n",
      "        [ 6708.7529,     0.0000, -4423.3711],\n",
      "        [-9787.5156, -6461.0713,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2220.0039,     0.0000],\n",
      "        [ 6697.9043,     0.0000, -3119.6082],\n",
      "        [-9771.7041, -6450.7676,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2232.6201, -2222.5190],\n",
      "        [ 6735.4756,     0.0000, -4436.4727],\n",
      "        [-9826.5361, -6487.4922,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2229.2563,     0.0000],\n",
      "        [ 6724.4961,     0.0000, -3128.4053],\n",
      "        [-9810.5322, -6477.7856,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000, -2220.7246],\n",
      "        [ 6737.7749,     0.0000, -4432.9009],\n",
      "        [-9829.9219, -4268.2690,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2238.6526, -1106.2668],\n",
      "        [ 6751.1021,     0.0000,     0.0000],\n",
      "        [-9849.3818, -6505.2383,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,     0.0000, -2226.6099],\n",
      "        [ 6764.4497,     0.0000, -4444.6587],\n",
      "        [-9868.8721, -4289.3003,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2256.0820, -2237.5486],\n",
      "        [ 6802.3271,     0.0000, -4466.4971],\n",
      "        [-9924.1504, -6556.0537,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1089.0957, -2232.4026],\n",
      "        [ 6791.1499,     0.0000, -4456.2271],\n",
      "        [-9907.8613,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2265.0503, -2243.4619],\n",
      "        [ 6829.1572,     0.0000, -4478.3057],\n",
      "        [-9963.3291, -6582.2764,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  1091.1431, -2238.3828],\n",
      "        [ 6817.9067,     0.0000, -4468.1694],\n",
      "        [-9946.9326,     0.0000,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2265.3235,     0.0000],\n",
      "        [ 6831.3359,     0.0000, -3161.2136],\n",
      "        [-9966.5430, -6583.2095,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2269.5242, -2244.3503],\n",
      "        [ 3309.7798,     0.0000, -4480.0894],\n",
      "        [    0.0000, -6595.4819,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2282.3252,  -2255.5566],\n",
      "        [  6881.9355,      0.0000,  -4502.4639],\n",
      "        [-10040.3936,  -6632.7578,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2278.7761,      0.0000],\n",
      "        [  6869.5977,      0.0000,  -3173.8848],\n",
      "        [-10022.4062,  -6622.5171,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2291.7949,  -2261.6079],\n",
      "        [  6906.9756,      0.0000,  -4514.5566],\n",
      "        [-10076.9492,  -6660.4302,      0.0000]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:43:19,394 - INFO - Iter 700: Z_norm=22.4514, Theta_norm=10.9516, log_joint=-76318.0547, grad_Z_norm=3.3869e+03, grad_Theta_norm=1.3954e+04\n",
      "2025-06-17 11:43:19,394 - INFO -     grad_Theta (sample from iter 700):\n",
      "2025-06-17 11:43:19,395 - INFO - tensor([[    0.0000,     0.0000, -1621.5155],\n",
      "        [ 4957.6777,     0.0000, -3236.8372],\n",
      "        [-7233.0391, -3161.9846,     0.0000]])\n",
      "2025-06-17 11:43:19,396 - INFO -     Annealed: alpha=0.100, beta=1.700, tau=1.000\n",
      "2025-06-17 11:43:19,396 - INFO -     Current Edge Probs (from Z, alpha=0.100):\n",
      "2025-06-17 11:43:19,397 - INFO - tensor([[0.0000, 0.9993, 0.9992],\n",
      "        [0.9999, 0.0000, 0.9990],\n",
      "        [0.9996, 0.9968, 0.0000]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient:\n",
      " tensor([[    0.0000,  2288.3735, -2256.4233],\n",
      "        [ 3330.3640,     0.0000, -4504.2148],\n",
      "        [    0.0000, -6650.5649,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1099.0072,  -2259.5522],\n",
      "        [  6906.2417,      0.0000,  -4510.4673],\n",
      "        [-10075.9023,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,      0.0000,  -2262.7212],\n",
      "        [  6918.1221,      0.0000,  -4516.7993],\n",
      "        [-10093.2432,  -4412.3472,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2311.0659,  -2274.0991],\n",
      "        [  6955.2056,      0.0000,  -4539.5166],\n",
      "        [-10147.3545,  -6716.7471,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1102.3435,  -2269.0916],\n",
      "        [  6942.2393,      0.0000,  -4529.5264],\n",
      "        [-10128.4492,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2319.9390,  -2280.5195],\n",
      "        [  6979.6494,      0.0000,  -4552.3433],\n",
      "        [-10183.0410,  -6742.6768,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1106.3849,  -2279.4773],\n",
      "        [  6978.9468,      0.0000,  -4550.2666],\n",
      "        [-10182.0264,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1105.4921,  -2278.7478],\n",
      "        [  6979.2656,      0.0000,  -4548.8140],\n",
      "        [-10182.5049,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2331.9609,  -2290.2568],\n",
      "        [  7017.1396,      0.0000,  -4571.7915],\n",
      "        [-10237.7734,  -6777.7832,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2335.8042,  -2293.5149],\n",
      "        [  7029.7627,      0.0000,  -4578.2964],\n",
      "        [-10256.2051,  -6789.0020,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2339.8037,  -2296.7578],\n",
      "        [  7042.3628,      0.0000,  -4584.7725],\n",
      "        [-10274.6006,  -6800.6816,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1109.6339,  -2291.7041],\n",
      "        [  7029.5317,      0.0000,  -4574.6875],\n",
      "        [-10255.8955,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2347.7378,  -2303.2422],\n",
      "        [  7067.6396,      0.0000,  -4597.7227],\n",
      "        [-10311.5098,  -6823.8447,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2351.6926,  -2306.4824],\n",
      "        [  7080.3037,      0.0000,  -4604.1909],\n",
      "        [-10330.0000,  -6835.3887,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2355.7891,  -2309.7078],\n",
      "        [  7092.9277,      0.0000,  -4610.6318],\n",
      "        [-10348.4336,  -6847.3506,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2360.0107,  -2312.9199],\n",
      "        [  7105.5166,      0.0000,  -4617.0435],\n",
      "        [-10366.8105,  -6859.6782,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1114.9973,  -2307.7788],\n",
      "        [  7092.4365,      0.0000,  -4606.7822],\n",
      "        [-10347.7432,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2368.3154,  -2319.3462],\n",
      "        [  7130.7427,      0.0000,  -4629.8745],\n",
      "        [-10403.6465,  -6883.9248,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2372.4233,  -2322.5583],\n",
      "        [  7143.3652,      0.0000,  -4636.2876],\n",
      "        [-10422.0781,  -6895.9175,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1118.2493,  -2317.3813],\n",
      "        [  7130.1743,      0.0000,  -4625.9536],\n",
      "        [-10402.8477,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2371.9565, -2320.5940],\n",
      "        [ 3432.0383,     0.0000, -4632.3672],\n",
      "        [    0.0000, -6894.6626,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1120.4507,  -2323.9517],\n",
      "        [  7154.5601,      0.0000,  -4639.0693],\n",
      "        [-10438.4502,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2388.7644,  -2335.7271],\n",
      "        [  7192.3931,      0.0000,  -4662.5752],\n",
      "        [-10493.6562,  -6943.6152,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1122.6569,  -2330.6477],\n",
      "        [  7178.4346,      0.0000,  -4652.4370],\n",
      "        [-10473.3047,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2396.5728,  -2342.4233],\n",
      "        [  7216.5273,      0.0000,  -4675.9438],\n",
      "        [-10528.8936,  -6966.3984,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1124.8069,  -2337.2979],\n",
      "        [  7202.6353,      0.0000,  -4665.7124],\n",
      "        [-10508.6367,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2404.0339,  -2349.0771],\n",
      "        [  7240.9468,      0.0000,  -4689.2271],\n",
      "        [-10564.5459,  -6988.1602,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2407.7756,  -2352.3794],\n",
      "        [  7253.1992,      0.0000,  -4695.8184],\n",
      "        [-10582.4346,  -6999.0767,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1127.9907,  -2347.1719],\n",
      "        [  7239.2632,      0.0000,  -4685.4224],\n",
      "        [-10562.1152,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2415.2434,  -2358.9443],\n",
      "        [  7277.7773,      0.0000,  -4708.9214],\n",
      "        [-10618.3223,  -7020.8604,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2418.9854,  -2362.2068],\n",
      "        [  7290.0879,      0.0000,  -4715.4346],\n",
      "        [-10636.2949,  -7031.7764,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1131.1620,  -2356.9272],\n",
      "        [  7276.0645,      0.0000,  -4704.8950],\n",
      "        [-10615.8477,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2417.7129,      0.0000],\n",
      "        [  7288.4053,      0.0000,  -3323.9609],\n",
      "        [-10633.8662,  -7028.1543,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2430.2083,  -2371.7793],\n",
      "        [  7327.1230,      0.0000,  -4734.5464],\n",
      "        [-10690.3691,  -7064.5146,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2434.1116,  -2374.8513],\n",
      "        [  7339.4482,      0.0000,  -4740.6836],\n",
      "        [-10708.3652,  -7075.9053,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2438.1460,  -2377.9180],\n",
      "        [  7351.7261,      0.0000,  -4746.8076],\n",
      "        [-10726.2949,  -7087.6826,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2442.2964,  -2380.9785],\n",
      "        [  7363.9600,      0.0000,  -4752.9214],\n",
      "        [-10744.1611,  -7099.7988,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2446.5503,  -2384.0352],\n",
      "        [  7376.1523,      0.0000,  -4759.0220],\n",
      "        [-10761.9619,  -7112.2188,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2450.8962,  -2387.0852],\n",
      "        [  7388.3066,      0.0000,  -4765.1143],\n",
      "        [-10779.7109,  -7124.9092,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2455.3232,  -2390.1311],\n",
      "        [  7400.4233,      0.0000,  -4771.1973],\n",
      "        [-10797.4004,  -7137.8374,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2459.8232,  -2393.1729],\n",
      "        [  7412.5049,      0.0000,  -4777.2695],\n",
      "        [-10815.0400,  -7150.9785,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2464.3862,  -2396.2095],\n",
      "        [  7424.5532,      0.0000,  -4783.3315],\n",
      "        [-10832.6328,  -7164.3086,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2469.0061,  -2399.2412],\n",
      "        [  7436.5713,      0.0000,  -4789.3857],\n",
      "        [-10850.1836,  -7177.8057,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2464.7676,  -1161.0754],\n",
      "        [  7421.7358,      0.0000,      0.0000],\n",
      "        [-10828.5527,  -7165.5498,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2478.4177,  -2405.0474],\n",
      "        [  7460.5830,      0.0000,  -4800.9746],\n",
      "        [-10885.2461,  -7205.2998,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1146.8663,  -2399.1763],\n",
      "        [  7445.6631,      0.0000,  -4789.2524],\n",
      "        [-10863.4902,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2487.5620,  -2410.7034],\n",
      "        [  7484.6753,      0.0000,  -4812.2617],\n",
      "        [-10920.4238,  -7232.0127,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2483.0288,      0.0000],\n",
      "        [  7469.7349,      0.0000,  -3384.8579],\n",
      "        [-10898.6416,  -7218.8921,      0.0000]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:43:21,735 - INFO - Iter 750: Z_norm=23.1398, Theta_norm=11.8150, log_joint=-89633.6328, grad_Z_norm=1.1992e+03, grad_Theta_norm=1.0070e+04\n",
      "2025-06-17 11:43:21,736 - INFO -     grad_Theta (sample from iter 750):\n",
      "2025-06-17 11:43:21,737 - INFO - tensor([[    0.0000,  2488.6245, -2401.8704],\n",
      "        [ 3563.2915,     0.0000, -4794.6367],\n",
      "        [    0.0000, -7235.4805,     0.0000]])\n",
      "2025-06-17 11:43:21,738 - INFO -     Annealed: alpha=0.100, beta=1.750, tau=1.000\n",
      "2025-06-17 11:43:21,738 - INFO -     Current Edge Probs (from Z, alpha=0.100):\n",
      "2025-06-17 11:43:21,739 - INFO - tensor([[0.0000, 0.9996, 0.9994],\n",
      "        [0.9999, 0.0000, 0.9994],\n",
      "        [0.9997, 0.9982, 0.0000]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient:\n",
      " tensor([[     0.0000,   2496.5266,  -2416.2998],\n",
      "        [  7508.7842,      0.0000,  -4823.4351],\n",
      "        [-10955.6309,  -7258.1929,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2501.1045,  -2419.0532],\n",
      "        [  7520.7935,      0.0000,  -4828.9326],\n",
      "        [-10973.1650,  -7271.5693,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2505.7322,  -2421.8291],\n",
      "        [  7532.7588,      0.0000,  -4834.4746],\n",
      "        [-10990.6367,  -7285.0874,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2510.4033,  -2424.6235],\n",
      "        [  7544.6860,      0.0000,  -4840.0537],\n",
      "        [-11008.0557,  -7298.7324,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[    0.0000,  2506.0554, -2418.6936],\n",
      "        [ 3588.2495,     0.0000, -4828.2192],\n",
      "        [    0.0000, -7286.1592,     0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1156.1389,  -2421.6865],\n",
      "        [  7540.3896,      0.0000,  -4834.1948],\n",
      "        [-11001.8076,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2524.7495,  -2433.4749],\n",
      "        [  7578.9043,      0.0000,  -4857.7275],\n",
      "        [-11058.0117,  -7340.6421,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1155.9915,  -2422.4768],\n",
      "        [  7546.5005,      0.0000,  -4835.7744],\n",
      "        [-11010.7422,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1159.6226,  -2430.7737],\n",
      "        [  7574.2744,      0.0000,  -4852.3374],\n",
      "        [-11051.2764,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2528.3835,      0.0000],\n",
      "        [  7585.8384,      0.0000,  -3424.3838],\n",
      "        [-11068.1602,  -7351.3618,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2532.3872,      0.0000],\n",
      "        [  7597.4277,      0.0000,  -3428.4248],\n",
      "        [-11085.0801,  -7363.0454,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2536.5071,      0.0000],\n",
      "        [  7609.0361,      0.0000,  -3432.3516],\n",
      "        [-11102.0283,  -7375.0728,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2549.9143,  -2450.9702],\n",
      "        [  7648.2041,      0.0000,  -4892.6768],\n",
      "        [-11159.1914,  -7414.1055,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2545.0312,      0.0000],\n",
      "        [  7632.2617,      0.0000,  -3440.0105],\n",
      "        [-11135.9404,  -7399.9604,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2558.6299,  -2456.1848],\n",
      "        [  7671.5029,      0.0000,  -4903.1089],\n",
      "        [-11193.2080,  -7439.5557,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2563.0872,  -2458.7703],\n",
      "        [  7683.1318,      0.0000,  -4908.2822],\n",
      "        [-11210.1895,  -7452.5752,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2567.5967,  -2461.3894],\n",
      "        [  7694.7373,      0.0000,  -4913.5195],\n",
      "        [-11227.1328,  -7465.7451,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2572.1519,  -2464.0405],\n",
      "        [  7706.3149,      0.0000,  -4918.8213],\n",
      "        [-11244.0391,  -7479.0488,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2576.7466,  -2466.7185],\n",
      "        [  7717.8711,      0.0000,  -4924.1758],\n",
      "        [-11260.9092,  -7492.4722,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1172.0243,  -2460.5283],\n",
      "        [  7701.5698,      0.0000,  -4911.8262],\n",
      "        [-11237.1377,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2585.6091,  -2472.1833],\n",
      "        [  7741.0605,      0.0000,  -4935.0977],\n",
      "        [-11294.7676,  -7518.3574,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2589.9141,  -2474.9609],\n",
      "        [  7752.6797,      0.0000,  -4940.6489],\n",
      "        [-11311.7324,  -7530.9277,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2594.2812,  -2477.7524],\n",
      "        [  7764.2651,      0.0000,  -4946.2256],\n",
      "        [-11328.6504,  -7543.6841,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2598.7063,  -2480.5544],\n",
      "        [  7775.8184,      0.0000,  -4951.8242],\n",
      "        [-11345.5205,  -7556.6079,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2603.1821,  -2483.3677],\n",
      "        [  7787.3418,      0.0000,  -4957.4438],\n",
      "        [-11362.3496,  -7569.6787,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2607.7004,  -2486.1907],\n",
      "        [  7798.8384,      0.0000,  -4963.0811],\n",
      "        [-11379.1348,  -7582.8799,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2612.2590,  -2489.0203],\n",
      "        [  7810.3047,      0.0000,  -4968.7334],\n",
      "        [-11395.8779,  -7596.1963,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1181.0217,  -2482.8840],\n",
      "        [  7793.5801,      0.0000,  -4956.4863],\n",
      "        [-11371.4883,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2611.6106,      0.0000],\n",
      "        [  7805.1006,      0.0000,  -3497.7104],\n",
      "        [-11388.3096,  -7594.4243,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2625.3335,  -2497.4722],\n",
      "        [  7844.8711,      0.0000,  -4985.6152],\n",
      "        [-11446.3496,  -7634.3853,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2629.6802,  -2500.2227],\n",
      "        [  7856.3892,      0.0000,  -4991.1113],\n",
      "        [-11463.1699,  -7647.0776,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1185.4353,  -2493.9727],\n",
      "        [  7839.5405,      0.0000,  -4978.6387],\n",
      "        [-11438.5986,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2638.1042,  -2505.8005],\n",
      "        [  7879.4658,      0.0000,  -5002.2529],\n",
      "        [-11496.8633,  -7671.6787,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2632.7000,      0.0000],\n",
      "        [  7862.5923,      0.0000,  -3516.9827],\n",
      "        [-11472.2588,  -7656.0103,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2646.4185,  -2511.3008],\n",
      "        [  7902.5464,      0.0000,  -5013.2451],\n",
      "        [-11530.5664,  -7695.9575,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2650.6895,  -2514.0012],\n",
      "        [  7914.0391,      0.0000,  -5018.6406],\n",
      "        [-11547.3496,  -7708.4287,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2645.4583,      0.0000],\n",
      "        [  7896.9487,      0.0000,  -3528.3489],\n",
      "        [-11522.4258,  -7693.2700,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2659.4177,  -2519.3057],\n",
      "        [  7936.9385,      0.0000,  -5029.2456],\n",
      "        [-11580.7871,  -7733.9229,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1193.0946,  -2512.8401],\n",
      "        [  7919.7241,      0.0000,  -5016.3442],\n",
      "        [-11555.6836,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2667.9238,  -2524.6011],\n",
      "        [  7959.8623,      0.0000,  -5039.8306],\n",
      "        [-11614.2617,  -7758.7637,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2672.0652,  -2527.2998],\n",
      "        [  7971.3262,      0.0000,  -5045.2212],\n",
      "        [-11631.0049,  -7770.8555,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2676.2759,  -2530.0142],\n",
      "        [  7982.7495,      0.0000,  -5050.6465],\n",
      "        [-11647.6797,  -7783.1533,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2680.5503,  -2532.7444],\n",
      "        [  7994.1270,      0.0000,  -5056.1016],\n",
      "        [-11664.2930,  -7795.6348,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,      0.0000,  -2526.3564],\n",
      "        [  7976.6357,      0.0000,  -5043.3525],\n",
      "        [-11638.7842,  -5235.1323,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2689.0432,  -2538.2627],\n",
      "        [  8016.8467,      0.0000,  -5067.1255],\n",
      "        [-11697.4707,  -7820.4482,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2693.2727,  -2541.0464],\n",
      "        [  8028.1860,      0.0000,  -5072.6846],\n",
      "        [-11714.0273,  -7832.8115,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2697.5605,  -2543.8367],\n",
      "        [  8039.4878,      0.0000,  -5078.2583],\n",
      "        [-11730.5293,  -7845.3442,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2701.9009,  -2546.6338],\n",
      "        [  8050.7520,      0.0000,  -5083.8438],\n",
      "        [-11746.9756,  -7858.0283,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2706.2864,  -2549.4353],\n",
      "        [  8061.9800,      0.0000,  -5089.4370],\n",
      "        [-11763.3750,  -7870.8457,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2710.7126,  -2552.2412],\n",
      "        [  8073.1807,      0.0000,  -5095.0400],\n",
      "        [-11779.7246,  -7883.7842,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2715.1753,  -2555.0508],\n",
      "        [  8084.3486,      0.0000,  -5100.6509],\n",
      "        [-11796.0332,  -7896.8252,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2719.6689,  -2557.8645],\n",
      "        [  8095.4883,      0.0000,  -5106.2686],\n",
      "        [-11812.3037,  -7909.9590,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2724.1912,  -2560.6802],\n",
      "        [  8106.6035,      0.0000,  -5111.8892],\n",
      "        [-11828.5293,  -7923.1738,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1209.0049,  -2554.2661],\n",
      "        [  8088.4600,      0.0000,  -5099.0859],\n",
      "        [-11802.0693,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:43:24,287 - INFO - Iter 800: Z_norm=23.8411, Theta_norm=12.6343, log_joint=-103278.8906, grad_Z_norm=3.1870e+02, grad_Theta_norm=1.7614e+04\n",
      "2025-06-17 11:43:24,288 - INFO -     grad_Theta (sample from iter 800):\n",
      "2025-06-17 11:43:24,289 - INFO - tensor([[    0.0000,  1551.5604, -1457.0111],\n",
      "        [ 4615.0684,     0.0000, -2908.6338],\n",
      "        [-6733.9644, -4512.7021,     0.0000]])\n",
      "2025-06-17 11:43:24,289 - INFO -     Annealed: alpha=0.100, beta=1.800, tau=1.000\n",
      "2025-06-17 11:43:24,290 - INFO -     Current Edge Probs (from Z, alpha=0.100):\n",
      "2025-06-17 11:43:24,290 - INFO - tensor([[0.0000, 0.9997, 0.9996],\n",
      "        [1.0000, 0.0000, 0.9996],\n",
      "        [0.9998, 0.9992, 0.0000]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final gradient:\n",
      " tensor([[     0.0000,   2732.8916,  -2566.3542],\n",
      "        [  8128.9014,      0.0000,  -5123.2173],\n",
      "        [-11861.0879,  -7948.5957,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2737.1064,  -2569.2080],\n",
      "        [  8140.0708,      0.0000,  -5128.9141],\n",
      "        [-11877.4023,  -7960.9111,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2741.3767,  -2572.0591],\n",
      "        [  8151.2080,      0.0000,  -5134.6064],\n",
      "        [-11893.6621,  -7973.3848,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2745.6960,  -2574.9084],\n",
      "        [  8162.3096,      0.0000,  -5140.2935],\n",
      "        [-11909.8750,  -7986.0034,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1211.6844,  -2562.9163],\n",
      "        [  8126.3369,      0.0000,  -5116.3535],\n",
      "        [-11857.3955,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2754.0444,  -2580.6362],\n",
      "        [  8184.5713,      0.0000,  -5151.7271],\n",
      "        [-11942.3818,  -8010.3887,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2758.1086,  -2583.5112],\n",
      "        [  8195.7168,      0.0000,  -5157.4648],\n",
      "        [-11958.6562,  -8022.2583,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2762.2405,  -2586.3799],\n",
      "        [  8206.8242,      0.0000,  -5163.1914],\n",
      "        [-11974.8770,  -8034.3262,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2766.4336,  -2589.2434],\n",
      "        [  8217.8965,      0.0000,  -5168.9082],\n",
      "        [-11991.0410,  -8046.5703,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2770.6790,  -2592.1018],\n",
      "        [  8228.9355,      0.0000,  -5174.6138],\n",
      "        [-12007.1621,  -8058.9741,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   1220.6417,  -2585.6111],\n",
      "        [  8210.2705,      0.0000,  -5161.6548],\n",
      "        [-11979.9375,      0.0000,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2778.8992,  -2597.8423],\n",
      "        [  8251.0645,      0.0000,  -5186.0713],\n",
      "        [-12039.4736,  -8082.9824,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2782.9050,  -2600.7200],\n",
      "        [  8262.1455,      0.0000,  -5191.8149],\n",
      "        [-12055.6504,  -8094.6787,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2786.9814,  -2603.5908],\n",
      "        [  8273.1826,      0.0000,  -5197.5444],\n",
      "        [-12071.7734,  -8106.5845,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2791.1226,  -2606.4543],\n",
      "        [  8284.1914,      0.0000,  -5203.2598],\n",
      "        [-12087.8428,  -8118.6777,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2795.3196,  -2609.3118],\n",
      "        [  8295.1611,      0.0000,  -5208.9639],\n",
      "        [-12103.8613,  -8130.9365,      0.0000]], grad_fn=<SumBackward1>)\n",
      "Final gradient:\n",
      " tensor([[     0.0000,   2789.4851,      0.0000],\n",
      "        [  8276.1914,      0.0000,  -3658.4231],\n",
      "        [-12076.1943,  -8114.0171,      0.0000]], grad_fn=<SumBackward1>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 72\u001b[0m\n\u001b[1;32m     69\u001b[0m lj_val \u001b[38;5;241m=\u001b[39m log_joint(params_for_grad, data, hparams)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Compute gradients of log-joint w.r.t. Z and Theta\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_log_joint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_for_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m grad_z \u001b[38;5;241m=\u001b[39m grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     74\u001b[0m grad_theta \u001b[38;5;241m=\u001b[39m grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtheta\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/research/dibs_clean/models/dibs.py:294\u001b[0m, in \u001b[0;36mgrad_log_joint\u001b[0;34m(params, data, hparams)\u001b[0m\n\u001b[1;32m    291\u001b[0m z, theta \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m], params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtheta\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    293\u001b[0m grad_z \u001b[38;5;241m=\u001b[39m grad_z_log_joint_gumbel(z, theta\u001b[38;5;241m.\u001b[39mdetach(), data, hparams)\n\u001b[0;32m--> 294\u001b[0m grad_theta \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_theta_log_joint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m: grad_z, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtheta\u001b[39m\u001b[38;5;124m\"\u001b[39m: grad_theta}\n",
      "File \u001b[0;32m~/research/dibs_clean/models/dibs.py:260\u001b[0m, in \u001b[0;36mgrad_theta_log_joint\u001b[0;34m(z, theta, data, hparams)\u001b[0m\n\u001b[1;32m    258\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_samples):\n\u001b[0;32m--> 260\u001b[0m     g_soft \u001b[38;5;241m=\u001b[39m bernoulli_soft_gmat(z, hparams)\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m#print(f\"g_soft values: {g_soft}\")\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     g_hard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbernoulli(g_soft)\n",
      "File \u001b[0;32m~/research/dibs_clean/models/dibs.py:28\u001b[0m, in \u001b[0;36mbernoulli_soft_gmat\u001b[0;34m(z, hparams)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbernoulli_soft_gmat\u001b[39m(z: torch\u001b[38;5;241m.\u001b[39mTensor, hparams: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 28\u001b[0m     probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[43mscores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malpha\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     29\u001b[0m     d \u001b[38;5;241m=\u001b[39m probs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     30\u001b[0m     diag_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(d, device\u001b[38;5;241m=\u001b[39mprobs\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mprobs\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/research/dibs_clean/models/dibs.py:20\u001b[0m, in \u001b[0;36mscores\u001b[0;34m(z, alpha)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mscores\u001b[39m(z: torch\u001b[38;5;241m.\u001b[39mTensor, alpha: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     19\u001b[0m     u, v \u001b[38;5;241m=\u001b[39m z[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m], z[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 20\u001b[0m     raw_scores \u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m...ik,...jk->...ij\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;241m*\u001b[39mbatch_dims, d, _ \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     22\u001b[0m     diag_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(d, device\u001b[38;5;241m=\u001b[39mz\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mz\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/dibs_env/lib/python3.9/site-packages/torch/functional.py:402\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    404\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# ENHANCED TRAINING LOOP WITH COMPREHENSIVE MONITORING\n",
    "# ========================================================================\n",
    "# This version extends the basic training loop with:\n",
    "# 1. Edge probability tracking during training\n",
    "# 2. Parameter norm monitoring (Z and Theta norms)\n",
    "# 3. Gradient norm computation and optional clipping\n",
    "# 4. Structural Hamming Distance (SHD) computation\n",
    "# 5. Enhanced MLflow logging with multiple metrics\n",
    "# 6. Numerical stability checks (NaN/Inf detection)\n",
    "# 7. Weighted theta matrix visualization (G * Theta)\n",
    "# 8. PyTorch optimizers with proper gradient hooking\n",
    "\n",
    "log.info(\"\\n\" + \"=\"*80)\n",
    "log.info(\"STARTING ENHANCED TRAINING LOOP WITH DETAILED MONITORING\")\n",
    "log.info(\"=\"*80)\n",
    "\n",
    "# --- Enhanced Training Configuration ---\n",
    "# Reset particles for a clean experiment\n",
    "particle_enhanced = init_particle(cfg.d_nodes, cfg.k_latent, cfg.device)\n",
    "\n",
    "# Enhanced training hyperparameters\n",
    "num_iterations_enhanced = cfg.num_iterations  # Match the final iteration from your output\n",
    "lr_z_enhanced = cfg.lr          # Separate learning rate for Z\n",
    "lr_theta_enhanced = cfg.lr      # Separate learning rate for Theta  \n",
    "max_grad_norm = 10000       # Gradient clipping threshold\n",
    "logging_interval = 50          # Log every N iterations (more frequent for better monitoring)\n",
    "\n",
    "# Initialize PyTorch optimizers for enhanced training\n",
    "optimizer_z_enhanced = torch.optim.Adam([particle_enhanced['z']], lr=lr_z_enhanced)\n",
    "optimizer_theta_enhanced = torch.optim.Adam([particle_enhanced['theta']], lr=lr_theta_enhanced)\n",
    "\n",
    "# Log initial configuration\n",
    "log.info(f\"Enhanced Training Configuration:\")\n",
    "log.info(f\"  Iterations: {num_iterations_enhanced}\")\n",
    "log.info(f\"  Learning rates - Z: {lr_z_enhanced}, Theta: {lr_theta_enhanced}\")\n",
    "log.info(f\"  Gradient clipping threshold: {max_grad_norm}\")\n",
    "log.info(f\"  Logging interval: {logging_interval}\")\n",
    "log.info(f\"  Initial Z norm: {particle_enhanced['z'].norm().item():.4f}\")\n",
    "log.info(f\"  Initial Theta norm: {particle_enhanced['theta'].norm().item():.4f}\")\n",
    "\n",
    "# --- Main Enhanced Training Loop ---\n",
    "for t in range(1, num_iterations_enhanced + 1):\n",
    "    hparams = update_dibs_hparams(hparams, t)\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # STEP 1: Parameter Setup and Gradient Clearing\n",
    "    # ------------------------------------------------\n",
    "    # Clear gradients using optimizers\n",
    "    optimizer_z_enhanced.zero_grad()\n",
    "    optimizer_theta_enhanced.zero_grad()\n",
    "    \n",
    "    # Enable gradient computation for both Z and Theta parameters\n",
    "    particle_enhanced['z'].requires_grad_(True)\n",
    "    particle_enhanced['theta'].requires_grad_(True)\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # STEP 2: Forward Pass - Compute Log-Joint and Gradients\n",
    "    # ------------------------------------------------\n",
    "    # Prepare parameters dictionary for gradient computation\n",
    "    params_for_grad = {\n",
    "        \"z\": particle_enhanced['z'], \n",
    "        \"theta\": particle_enhanced['theta'], \n",
    "        \"t\": torch.tensor(float(t))  # Time step for annealing\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Compute log-joint probability (objective function)\n",
    "        lj_val = log_joint(params_for_grad, data, hparams).item()\n",
    "        \n",
    "        # Compute gradients of log-joint w.r.t. Z and Theta\n",
    "        grads = grad_log_joint(params_for_grad, data, hparams)\n",
    "        grad_z = grads['z']\n",
    "        grad_theta = grads['theta']\n",
    "        \n",
    "        # ------------------------------------------------\n",
    "        # STEP 3: Gradient Analysis and Clipping\n",
    "        # ------------------------------------------------\n",
    "        # Compute gradient norms BEFORE clipping for monitoring\n",
    "        grad_z_norm_original = grad_z.norm().item()\n",
    "        grad_theta_norm_original = grad_theta.norm().item()\n",
    "        \n",
    "        # Apply gradient clipping if gradients exceed threshold\n",
    "        grad_z_clipped = False\n",
    "        grad_theta_clipped = False\n",
    "        \n",
    "        if grad_z_norm_original > max_grad_norm:\n",
    "            grad_z = grad_z * (max_grad_norm / grad_z_norm_original)\n",
    "            grad_z_clipped = True\n",
    "            \n",
    "        if grad_theta_norm_original > max_grad_norm:\n",
    "            grad_theta = grad_theta * (max_grad_norm / grad_theta_norm_original)\n",
    "            grad_theta_clipped = True\n",
    "            \n",
    "        # Compute final gradient norms AFTER clipping\n",
    "        grad_z_norm_final = grad_z.norm().item()\n",
    "        grad_theta_norm_final = grad_theta.norm().item()\n",
    "            \n",
    "    except Exception as e:\n",
    "        log.error(f\"Error in forward pass at iteration {t}: {e}\")\n",
    "        break\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # STEP 4: Parameter Update using PyTorch Optimizers\n",
    "    # ------------------------------------------------\n",
    "    # Hook gradients into PyTorch's gradient system\n",
    "    # This is crucial: assign the computed gradients to .grad attributes\n",
    "    particle_enhanced['z'].grad = grad_z\n",
    "    particle_enhanced['theta'].grad = grad_theta\n",
    "    \n",
    "    # Use PyTorch optimizers to update parameters\n",
    "    optimizer_z_enhanced.step()\n",
    "    optimizer_theta_enhanced.step()\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # STEP 5: Comprehensive Logging and Monitoring\n",
    "    # ------------------------------------------------\n",
    "    if t % logging_interval == 0 or t == 1 or t == num_iterations_enhanced:\n",
    "        \n",
    "        # Compute current parameter norms\n",
    "        z_norm = particle_enhanced['z'].norm().item()\n",
    "        theta_norm = particle_enhanced['theta'].norm().item()\n",
    "        \n",
    "        # ------------------------------------------------\n",
    "        # STEP 5a: Edge Probability Analysis\n",
    "        # ------------------------------------------------\n",
    "        with torch.no_grad():\n",
    "            # Soft edge probabilities (continuous values)\n",
    "            edge_probs = bernoulli_soft_gmat(particle_enhanced['z'], hparams).detach().cpu()\n",
    "            \n",
    "            # Hard graph (binary adjacency matrix after thresholding)\n",
    "            hard_graph = hard_gmat_from_z(particle_enhanced['z'], hparams['alpha']).detach().cpu()\n",
    "            \n",
    "            # Weighted theta matrix (element-wise multiplication of G and Theta)\n",
    "            theta_cpu = particle_enhanced['theta'].detach().cpu()\n",
    "            weighted_theta = hard_graph * theta_cpu\n",
    "        \n",
    "        # ------------------------------------------------\n",
    "        # STEP 5b: Ground Truth Comparison\n",
    "        # ------------------------------------------------\n",
    "        # Compute Structural Hamming Distance (SHD) if ground truth is available\n",
    "        shd = float('nan')\n",
    "        if 'graph_adj' in locals():\n",
    "            # SHD = number of edge differences between learned and true graph\n",
    "            shd = torch.sum(torch.abs(hard_graph.int() - graph_adj.int())).item()\n",
    "        \n",
    "        # ------------------------------------------------\n",
    "        # STEP 5c: Concise Console Logging (Updated Format)\n",
    "        # ------------------------------------------------\n",
    "        # Implement beta annealing (beta increases with iteration for better convergence)\n",
    "        current_beta = cfg.beta_val + t * 0.001  # Annealing: beta increases over time\n",
    "        hparams['beta'] = current_beta  # Update beta in hparams\n",
    "        \n",
    "        # Concise logging format matching the target output\n",
    "        log.info(f\"Iter {t}: Z_norm={z_norm:.4f}, Theta_norm={theta_norm:.4f}, log_joint={lj_val:.4f}, grad_Z_norm={grad_z_norm_original:.4e}, grad_Theta_norm={grad_theta_norm_original:.4e}\")\n",
    "        \n",
    "        # Show a sample of the current grad_Theta matrix\n",
    "        log.info(f\"    grad_Theta (sample from iter {t}):\")\n",
    "        log.info(f\"{grad_theta.detach().cpu()}\")\n",
    "        \n",
    "        # Show annealed hyperparameters\n",
    "        current_alpha = hparams.get('alpha', cfg.alpha_val)\n",
    "        current_tau = hparams.get('tau', cfg.tau_val)\n",
    "        log.info(f\"    Annealed: alpha={current_alpha:.3f}, beta={current_beta:.3f}, tau={current_tau:.3f}\")\n",
    "        \n",
    "        # Show current edge probabilities\n",
    "        log.info(f\"    Current Edge Probs (from Z, alpha={current_alpha:.3f}):\")\n",
    "        log.info(f\"{edge_probs}\")\n",
    "        \n",
    "        # Edge probability statistics for MLflow logging\n",
    "        max_edge_prob = edge_probs.max().item()\n",
    "        mean_edge_prob = edge_probs.mean().item()\n",
    "        num_edges_hard = hard_graph.sum().item()\n",
    "        \n",
    "        # Ground truth comparison\n",
    "        if not math.isnan(shd):\n",
    "            pass  # Skip detailed SHD logging during training for cleaner output\n",
    "        \n",
    "        # ------------------------------------------------\n",
    "        # STEP 5e: Enhanced MLflow Logging\n",
    "        # ------------------------------------------------\n",
    "        # Log all metrics to MLflow for experiment tracking\n",
    "        mlflow.log_metric(\"enhanced_log_joint\", lj_val, step=t)\n",
    "        mlflow.log_metric(\"z_norm\", z_norm, step=t)\n",
    "        mlflow.log_metric(\"theta_norm\", theta_norm, step=t)\n",
    "        mlflow.log_metric(\"grad_z_norm_original\", grad_z_norm_original, step=t)\n",
    "        mlflow.log_metric(\"grad_theta_norm_original\", grad_theta_norm_original, step=t)\n",
    "        mlflow.log_metric(\"grad_z_norm_final\", grad_z_norm_final, step=t)\n",
    "        mlflow.log_metric(\"grad_theta_norm_final\", grad_theta_norm_final, step=t)\n",
    "        mlflow.log_metric(\"max_edge_prob\", max_edge_prob, step=t)\n",
    "        mlflow.log_metric(\"mean_edge_prob\", mean_edge_prob, step=t)\n",
    "        mlflow.log_metric(\"num_hard_edges\", num_edges_hard, step=t)\n",
    "        \n",
    "        if not math.isnan(shd):\n",
    "            mlflow.log_metric(\"structural_hamming_distance\", shd, step=t)\n",
    "        \n",
    "        # Log boolean indicators as metrics\n",
    "        mlflow.log_metric(\"z_gradient_clipped\", float(grad_z_clipped), step=t)\n",
    "        mlflow.log_metric(\"theta_gradient_clipped\", float(grad_theta_clipped), step=t)\n",
    "        \n",
    "        # ------------------------------------------------\n",
    "        # STEP 5f: Numerical Stability Checks\n",
    "        # ------------------------------------------------\n",
    "        # Check for NaN or Inf values that could break training\n",
    "        z_has_nan = torch.isnan(particle_enhanced['z']).any()\n",
    "        z_has_inf = torch.isinf(particle_enhanced['z']).any()\n",
    "        theta_has_nan = torch.isnan(particle_enhanced['theta']).any()\n",
    "        theta_has_inf = torch.isinf(particle_enhanced['theta']).any()\n",
    "        \n",
    "        if z_has_nan or theta_has_nan:\n",
    "            log.error(\"!!! NaN DETECTED IN PARAMETERS - STOPPING TRAINING !!!\")\n",
    "            log.error(f\"Z has NaN: {z_has_nan}, Theta has NaN: {theta_has_nan}\")\n",
    "            break\n",
    "            \n",
    "        if z_has_inf or theta_has_inf:\n",
    "            log.error(\"!!! INFINITY DETECTED IN PARAMETERS - STOPPING TRAINING !!!\")\n",
    "            log.error(f\"Z has Inf: {z_has_inf}, Theta has Inf: {theta_has_inf}\")\n",
    "            break\n",
    "\n",
    "# ========================================================================\n",
    "# ENHANCED TRAINING COMPLETION AND FINAL ANALYSIS\n",
    "# ========================================================================\n",
    "\n",
    "log.info(\"\\n\" + \"=\"*80)\n",
    "log.info(\"ENHANCED TRAINING LOOP COMPLETED\")\n",
    "log.info(\"=\"*80)\n",
    "\n",
    "# Compute final graph structures\n",
    "with torch.no_grad():\n",
    "    final_edge_probs_enhanced = bernoulli_soft_gmat(particle_enhanced['z'], hparams).detach().cpu()\n",
    "    final_hard_graph_enhanced = hard_gmat_from_z(particle_enhanced['z'], hparams['alpha']).detach().cpu()\n",
    "    final_theta_enhanced = particle_enhanced['theta'].detach().cpu()\n",
    "    final_weighted_theta_enhanced = final_hard_graph_enhanced * final_theta_enhanced\n",
    "\n",
    "# Final comparison with ground truth - matching the target output format\n",
    "log.info(\"\\n        --- Comparison with Ground Truth ---\")\n",
    "log.info(f\"Final G_learned_hard:\")\n",
    "log.info(f\"{final_hard_graph_enhanced.int()}\")\n",
    "log.info(\"**************************************************\")\n",
    "\n",
    "# Create final weighted matrix using learned hard graph and learned theta\n",
    "log.info(f\"Final G_learned_hard * Theta_learned:\")\n",
    "log.info(f\"{final_weighted_theta_enhanced}\")\n",
    "\n",
    "# Additional analysis - show ground truth comparison if available\n",
    "if 'graph_adj' in locals():\n",
    "    final_shd = torch.sum(torch.abs(final_hard_graph_enhanced.int() - graph_adj.int())).item()\n",
    "    log.info(f\"\\nFinal Structural Hamming Distance: {final_shd}\")\n",
    "    \n",
    "    log.info(f\"\\nDetailed Comparison:\")\n",
    "    log.info(f\"Ground Truth Graph:\")\n",
    "    log.info(f\"{graph_adj.int()}\")\n",
    "    log.info(f\"Learned Graph:\")\n",
    "    log.info(f\"{final_hard_graph_enhanced.int()}\")\n",
    "    \n",
    "    if 'graph_weights' in locals():\n",
    "        log.info(f\"Ground Truth Theta:\")\n",
    "        log.info(f\"{graph_weights}\")\n",
    "        log.info(f\"Learned Theta:\")\n",
    "        log.info(f\"{final_theta_enhanced}\")\n",
    "        \n",
    "        # Show weighted matrices comparison\n",
    "        ground_truth_weighted = graph_adj * graph_weights\n",
    "        log.info(f\"Ground Truth G * Theta:\")\n",
    "        log.info(f\"{ground_truth_weighted}\")\n",
    "\n",
    "log.info(\"\\nEnhanced training analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2276644",
   "metadata": {},
   "source": [
    "# Training Methods Comparison\n",
    "Compare results between the basic training loop and the enhanced training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea688a7",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f7c750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 11:21:42,495 - INFO - \n",
      "================================================================================\n",
      "2025-06-17 11:21:42,499 - INFO - FINAL RESULTS FROM ENHANCED TRAINING\n",
      "2025-06-17 11:21:42,499 - INFO - ================================================================================\n",
      "2025-06-17 11:21:42,501 - INFO - \n",
      "1. LEARNED EDGE PROBABILITIES (Soft Graph):\n",
      "2025-06-17 11:21:42,502 - INFO - tensor([[0.0000, 0.5180, 0.5521],\n",
      "        [0.8712, 0.0000, 0.5817],\n",
      "        [0.9199, 0.7737, 0.0000]])\n",
      "2025-06-17 11:21:42,502 - INFO - \n",
      "2. LEARNED HARD GRAPH (Binary Adjacency Matrix):\n",
      "2025-06-17 11:21:42,503 - INFO - tensor([[0, 1, 1],\n",
      "        [1, 0, 1],\n",
      "        [1, 1, 0]], dtype=torch.int32)\n",
      "2025-06-17 11:21:42,505 - INFO - \n",
      "3. LEARNED THETA MATRIX (Edge Weights):\n",
      "2025-06-17 11:21:42,506 - INFO - tensor([[-0.3611, -1.1584,  1.9121],\n",
      "        [-1.7127, -0.4005,  2.0358],\n",
      "        [ 3.9815,  2.3314,  1.4922]])\n",
      "2025-06-17 11:21:42,511 - INFO - \n",
      "4. FINAL WEIGHTED GRAPH (G ⊙ Theta):\n",
      "2025-06-17 11:21:42,513 - INFO - tensor([[-0.0000, -1.1584,  1.9121],\n",
      "        [-1.7127, -0.0000,  2.0358],\n",
      "        [ 3.9815,  2.3314,  0.0000]])\n",
      "2025-06-17 11:21:42,515 - INFO - \n",
      "------------------------------------------------------------\n",
      "2025-06-17 11:21:42,516 - INFO - GROUND TRUTH COMPARISON\n",
      "2025-06-17 11:21:42,519 - INFO - ------------------------------------------------------------\n",
      "2025-06-17 11:21:42,523 - INFO - \n",
      "Ground Truth Graph:\n",
      "2025-06-17 11:21:42,524 - INFO - tensor([[0, 1, 0],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 0]], dtype=torch.int32)\n",
      "2025-06-17 11:21:42,525 - INFO - \n",
      "Ground Truth Weights:\n",
      "2025-06-17 11:21:42,526 - INFO - tensor([[ 0.0000,  2.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -1.5000],\n",
      "        [ 0.0000,  0.0000,  0.0000]])\n",
      "2025-06-17 11:21:42,526 - INFO - \n",
      "Ground Truth Weighted (G_true ⊙ Theta_true):\n",
      "2025-06-17 11:21:42,527 - INFO - tensor([[ 0.0000,  2.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -1.5000],\n",
      "        [ 0.0000,  0.0000,  0.0000]])\n",
      "2025-06-17 11:21:42,528 - INFO - \n",
      "Structural Hamming Distance (SHD): 4\n",
      "2025-06-17 11:21:42,528 - INFO - Perfect Structure Recovery: False\n",
      "2025-06-17 11:21:42,545 - INFO - \n",
      "Final results logging complete and MLflow run ended!\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# FINAL RESULTS: Matrix Outputs (Enhanced Training)\n",
    "# ========================================================================\n",
    "# Display the final learned matrices from the enhanced training loop\n",
    "\n",
    "log.info(\"\\n\" + \"=\"*80)\n",
    "log.info(\"FINAL RESULTS FROM ENHANCED TRAINING\")\n",
    "log.info(\"=\"*80)\n",
    "\n",
    "# Use results from enhanced training loop\n",
    "final_graph_enhanced = hard_gmat_from_z(particle_enhanced['z'], hparams['alpha']).detach().cpu()\n",
    "edge_probs_enhanced = bernoulli_soft_gmat(particle_enhanced['z'], hparams).detach().cpu()\n",
    "theta_enhanced = particle_enhanced['theta'].detach().cpu()\n",
    "weighted_theta_enhanced = final_graph_enhanced * theta_enhanced\n",
    "\n",
    "log.info(f\"\\n1. LEARNED EDGE PROBABILITIES (Soft Graph):\")\n",
    "log.info(f\"{edge_probs_enhanced}\")\n",
    "\n",
    "log.info(f\"\\n2. LEARNED HARD GRAPH (Binary Adjacency Matrix):\")\n",
    "log.info(f\"{final_graph_enhanced.int()}\")\n",
    "\n",
    "log.info(f\"\\n3. LEARNED THETA MATRIX (Edge Weights):\")\n",
    "log.info(f\"{theta_enhanced}\")\n",
    "\n",
    "log.info(f\"\\n4. FINAL WEIGHTED GRAPH (G ⊙ Theta):\")\n",
    "log.info(f\"{weighted_theta_enhanced}\")\n",
    "\n",
    "# Ground truth comparison\n",
    "if 'graph_adj' in locals() and 'graph_weights' in locals():\n",
    "    log.info(f\"\\n\" + \"-\"*60)\n",
    "    log.info(\"GROUND TRUTH COMPARISON\")\n",
    "    log.info(\"-\"*60)\n",
    "    \n",
    "    log.info(f\"\\nGround Truth Graph:\")\n",
    "    log.info(f\"{graph_adj.int()}\")\n",
    "    \n",
    "    log.info(f\"\\nGround Truth Weights:\")\n",
    "    log.info(f\"{graph_weights}\")\n",
    "    \n",
    "    ground_truth_weighted = graph_adj * graph_weights\n",
    "    log.info(f\"\\nGround Truth Weighted (G_true ⊙ Theta_true):\")\n",
    "    log.info(f\"{ground_truth_weighted}\")\n",
    "    \n",
    "    # Compute final metrics\n",
    "    final_shd = torch.sum(torch.abs(final_graph_enhanced.int() - graph_adj.int())).item()\n",
    "    log.info(f\"\\nStructural Hamming Distance (SHD): {final_shd}\")\n",
    "    \n",
    "    # Check if structure is correctly recovered\n",
    "    structure_match = torch.equal(final_graph_enhanced.int(), graph_adj.int())\n",
    "    log.info(f\"Perfect Structure Recovery: {structure_match}\")\n",
    "\n",
    "# MLflow logging for final results\n",
    "mlflow.log_metric(\"final_z_norm\", particle_enhanced['z'].norm().item())\n",
    "mlflow.log_metric(\"final_theta_norm\", particle_enhanced['theta'].norm().item())\n",
    "mlflow.log_metric(\"final_max_edge_prob\", edge_probs_enhanced.max().item())\n",
    "mlflow.log_metric(\"final_mean_edge_prob\", edge_probs_enhanced.mean().item())\n",
    "mlflow.log_metric(\"final_num_edges\", final_graph_enhanced.sum().item())\n",
    "\n",
    "if 'graph_adj' in locals():\n",
    "    mlflow.log_metric(\"final_shd\", final_shd)\n",
    "    mlflow.log_metric(\"perfect_structure_recovery\", float(structure_match))\n",
    "\n",
    "# End the MLflow run\n",
    "mlflow.end_run()\n",
    "log.info(\"\\nFinal results logging complete and MLflow run ended!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dibs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
